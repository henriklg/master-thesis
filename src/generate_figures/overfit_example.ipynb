{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lr_and_accuracy(history, conf):\n",
    "    import seaborn as sns\n",
    "    sns.set()\n",
    "\n",
    "    SMALL_SIZE = 12\n",
    "    MEDIUM_SIZE = 14\n",
    "    BIGGER_SIZE = 16\n",
    "\n",
    "    plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "    acc = history['sparse_categorical_accuracy']\n",
    "    val_acc = history['val_sparse_categorical_accuracy']\n",
    "\n",
    "    loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "    \n",
    "    epochs_range = range(60)\n",
    "    \n",
    "    if conf[\"decay_rate\"] > 0:\n",
    "        lr = history['lr']\n",
    "        # Plot the learning rate\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(epochs_range, lr, label='Learning Rate')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Learnign rate')\n",
    "        plt.title('Learning Rate development during training');\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(conf[\"log_dir\"]+'/learning_rate.pdf', format='pdf')\n",
    "    \n",
    "    # Plot train-val accuracy and loss\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Subplot 1\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylim([0, 1.01])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    # Subplot 2\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylim([-0.01, 3])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(conf[\"log_dir\"]+'/accuracy_and_loss.pdf', format='pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_schedule_conf = {\n",
    "    \"log_dir\": \".\",\n",
    "    \"decay_rate\": 0\n",
    "    }\n",
    "\n",
    "experiment_directory = \"/home/henriklg/master-thesis/code/hyper-kvasir/experiments/misc_old/overfit_example\"\n",
    "\n",
    "no_schedule_history = {\n",
    "    \"loss\": [1.5072544227386344, 0.7790612218708828, 0.6250192923792477, 0.5121105169427806, 0.47008189970049363, 0.42635839740777837, 0.394188962106047, 0.37841374606921757, 0.3476650296100255, 0.3259111303707649, 0.29389441655627613, 0.30275844063224466, 0.26665452842054693, 0.2635612076726453, 0.23953651431305656, 0.22976859890181442, 0.20154377445578575, 0.1805611290037632, 0.1766955211501697, 0.16294705379625846, 0.14493887010833312, 0.12392903363396382, 0.12449626207094767, 0.12019846106654611, 0.09853680939253034, 0.09220942154783628, 0.08217798761124241, 0.08895607967058132, 0.10141584758871589, 0.06739018878353567, 0.0788314595561603, 0.07878443068856823, 0.04671982264724271, 0.0424491838343313, 0.04655713375240307, 0.045301885536775506, 0.03314688705421727, 0.030609465726041073, 0.02400444703505792, 0.02572265391213948, 0.022721807460364854, 0.022230125398672154, 0.034153152698779415, 0.020002304964722935, 0.027791833597112944, 0.03248033320113759, 0.021846247286985403, 0.018239968427224085, 0.011502489237594499, 0.018537745091478052, 0.01818391529778982, 0.01010182930923324, 0.01021367406742527, 0.01677587423859975, 0.024793762778903453, 0.019031021726951966, 0.006122106996340805, 0.017206230188784158, 0.008957777759421552, 0.026934080883150052], \n",
    "    \"sparse_categorical_accuracy\": [0.5691002, 0.74703664, 0.7909483, 0.8279903, 0.83943963, 0.85775864, 0.86355066, 0.87217134, 0.87796336, 0.88671875, 0.89426184, 0.89426184, 0.9042295, 0.9108297, 0.9139278, 0.9185075, 0.9284752, 0.936153, 0.94019395, 0.94275326, 0.95029634, 0.95743537, 0.9555496, 0.9610722, 0.9676724, 0.9676724, 0.970097, 0.97265625, 0.9686153, 0.9788524, 0.97494614, 0.97481143, 0.9850485, 0.9865302, 0.9853179, 0.9853179, 0.98935884, 0.991514, 0.9931304, 0.9931304, 0.992861, 0.99272627, 0.98949355, 0.99380386, 0.992861, 0.9890894, 0.9932651, 0.9954203, 0.9967672, 0.99501616, 0.99501616, 0.9967672, 0.99609375, 0.99568963, 0.9940733, 0.99393857, 0.99851835, 0.99515086, 0.9975754, 0.99488145], \n",
    "    \"val_loss\": [3919.4466145833335, 11.65205423037211, 4.360255757967631, 4.273410499095917, 1.3454897205034893, 2.2958114743232727, 0.6566694676876068, 1.7990142504374187, 1.2267223745584488, 1.6769937773545582, 0.6317088603973389, 0.6943292692303658, 0.584413061539332, 0.652853491405646, 0.9270377308130264, 0.5677525550127029, 0.5511963839332262, 0.6477192168434461, 0.9203999936580658, 0.6613056461016337, 0.7751666804154714, 0.6975759491324425, 0.7513672312100729, 0.6839244663715363, 0.7200210466980934, 0.9663039296865463, 0.8110103557507197, 0.8093332896629969, 0.8051123370726904, 0.7844762777288755, 1.004360094666481, 0.9871400992075602, 1.0284421841303508, 0.8175521641969681, 1.1002954989671707, 0.7096163878838221, 0.9926159679889679, 0.9591069966554642, 0.9033658156792322, 0.819308136900266, 0.7499794612328211, 0.8792222191890081, 0.8911004836360613, 0.9291882663965225, 0.9136366893847784, 1.1273022045691807, 0.8832092881202698, 0.9507997334003448, 0.9865448425213496, 0.9420620948076248, 0.9097297737995783, 1.0210385397076607, 1.055717463294665, 1.0009022454420726, 0.9238067418336868, 0.9220342685778936, 1.0081120158235233, 0.8685589333375295, 1.0002639045317967, 0.8850182692209879], \n",
    "    \"val_sparse_categorical_accuracy\": [0.057942707, 0.08528646, 0.37955728, 0.5722656, 0.7050781, 0.66796875, 0.80338544, 0.66276044, 0.7389323, 0.75651044, 0.8261719, 0.8020833, 0.81966144, 0.81640625, 0.7890625, 0.8489583, 0.85091144, 0.81184894, 0.77994794, 0.8385417, 0.81901044, 0.8339844, 0.8411458, 0.83528644, 0.86588544, 0.8489583, 0.8144531, 0.84244794, 0.8157552, 0.82942706, 0.796875, 0.8170573, 0.83463544, 0.8489583, 0.84244794, 0.86002606, 0.8404948, 0.8261719, 0.85026044, 0.8489583, 0.8619792, 0.8619792, 0.8717448, 0.8652344, 0.8391927, 0.85026044, 0.86002606, 0.86328125, 0.87369794, 0.8730469, 0.8645833, 0.86783856, 0.85286456, 0.8417969, 0.8483073, 0.86653644, 0.8730469, 0.86783856, 0.8723958, 0.86653644]\n",
    "}\n",
    "\n",
    "plot_lr_and_accuracy(no_schedule_history, no_schedule_conf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
