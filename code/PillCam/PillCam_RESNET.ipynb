{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading images\n",
    "https://www.tensorflow.org/tutorials/load_data/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import resnet\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_GPUS = 1\n",
    "BS_PER_GPU = 128\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "IMG_HEIGHT = 64\n",
    "IMG_WIDTH = 64\n",
    "NUM_CHANNELS = 3\n",
    "NUM_CLASSES = 8\n",
    "#NUM_TRAIN_SAMPLES = 40000\n",
    "\n",
    "BASE_LEARNING_RATE = 0.1\n",
    "LR_SCHEDULE = [(0.1, 30), (0.01, 45)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "  x = tf.image.per_image_standardization(x)\n",
    "  return x, y\n",
    "\n",
    "\n",
    "def augmentation(x, y):\n",
    "    x = tf.image.resize_with_crop_or_pad(\n",
    "        x, IMG_HEIGHT + 8, IMG_WIDTH + 8)\n",
    "    x = tf.image.random_crop(x, [IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS])\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    return x, y\t\n",
    "\n",
    "\n",
    "def schedule(epoch):\n",
    "  initial_learning_rate = BASE_LEARNING_RATE * BS_PER_GPU / 128\n",
    "  learning_rate = initial_learning_rate\n",
    "  for mult, start_epoch in LR_SCHEDULE:\n",
    "    if epoch >= start_epoch:\n",
    "      learning_rate = initial_learning_rate * mult\n",
    "    else:\n",
    "      break\n",
    "  tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "  return learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names:  ['Anatomic landmarks' 'Unknown' 'Protruding lesions' 'Flat lesions'\n",
      " 'Lumen' 'Mucosa' 'Normal' 'Excavated lesions']\n"
     ]
    }
   ],
   "source": [
    "data_dir = pathlib.Path('/mnt/sdb/augere_export_class/')\n",
    "\n",
    "DATASET_SIZE = len(list(data_dir.glob('*/*.png')))\n",
    "class_names = np.array([item.name for item in data_dir.glob('*') if item.name != 'metadata.json'])\n",
    "print (\"Class names: \",class_names)\n",
    "\n",
    "# Create a dataset of the file paths\n",
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anatomic landmarks: 6868\n",
      "Unknown           : 274\n",
      "Protruding lesions: 583\n",
      "Flat lesions      : 908\n",
      "Lumen             : 1446\n",
      "Mucosa            : 251\n",
      "Normal            : 33129\n",
      "Excavated lesions : 1252\n",
      "\n",
      "Total number of images: 44711\n",
      "But the dataset is mainly shit\n"
     ]
    }
   ],
   "source": [
    "samples_per_class = []\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_samples = len(list(data_dir.glob(class_name+'/*.png')))\n",
    "    samples_per_class.append(class_samples)\n",
    "    print('{0:18}: {1:3d}'.format(classes, class_samples))\n",
    "\n",
    "print ('\\nTotal number of images:', DATASET_SIZE)\n",
    "\n",
    "# If one class contains more than half of the entire sample size\n",
    "if np.max(samples_per_class) > DATASET_SIZE//2:\n",
    "    print (\"But the dataset is mainly shit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_test(file_path):\n",
    "    # Not used, mainly for log\n",
    "    label = [i for i, s in enumerate(class_names) if 'Normal' in s]\n",
    "    return np.uint8(label)\n",
    "    \n",
    "def get_label_int(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # get class integer from class-list\n",
    "    label_int64 = tf.reduce_min(tf.where(tf.equal(parts[-2], class_names)))\n",
    "    # cast to tensor array with dtype=uint8\n",
    "    label_uint8 = tf.dtypes.cast(label_int64, tf.uint8)\n",
    "    return tf.reshape(label_uint8, [-1])\n",
    "\n",
    "def get_label_bool(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    return parts[-2] == class_names\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label_int(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label\n",
    "\n",
    "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing an example image/label pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Normal\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image, label in labeled_ds.take(1):\n",
    "    plt.figure()\n",
    "    #plt.figure(frameon=False, facecolor='white')\n",
    "    fig = plt.imshow(image.numpy())\n",
    "    plt.axis('off')\n",
    "    print(\"Class:\",class_names[label.numpy()][0])\n",
    "    \n",
    "#print(next(iter(labeled_ds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "See https://lambdalabs.com/blog/tensorflow-2-0-tutorial-01-image-classification-basics/\n",
    "\n",
    "https://github.com/lambdal/TensorFlow2-tutorial/tree/master/01-basic-image-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting into training, test and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "val_size = int(0.15 * DATASET_SIZE)\n",
    "test_size = int(0.15 * DATASET_SIZE)\n",
    "\n",
    "train_ds = labeled_ds.take(train_size)\n",
    "test_ds = labeled_ds.skip(train_size)\n",
    "val_ds = test_ds.skip(val_size)\n",
    "test_ds = test_ds.take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset sample size:        44711\n",
      "Train dataset sample size:       31297\n",
      "Test dataset sample size:         6706\n",
      "Validation dataset sample size:   6708\n"
     ]
    }
   ],
   "source": [
    "def get_size(ds):\n",
    "    return tf.data.experimental.cardinality(ds).numpy()\n",
    "\n",
    "print (\"{:32} {:>5}\".format(\"Full dataset sample size:\", get_size(labeled_ds)))\n",
    "print (\"{:32} {:>5}\".format(\"Train dataset sample size:\", get_size(train_ds)))\n",
    "print (\"{:32} {:>5}\".format(\"Test dataset sample size:\", get_size(test_ds)))\n",
    "print (\"{:32} {:>5}\".format(\"Validation dataset sample size:\", get_size(val_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
    "    # This is a small dataset, only load it once, and keep it in memory.\n",
    "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "    # fit in memory.\n",
    "    if cache:\n",
    "      if isinstance(cache, str):\n",
    "        ds = ds.cache(cache)\n",
    "      else:\n",
    "        ds = ds.cache()\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    # Repeat forever\n",
    "    #ds = ds.repeat()\n",
    "\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# Create training dataset\n",
    "train_ds = prepare_for_training(train_ds, cache=\"./train_ds.tfcache\")\n",
    "# Create test dataset\n",
    "test_ds = prepare_for_training(test_ds, cache=\"./test_ds.tfcache\")\n",
    "# Create validation dataset\n",
    "val_ds = prepare_for_training(val_ds, cache=\"./val_ds.tfcache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "245/245 [==============================] - 25s 103ms/step - loss: 0.8399 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "245/245 [==============================] - 14s 58ms/step - loss: 0.6879 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6219 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "245/245 [==============================] - 14s 59ms/step - loss: 0.5650 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5108 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "245/245 [==============================] - 14s 58ms/step - loss: 0.4641 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4196 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "245/245 [==============================] - 14s 59ms/step - loss: 0.3812 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3447 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "245/245 [==============================] - 14s 59ms/step - loss: 0.3131 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2831 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "245/245 [==============================] - 14s 59ms/step - loss: 0.2572 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2325 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "245/245 [==============================] - 14s 59ms/step - loss: 0.2113 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1910 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "245/245 [==============================] - 14s 59ms/step - loss: 0.1735 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1569 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "245/245 [==============================] - 15s 61ms/step - loss: 0.1425 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1289 - val_sparse_categorical_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(22)\n",
    "#train_dataset = train_dataset.map(augmentation).map(preprocess).shuffle(NUM_TRAIN_SAMPLES).batch(BS_PER_GPU * NUM_GPUS, drop_remainder=True)\n",
    "#test_dataset = test_dataset.map(preprocess).batch(BS_PER_GPU * NUM_GPUS, drop_remainder=True)\n",
    "\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS)\n",
    "img_input = tf.keras.layers.Input(shape=input_shape)\n",
    "opt = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "\n",
    "if NUM_GPUS == 1:\n",
    "    model = resnet.resnet56(img_input=img_input, classes=NUM_CLASSES)\n",
    "    model.compile(\n",
    "              optimizer=opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "else:\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():\n",
    "      model = resnet.resnet56(img_input=img_input, classes=NUM_CLASSES)\n",
    "      model.compile(\n",
    "                optimizer=opt,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['sparse_categorical_accuracy'])  \n",
    "\n",
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
    "file_writer.set_as_default()\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "  log_dir=log_dir,\n",
    "  update_freq='batch',\n",
    "  histogram_freq=1)\n",
    "\n",
    "lr_schedule_callback = LearningRateScheduler(schedule)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    validation_data=test_ds,\n",
    "    validation_freq=1,\n",
    "    #steps_per_epoch=245, if ds.repeat() should be ceil(num_samples/batch_size)\n",
    "    #validation_steps=245, sould be ceil(num_val_samples/batch_size)\n",
    "    callbacks=[tensorboard_callback, lr_schedule_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "history dict: {'loss': [0.8420474028844066, 0.6894135404654683, 0.5662812322847613, 0.4651409038448919, 0.382064679968634, 0.31382623726987885, 0.2577754840043862, 0.21173564287533825, 0.1739187197425927, 0.14285606744104892], 'sparse_categorical_accuracy': [0.996006, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.7590075731277466, 0.6234455108642578, 0.5120953917503357, 0.42063289880752563, 0.3455059826374054, 0.28379708528518677, 0.23310968279838562, 0.1914752572774887, 0.1572769284248352, 0.12918657064437866], 'val_sparse_categorical_accuracy': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'lr': [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]}\n"
     ]
    }
   ],
   "source": [
    "# The returned \"history\" object holds a record\n",
    "# of the loss values and metric values during training\n",
    "print('\\nhistory dict:', history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the results\n",
    "\n",
    "`Tensorboard`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/home/henrik/anaconda3/envs/TF2/bin:/home/henrik/anaconda3/bin:/home/henrik/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\n"
     ]
    }
   ],
   "source": [
    "PATH = os.getenv('PATH')\n",
    "%env PATH=/home/henrik/anaconda3/envs/TF2/bin:$PATH\n",
    "\n",
    "# Clear any logs from previous runs (move to .old instead?)\n",
    "# !rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "No known TensorBoard instances running.\n"
     ]
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "notebook.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start tensorboard\n",
    "%tensorboard --logdir logs\n",
    "\n",
    "# !kill 20058"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Keras`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)\n",
    "\n",
    "model.save('model.h5')\n",
    "\n",
    "new_model = keras.models.load_model('model.h5')\n",
    " \n",
    "new_model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(val_ds))\n",
    "image = image.numpy()\n",
    "print (\"True label:\", class_names[label.numpy()[0][0]])\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(image[0])\n",
    "#print (image.numpy())\n",
    "res = model.predict(image)\n",
    "\n",
    "print (\"Predicted label:\", class_names[np.argmax(res[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for lab in res:\n",
    "    print ('{:3} True:{:20} Pred:{}'.format(idx, class_names[label[idx]], class_names[np.argmax(lab)]))\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
