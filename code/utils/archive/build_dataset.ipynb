{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: [link](https://github.com/cs230-stanford/cs230-code-examples/blob/master/tensorflow/vision/build_dataset.py)\n",
    "### TODO\n",
    "- DONE Create py script with argparse \n",
    "- DONE Handle minority classes > 10\n",
    "- DONE Test opencv vs pillow (opencv just barely faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from math import ceil, floor\n",
    "from pathlib import Path\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/cifar'\n",
    "output_dir = \"data/output\"\n",
    "size = 32\n",
    "seed = 230\n",
    "splits = [0.7, 0.15, 0.15]\n",
    "train_split = splits[0]\n",
    "test_split = splits[0]+splits[1]\n",
    "\n",
    "random.seed(seed)\n",
    "assert sum(splits) == 1.0, 'Sum of splits must be 1.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_save(filename, output_dir, size=size):\n",
    "    \"\"\"Resize the image contained in `filename` and save it to the `output_dir`\"\"\"\n",
    "    image = cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n",
    "    # Use bilinear interpolation instead of the default \"nearest neighbor\" method\n",
    "    image = cv2.resize(image, (size, size), interpolation=cv2.INTER_LINEAR)\n",
    "    path = os.path.join(output_dir, filename.split('/')[-1])\n",
    "    cv2.imwrite(path, image)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# resize just one single folder of images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = os.listdir(data_dir)\n",
    "num_classes = len(class_names)\n",
    "num_samples = len(list(Path(data_dir).glob('*/*')))\n",
    "\n",
    "image_folders = [os.path.join(data_dir, class_name) for class_name in class_names]\n",
    "\n",
    "# Create folders for train, test and val with subfolders\n",
    "train_folders = [os.path.join(output_dir, 'train', class_name) for class_name in class_names]\n",
    "test_folders = [os.path.join(output_dir, 'test', class_name) for class_name in class_names]\n",
    "val_folders = [os.path.join(output_dir, 'val', class_name) for class_name in class_names]\n",
    "\n",
    "# Create all folders\n",
    "[Path(train_folder).mkdir(parents=True, exist_ok=True) for train_folder in train_folders]\n",
    "[Path(test_folder).mkdir(parents=True, exist_ok=True) for test_folder in test_folders]\n",
    "[Path(val_folder).mkdir(parents=True, exist_ok=True) for val_folder in val_folders];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855e5fdd26974e1f862bf65936fd1a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Images', max=10000.0, style=ProgressStyle(description_widâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done building dataset.\n"
     ]
    }
   ],
   "source": [
    "tqdm_img = tqdm(total=num_samples, desc='Images', position=0)\n",
    "\n",
    "# Iterate over categories\n",
    "for idx, directory in enumerate(image_folders):\n",
    "    \n",
    "    random.seed(seed)\n",
    "    # Get filenames in category, sort and shuffle (for reproducible split)\n",
    "    filenames = os.listdir(directory)\n",
    "    filenames.sort()\n",
    "    random.shuffle(filenames)\n",
    "    num_samples = len(filenames)\n",
    "    \n",
    "    # Calculate number of samples for each dataset\n",
    "    # NB: minimum 4 samples to get one in each split\n",
    "    filenames = np.array(filenames)\n",
    "    filenames_split = np.split(filenames, [floor(num_samples*train_split), floor(num_samples*test_split)])\n",
    "    \n",
    "    # Split dataset into train test val\n",
    "    ds = {'train': filenames_split[0],\n",
    "          'test': filenames_split[1],\n",
    "          'val': filenames_split[2]}\n",
    "    \n",
    "    # Copy files to correct folder/split\n",
    "    for split in ds:\n",
    "        output = os.path.join(output_dir, split, directory.split(\"/\")[-1])\n",
    "        for filename in ds[split]:\n",
    "            filename = os.path.join(directory, filename)\n",
    "            resize_and_save(filename, output, size=size)\n",
    "            tqdm_img.update(1)\n",
    "\n",
    "print (\"Done building dataset.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
