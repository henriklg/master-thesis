{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kvasir dataset split into neg/pos and trained using Resnet50 without augmentation. Getting some decent results after training on resampled data with large step-size.  \n",
    "- Class weighting  \n",
    "- Resampling  \n",
    "- Initial Bias-estimation\n",
    "- Decreasing learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Some stuff to make utils-function work\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "from data_prep import create_dataset, print_class_info, show_image\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Jupyter-specific\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10662\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "data_dir = pathlib.Path('/home/henrik/master-thesis/data/hyper-kvasir/labeled/')\n",
    "\n",
    "ds_size = len(list(data_dir.glob('*/*.*g')))\n",
    "print (ds_size)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "IMG_HEIGHT = 64\n",
    "IMG_WIDTH = 64\n",
    "num_classes = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array([item.name for item in data_dir.glob('*') if item.name != '*.txt'])\n",
    "\n",
    "# Create a dataset of the file paths\n",
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['barretts-short-segment', 'bbps-0-1', 'impacted-stool', 'bbps-2-3',\n",
       "       'hemorrhoids', 'ulcerative-colitis-grade-2', 'normal-z-line',\n",
       "       'retroflex-stomach', 'esophagitis-b-d', 'dyed-resection-margins',\n",
       "       'ileum', 'ulcerative-colitis-0-1', 'dyed-lifted-polyps', 'polyps',\n",
       "       'ulcerative-colitis-2-3', 'ulcerative-colitis-1-2',\n",
       "       'ulcerative-colitis-grade-3', 'retroflex-rectum', 'esophagitis-a',\n",
       "       'ulcerative-colitis-grade-1', 'pylorus', 'cecum', 'barretts'],\n",
       "      dtype='<U26')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A short pure-tensorflow function that converts a file path to an `image_data, label` pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # get class integer from class-list\n",
    "    label_int = tf.reduce_min(tf.where(parts[-2] == class_names))\n",
    "    # cast to tensor array with dtype=uint8\n",
    "    return tf.dtypes.cast(label_int, tf.int32)\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label\n",
    "\n",
    "# Set 'num_parallel_calls' so multiple images are loaded and processed in parallel\n",
    "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset for training\n",
    "Want the data to be shuffled and batched. Here we use the `tf.data` api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=100):\n",
    "    # This is a small dataset, only load it once, and keep it in memory.\n",
    "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "    # fit in memory.\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "        else:\n",
    "            ds = ds.cache()\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    # Repeat forever\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return ds\n",
    "\n",
    "train_ds = prepare_for_training(labeled_ds, cache=\"../hyper-kvasir/cache/reject_resample_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_ds.take((ds_size//BATCH_SIZE)+1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "certainty_bs = 10\n",
    "\n",
    "### Counting functions\n",
    "def count(counts, batch):\n",
    "    images, labels = batch\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        counts['class_{}'.format(i)] += tf.reduce_sum(tf.cast(labels == i, tf.int32))\n",
    "\n",
    "    return counts\n",
    "\n",
    "def count_samples(count_ds):\n",
    "    count_ds = count_ds.batch(1024)\n",
    "    # Set the initial states to zero\n",
    "    initial_state = {}\n",
    "    for i in range(num_classes):\n",
    "        initial_state['class_{}'.format(i)] = 0\n",
    "\n",
    "    counts = count_ds.take(certainty_bs).reduce(\n",
    "                initial_state = initial_state,\n",
    "                reduce_func = count)\n",
    "\n",
    "    final_counts = []\n",
    "    for class_, value in counts.items():\n",
    "                final_counts.append(value.numpy().astype(np.float32))\n",
    "\n",
    "    final_counts = np.asarray(final_counts)\n",
    "    fractions = final_counts/final_counts.sum()\n",
    "    return fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00507812 0.06005859 0.01210937 0.10722657 0.00058594 0.04189453\n",
      " 0.08769532 0.07177734 0.02490234 0.09267578 0.00087891 0.00332031\n",
      " 0.09394531 0.09648438 0.00263672 0.00087891 0.01220703 0.03671875\n",
      " 0.03798828 0.01884766 0.09335937 0.09472656 0.00400391]\n"
     ]
    }
   ],
   "source": [
    "initial_dist = count_samples(train_ds.unbatch())\n",
    "print (initial_dist)\n",
    "\n",
    "target_dist = [1.0/num_classes] * num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for i in range(num_classes):\n",
    "    ds = train_ds.unbatch().filter(lambda image, label: label==i).repeat()\n",
    "    datasets.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_ds = tf.data.experimental.sample_from_datasets(datasets, target_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04462891 0.04326172 0.0421875  0.04091797 0.04296875 0.04335938\n",
      " 0.04746094 0.04326172 0.04042969 0.04277344 0.04267578 0.04482422\n",
      " 0.046875   0.04462891 0.04375    0.04150391 0.04628906 0.04394531\n",
      " 0.04335938 0.04121094 0.04482422 0.04160156 0.04326172]\n"
     ]
    }
   ],
   "source": [
    "print (count_samples(balanced_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rejection resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_func(image, label):\n",
    "    return tf.cast(label, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampler = tf.data.experimental.rejection_resample(\n",
    "            class_func, #=lambda features, label: label, \n",
    "            target_dist=target_dist,\n",
    "            initial_dist=initial_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_ds = train_ds.unbatch().apply(resampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_ds = resample_ds.map(lambda extra_label, img_and_label: img_and_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00634766 0.0609375  0.01152344 0.11025391 0.00078125 0.04150391\n",
      " 0.08544922 0.0734375  0.02509766 0.08779297 0.00078125 0.00341797\n",
      " 0.09277344 0.09580078 0.0015625  0.00097656 0.01328125 0.04130859\n",
      " 0.03798828 0.01875    0.09130859 0.09511719 0.00380859]\n"
     ]
    }
   ],
   "source": [
    "print (count_samples(balanced_ds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
