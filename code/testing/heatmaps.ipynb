{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with custom resnet\n",
    "https://gist.github.com/RaphaelMeudec/e9a805fa82880876f8d89766f0690b54"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "IMAGE_PATH = './cat.jpg'\n",
    "LAYER_NAME = 'block5_conv3'\n",
    "CAT_CLASS_INDEX = 281\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img(IMAGE_PATH, target_size=(224, 224))\n",
    "img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "model = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=True)\n",
    "\n",
    "grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(LAYER_NAME).output, model.output])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    conv_outputs, predictions = grad_model(np.array([img]))\n",
    "    loss = predictions[:, CAT_CLASS_INDEX]\n",
    "\n",
    "output = conv_outputs[0]\n",
    "grads = tape.gradient(loss, conv_outputs)[0]\n",
    "\n",
    "gate_f = tf.cast(output > 0, 'float32')\n",
    "gate_r = tf.cast(grads > 0, 'float32')\n",
    "guided_grads = tf.cast(output > 0, 'float32') * tf.cast(grads > 0, 'float32') * grads\n",
    "\n",
    "weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
    "\n",
    "cam = np.ones(output.shape[0: 2], dtype = np.float32)\n",
    "\n",
    "for i, w in enumerate(weights):\n",
    "    cam += w * output[:, :, i]\n",
    "\n",
    "cam = cv2.resize(cam.numpy(), (224, 224))\n",
    "cam = np.maximum(cam, 0)\n",
    "heatmap = (cam - cam.min()) / (cam.max() - cam.min())\n",
    "\n",
    "cam = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "\n",
    "output_image = cv2.addWeighted(cv2.cvtColor(img.astype('uint8'), cv2.COLOR_RGB2BGR), 0.5, cam, 1, 0)\n",
    "\n",
    "cv2.imwrite('cam.png', output_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixed to custom ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "IMAGE_PATH = './cat.jpg'\n",
    "LAYER_NAME = 'conv5_block3_3_conv'\n",
    "CAT_CLASS_INDEX = 22\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img(IMAGE_PATH, target_size=(224, 224))\n",
    "img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "\n",
    "\n",
    "def build_model(output_size, input_shape=(224, 224, 3), final_activation=\"softmax\"):\n",
    "\n",
    "    base_model = ResNet50(\n",
    "        input_shape=input_shape,\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False\n",
    "    )\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    output = Dense(output_size, activation=final_activation)(x)\n",
    "    \n",
    "    return Model(outputs=output, inputs=base_model.input)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = build_model(output_size = 23)\n",
    "\n",
    "\n",
    "grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(\"conv5_block3_3_conv\").output, model.output])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    conv_outputs, predictions = grad_model(np.array([img]))\n",
    "    loss = predictions[:, CAT_CLASS_INDEX]\n",
    "\n",
    "output = conv_outputs[0]\n",
    "grads = tape.gradient(loss, conv_outputs)[0]\n",
    "\n",
    "gate_f = tf.cast(output > 0, 'float32')\n",
    "gate_r = tf.cast(grads > 0, 'float32')\n",
    "guided_grads = tf.cast(output > 0, 'float32') * tf.cast(grads > 0, 'float32') * grads\n",
    "\n",
    "weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
    "\n",
    "cam = np.ones(output.shape[0: 2], dtype = np.float32)\n",
    "\n",
    "for i, w in enumerate(weights):\n",
    "    cam += w * output[:, :, i]\n",
    "\n",
    "cam = cv2.resize(cam.numpy(), (224, 224))\n",
    "cam = np.maximum(cam, 0)\n",
    "heatmap = (cam - cam.min()) / (cam.max() - cam.min())\n",
    "\n",
    "cam = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "\n",
    "output_image = cv2.addWeighted(cv2.cvtColor(img.astype('uint8'), cv2.COLOR_RGB2BGR), 0.5, cam, 1, 0)\n",
    "\n",
    "cv2.imwrite('cam.png', output_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried something but it didnt work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import models\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 21s 0us/step\n",
      "(1, 14, 14)\n"
     ]
    }
   ],
   "source": [
    "image_size = 224\n",
    "\n",
    "# Load pre-trained Keras model and the image to classify\n",
    "model = tf.keras.applications.vgg16.VGG16()\n",
    "image = np.random.random((image_size, image_size, 3))\n",
    "img_tensor = preprocessing.image.img_to_array(image)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "img_tensor = preprocess_input(img_tensor)\n",
    "\n",
    "conv_layer = model.get_layer(\"block5_conv3\")\n",
    "heatmap_model = models.Model([model.inputs], [conv_layer.output, model.output])\n",
    "\n",
    "# Get gradient of the winner class w.r.t. the output of the (last) conv. layer\n",
    "with tf.GradientTape() as gtape:\n",
    "    conv_output, predictions = heatmap_model(img_tensor)\n",
    "    loss = predictions[:, np.argmax(predictions[0])]\n",
    "    grads = gtape.gradient(loss, conv_output)\n",
    "    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_output), axis=-1)\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "max_heat = np.max(heatmap)\n",
    "if max_heat == 0:\n",
    "    max_heat = 1e-10\n",
    "heatmap /= max_heat\n",
    "\n",
    "print(heatmap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 13.5, 13.5, -0.5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(heatmap[-1])\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/gabrieldemarmiesse/heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/henrik/master_thesis/code/testing/data/meta_clsloc.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/TF2/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/henrik/master_thesis/code/testing/data/meta_clsloc.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-338c45339ee0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mheatmap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_heatmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynset_to_dfs_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/master_thesis/code/testing/heatmap.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmeta_clsloc_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"meta_clsloc.mat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0msynsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_clsloc_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"synsets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m synsets_imagenet_sorted = sorted([(int(s[0]), str(s[1][0])) for s in synsets[:1000]],\n",
      "\u001b[0;32m~/anaconda3/envs/TF2/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \"\"\"\n\u001b[1;32m    215\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF2/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF2/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF2/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reader needs file name or open file-like object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/henrik/master_thesis/code/testing/data/meta_clsloc.mat'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "\n",
    "from heatmap import to_heatmap, synset_to_dfs_ids\n",
    "\n",
    "\n",
    "def display_heatmap(new_model, img_path, ids, preprocessing=None):\n",
    "    # The quality is reduced.\n",
    "    # If you have more than 8GB of RAM, you can try to increase it.\n",
    "    img = image.load_img(img_path, target_size=(800, 1280))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    if preprocessing is not None:\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "    out = new_model.predict(x)\n",
    "\n",
    "    heatmap = out[0]  # Removing batch axis.\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        heatmap = heatmap[ids]\n",
    "        if heatmap.ndim == 3:\n",
    "            heatmap = np.sum(heatmap, axis=0)\n",
    "    else:\n",
    "        heatmap = heatmap[:, :, ids]\n",
    "        if heatmap.ndim == 3:\n",
    "            heatmap = np.sum(heatmap, axis=2)\n",
    "\n",
    "    plt.imshow(heatmap, interpolation=\"none\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
