{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kvasir dataset split into neg/pos and trained using Resnet50 without augmentation. Getting some decent results after training on resampled data with large step-size.  \n",
    "- Class weighting  \n",
    "- Resampling  \n",
    "- Initial Bias-estimation\n",
    "- Decreasing learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Some stuff to make utils-function work\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "from data_prep import create_dataset, print_class_info, show_image\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Jupyter-specific\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10662\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "data_dir = pathlib.Path('/mnt/sdb/hyper-kvasir/labeled/')\n",
    "\n",
    "image_count = len(list(data_dir.glob('*/*.*g')))\n",
    "print (image_count)\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "IMG_HEIGHT = 64\n",
    "IMG_WIDTH = 64\n",
    "num_classes = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array([item.name for item in data_dir.glob('*') if item.name != '*.txt'])\n",
    "\n",
    "# Create a dataset of the file paths\n",
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A short pure-tensorflow function that converts a file path to an `image_data, label` pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # get class integer from class-list\n",
    "    label_int = tf.reduce_min(tf.where(tf.equal(parts[-2], class_names)))\n",
    "    # cast to tensor array with dtype=uint8\n",
    "    return tf.dtypes.cast(label_int, tf.int32)\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label\n",
    "\n",
    "# Set 'num_parallel_calls' so multiple images are loaded and processed in parallel\n",
    "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset for training\n",
    "Want the data to be shuffled and batched. Here we use the `tf.data` api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
    "    # This is a small dataset, only load it once, and keep it in memory.\n",
    "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "    # fit in memory.\n",
    "    if cache:\n",
    "      if isinstance(cache, str):\n",
    "        ds = ds.cache(cache)\n",
    "      else:\n",
    "        ds = ds.cache()\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    # Repeat forever\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return ds\n",
    "\n",
    "train_ds = prepare_for_training(labeled_ds, cache=\"./cache/resampler_64.tfcache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(counts, batch):\n",
    "    images, labels = batch\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        counts['class_{}'.format(i)] += tf.reduce_sum(tf.cast(labels == i, tf.int32))\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00058594 0.00400391 0.03837891 0.02441406 0.00341797 0.00498047\n",
      " 0.09404297 0.09345703 0.03720703 0.04072266 0.01865234 0.10751953\n",
      " 0.06074219 0.00087891 0.07216797 0.08730469 0.00263672 0.01191406\n",
      " 0.09580078 0.09355469 0.09423828 0.01240234 0.00097656]\n"
     ]
    }
   ],
   "source": [
    "# Set the initial states\n",
    "initial_state = {}\n",
    "for i in range(num_classes):\n",
    "    initial_state['class_{}'.format(i)] = 0\n",
    "\n",
    "# Count samples\n",
    "counts = train_ds.take(10).reduce(\n",
    "    initial_state = initial_state,\n",
    "    reduce_func = count)\n",
    "\n",
    "\n",
    "final_counts = []\n",
    "for class_, value in counts.items():\n",
    "    final_counts.append(value.numpy().astype(np.float32))\n",
    "\n",
    "final_counts = np.asarray(final_counts)\n",
    "\n",
    "fractions = final_counts/final_counts.sum()\n",
    "print(fractions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling - dataset as two different tf.data datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for i in range(num_classes):\n",
    "    ds = train_ds.unbatch().filter(lambda image, label: label==i).repeat()\n",
    "    datasets.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "for image, label in datasets[2].batch(10).take(1):\n",
    "    print (label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_ds = tf.data.experimental.sample_from_datasets(datasets, target_dist).batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7 21  3  3  4 17  2  7 19  6]\n",
      "[ 1 13 13 14 17  0 21 20 14 22]\n",
      "[13  6  7 14  7 17  8  1 12  2]\n",
      "[15  3 14 20  1 14 17  5  6 12]\n",
      "[22  4 17  9 20  9  7  7 20 22]\n",
      "[ 5 22  6  0 11 16 14  7  9  4]\n",
      "[12 15  5 18  3 12 16  2  7 14]\n",
      "[ 6  7 11  2  4 21 14 18 12  8]\n",
      "[21 11 20  7  5 21  6 10  4  1]\n",
      "[ 9  8  1 14  9  8  6  9  9 12]\n"
     ]
    }
   ],
   "source": [
    "for images, labels in balanced_ds.take(10):\n",
    "    print (labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03666667 0.04       0.07666667 0.06333333 0.06       0.03333334\n",
      " 0.04666667 0.05333333 0.04       0.04333333 0.02333333 0.03666667\n",
      " 0.04333333 0.03333334 0.06       0.04666667 0.03666667 0.03\n",
      " 0.03       0.03       0.05333333 0.04333333 0.04      ]\n"
     ]
    }
   ],
   "source": [
    "initial_state = {}\n",
    "for i in range(num_classes):\n",
    "    initial_state['class_{}'.format(i)] = 0\n",
    "\n",
    "counts = balanced_ds.take(30).reduce(\n",
    "    initial_state = initial_state,\n",
    "    reduce_func = count)\n",
    "\n",
    "\n",
    "final_counts = []\n",
    "for class_, value in counts.items():\n",
    "    final_counts.append(value.numpy().astype(np.float32))\n",
    "\n",
    "final_counts = np.asarray(final_counts)\n",
    "\n",
    "fractions = final_counts/final_counts.sum()\n",
    "print (fractions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rejection resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_func(image, label):\n",
    "    return tf.cast(label, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dist = []\n",
    "for i in range(num_classes):\n",
    "    target_dist.append(1.0/num_classes)\n",
    "\n",
    "resampler = tf.data.experimental.rejection_resample(\n",
    "            class_func, #=lambda features, label: label, \n",
    "            target_dist=target_dist,\n",
    "            initial_dist=fractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_ds = train_ds.unbatch().apply(resampler).batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([14 11 15 12 15 18 11 15  8  7], shape=(10,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Testing cell\n",
    "for labels_resampled, img_and_label in resample_ds.take(1):\n",
    "    print(img_and_label[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4098, shape=(10,), dtype=int32, numpy=array([ 8,  0, 14, 18, 21, 15,  8, 16,  6,  1], dtype=int32)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4100, shape=(10,), dtype=int32, numpy=array([14, 11, 15, 12, 15, 18, 11, 15,  8,  7], dtype=int32)>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_and_label[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_ds = resample_ds.map(lambda extra_label, img_and_label: img_and_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18  6 12 20  9 12 11 15  3 15]\n",
      "[18 20 20  9  1  7 12  7 12 14]\n",
      "[15 18 20  9  8 11 19  7 11 15]\n",
      "[ 7 19  6  6 18 20 15  6 18  6]\n",
      "[19 18 15 20  3  6 11 19 18 15]\n",
      "[19 20 12 21 21 12 11  6 14 11]\n",
      "[16 19  8 15 15 11 15  3  3  7]\n",
      "[14 19 12 20 14 18 20  6 20 18]\n",
      "[19  6 15 11 11  7  6  9 15 11]\n",
      "[14 15 12 11  2 14  9 15  3  1]\n"
     ]
    }
   ],
   "source": [
    "for images, labels in balanced_ds.take(10):\n",
    "    print(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(counts, batch):\n",
    "    images, labels = batch\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        counts['class_{}'.format(i)] += tf.reduce_sum(tf.cast(labels == i, tf.int32))\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04666667 0.04666667 0.03666667 0.04333333 0.06333333 0.05\n",
      " 0.04       0.04       0.05       0.03666667 0.04       0.04666667\n",
      " 0.05       0.05       0.03333334 0.02333333 0.04333333 0.04\n",
      " 0.04       0.03333334 0.05666667 0.05666667 0.03333334]\n"
     ]
    }
   ],
   "source": [
    "initial_state = {}\n",
    "for i in range(num_classes):\n",
    "    initial_state['class_{}'.format(i)] = 0\n",
    "\n",
    "counts = balanced_ds.take(30).reduce(\n",
    "    initial_state = initial_state,\n",
    "    reduce_func = count)\n",
    "\n",
    "\n",
    "final_counts = []\n",
    "for class_, value in counts.items():\n",
    "    final_counts.append(value.numpy().astype(np.float32))\n",
    "\n",
    "final_counts = np.asarray(final_counts)\n",
    "\n",
    "fractions = final_counts/final_counts.sum()\n",
    "print(fractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
