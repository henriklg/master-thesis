{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to create a student-teacher model where we first train a teacher on labeled data, and then use this teacher model to label more data, then we swap out the teacher with a student and train again over all the samples. \n",
    "- Try AutoAugment/RandAugment\n",
    "- Add regularization\n",
    "- Resampling  \n",
    "  - Make resampling func for unlab_ds\n",
    "- Create evaluation script\n",
    "- Create new unlab_ds without previous findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# Some stuff to make utils-function work\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "from data_prep_ttv import create_dataset, prepare_for_training\n",
    "from utils import show_image, class_distribution\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Jupyter-specific\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('/home/henrik/master-thesis/data/hyper-kvasir/labeled_split/')\n",
    "\n",
    "conf = {\n",
    "    # Dataset\n",
    "    \"data_dir\": data_dir,\n",
    "    \"cache_dir\": \"./cache\",\n",
    "    \"ds_info\": 'hypkva',\n",
    "    \"augment\": [\"rotate\",\"crop\",\"flip\",\"brightness\",\"saturation\",\"contrast\"],\n",
    "    \"resample\": True,\n",
    "    \"class_weight\": False,\n",
    "    \"shuffle_buffer_size\": 2000,        # 0=no shuffling\n",
    "    \"seed\": 123,\n",
    "    \"neg_class\": None,                 # select neg class for binary ds (normal class)\n",
    "    \"outcast\": None,                   # list of folders to drop\n",
    "    # Model\n",
    "    \"model\": 'EfficientNetB0',\n",
    "    \"num_epochs\": 40,\n",
    "    \"batch_size\": 128,\n",
    "    \"img_shape\": (128, 128, 3),\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"optimizer\": 'Adam',\n",
    "    \"final_activation\": 'softmax',\n",
    "    # Callbacks\n",
    "    \"learning_schedule\": True,\n",
    "    \"decay_rate\": 0.15,                 # higher number gives steeper dropoff\n",
    "    \"checkpoint\": False,\n",
    "    \"early_stopping\": True,\n",
    "    \"early_stopping_patience\": 5,\n",
    "    # Misc\n",
    "    \"verbosity\": 1\n",
    "    }\n",
    "\n",
    "model_name = '{}x{}x{}_{}_{}'.format(conf[\"num_epochs\"], conf[\"batch_size\"], \n",
    "                                     conf[\"img_shape\"][1], conf[\"ds_info\"], conf[\"model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training, testing and validation dataset from utils/data_prep.py.  \n",
    "Returns tf.dataset for shuffled, cached and batched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "barretts-short-segment      :   53 | 0.50%\n",
      "bbps-0-1                    :  646 | 6.06%\n",
      "impacted-stool              :  131 | 1.23%\n",
      "bbps-2-3                    : 1148 | 10.77%\n",
      "hemorrhoids                 :    6 | 0.06%\n",
      "ulcerative-colitis-grade-2  :  443 | 4.15%\n",
      "normal-z-line               :  932 | 8.74%\n",
      "retroflex-stomach           :  764 | 7.17%\n",
      "esophagitis-b-d             :  260 | 2.44%\n",
      "dyed-resection-margins      :  989 | 9.28%\n",
      "ileum                       :    9 | 0.08%\n",
      "ulcerative-colitis-0-1      :   35 | 0.33%\n",
      "dyed-lifted-polyps          : 1002 | 9.40%\n",
      "polyps                      : 1028 | 9.64%\n",
      "ulcerative-colitis-2-3      :   28 | 0.26%\n",
      "ulcerative-colitis-1-2      :   11 | 0.10%\n",
      "ulcerative-colitis-grade-3  :  133 | 1.25%\n",
      "retroflex-rectum            :  391 | 3.67%\n",
      "esophagitis-a               :  403 | 3.78%\n",
      "ulcerative-colitis-grade-1  :  201 | 1.89%\n",
      "pylorus                     :  999 | 9.37%\n",
      "cecum                       : 1009 | 9.46%\n",
      "barretts                    :   41 | 0.38%\n",
      "\n",
      "Total number of images: 10662, in 23 classes.\n",
      "\n",
      "Dataset split: [7454, 1598, 1610]\n",
      "/home/henrik/master-thesis/data/hyper-kvasir/labeled_split/train/*/*.*g\n",
      "/home/henrik/master-thesis/data/hyper-kvasir/labeled_split/test/*/*.*g\n",
      "/home/henrik/master-thesis/data/hyper-kvasir/labeled_split/val/*/*.*g\n",
      "\n",
      "\n",
      "---- Ratios before resampling ---- \n",
      "[0.00496378 0.06063858 0.01220821 0.10772739 0.00053662 0.04158841\n",
      " 0.08746982 0.07163939 0.02441642 0.09283606 0.00080494 0.00321975\n",
      " 0.09404346 0.09645828 0.00254897 0.00093909 0.01247652 0.03662463\n",
      " 0.03783204 0.01878186 0.09377515 0.09471425 0.00375637]\n",
      "\n",
      "---- Ratios after resampling ----\n",
      "[0.04628387 0.04641803 0.04641803 0.04212504 0.04762544 0.04534478\n",
      " 0.04185672 0.04225919 0.04024685 0.04360075 0.04266166 0.03944191\n",
      " 0.04360075 0.04078347 0.03971022 0.04118594 0.04373491 0.04494231\n",
      " 0.04199088 0.04588141 0.04521063 0.04078347 0.04789375]\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds, val_ds, params = create_dataset(conf)\n",
    "\n",
    "train_steps = params[\"train_size\"] // conf[\"batch_size\"]\n",
    "test_steps = params[\"test_size\"] // conf[\"batch_size\"]\n",
    "val_steps = params[\"val_size\"] // conf[\"batch_size\"]\n",
    "class_names = params[\"class_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00496378 0.06063858 0.01220821 0.10772739 0.00053662 0.04158841\n",
      " 0.08746982 0.07163939 0.02441642 0.09283606 0.00080494 0.00321975\n",
      " 0.09404346 0.09645828 0.00254897 0.00093909 0.01247652 0.03662463\n",
      " 0.03783204 0.01878186 0.09377515 0.09471425 0.00375637]\n"
     ]
    }
   ],
   "source": [
    "dist, _ = class_distribution(train_ds.unbatch().take(params[\"train_size\"]), 23)\n",
    "print (dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import print_split_info\n",
    "\n",
    "ds = {\"train\": train_ds.unbatch().take(params[\"train_size\"]),\n",
    "      \"test\": test_ds.unbatch().take(params[\"test_size\"]),\n",
    "      \"val\": val_ds.unbatch().take(params[\"val_size\"])}\n",
    "\n",
    "# NB: this will cache the whole dataset\n",
    "print_split_info(ds, conf, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Show some images from training dataset (mainly to check augmentation)\n",
    "batch = next(iter(train_ds))\n",
    "images, labels = batch\n",
    "images = images.numpy()\n",
    "\n",
    "nrows, ncols = 3, 4  # array of sub-plots\n",
    "figsize = [ncols*3, nrows*3]     # figure size, inches\n",
    "\n",
    "# create figure (fig), and array of axes (ax)\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, \n",
    "                       figsize=figsize, frameon=False, facecolor='white')\n",
    "\n",
    "# plot simple raster image on each sub-plot\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    # i runs from 0 to (nrows*ncols-1)\n",
    "    # axi is equivalent with ax[rowid][colid]\n",
    "    img = images[i]\n",
    "    axi.imshow(img)\n",
    "    # get indices of row/column\n",
    "    rowid = i // ncols\n",
    "    colid = i % ncols\n",
    "    # write row/col indices as axes' title for identification\n",
    "    #axi.set_title(\"Row:\"+str(rowid)+\", Col:\"+str(colid))\n",
    "    axi.set_axis_off()\n",
    "\n",
    "plt.axis('off')\n",
    "plt.tight_layout(True)\n",
    "# plt.savefig(\"{}/unlab_data_checkout-{}.pdf\".format(log_dir, checkout), format='pdf')\n",
    "plt.show()\n",
    "\n",
    "print (\"time:\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Train a teacher model on labeled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conf[\"model\"] == 'EfficientNetB0': \n",
    "    from efficientnet import EfficientNetB0 as EfficientNet # 5.3M params\n",
    "elif conf[\"model\"] == 'EfficientNetB1': \n",
    "    from efficientnet import EfficientNetB1 as EfficientNet # 7.8M params\n",
    "elif conf[\"model\"] == 'EfficientNetB2':\n",
    "    from efficientnet import EfficientNetB2 as EfficientNet # 9.2M params\n",
    "elif conf[\"model\"] == 'EfficientNetB3':\n",
    "    from efficientnet import EfficientNetB3 as EfficientNet # 12M params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_base = EfficientNet(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False, \n",
    "    input_shape=conf[\"img_shape\"]\n",
    ")\n",
    "\n",
    "# Unfreeze the layers. I.E we're just using the pre-trained weights as initial weigths and biases and train over them\n",
    "efficientnet_base.trainable = True\n",
    "\n",
    "\n",
    "# # Define model\n",
    "# teacher_model = Sequential()\n",
    "# teacher_model.add(efficientnet_base)\n",
    "# teacher_model.add(layers.GlobalAveragePooling2D())\n",
    "# teacher_model.add(layers.Dropout(0.3))\n",
    "# teacher_model.add(layers.Dense(512, activation='relu'))\n",
    "# teacher_model.add(layers.Dropout(0.3))\n",
    "# teacher_model.add(layers.Dense(params[\"num_classes\"], activation=conf[\"final_activation\"]))\n",
    "\n",
    "from keras import regularizers\n",
    "# Define model\n",
    "teacher_model = Sequential()\n",
    "teacher_model.add(efficientnet_base)\n",
    "teacher_model.add(layers.GlobalAveragePooling2D())\n",
    "teacher_model.add(layers.Dropout(0.2))\n",
    "teacher_model.add(layers.Dense(512, kernel_regularizer=regularizers.l2(0.001),\n",
    "                               activation='relu'))\n",
    "teacher_model.add(layers.Dropout(0.2))\n",
    "teacher_model.add(layers.Dense(512, kernel_regularizer=regularizers.l2(0.001),\n",
    "                               activation='relu'))\n",
    "teacher_model.add(layers.Dropout(0.2))\n",
    "teacher_model.add(layers.Dense(512, kernel_regularizer=regularizers.l2(0.001),\n",
    "                               activation='relu'))\n",
    "teacher_model.add(layers.Dropout(0.2))\n",
    "teacher_model.add(layers.Dense(params[\"num_classes\"], activation=conf[\"final_activation\"]))\n",
    "\n",
    "if conf['optimizer'] == 'Adam':\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=conf[\"learning_rate\"])\n",
    "elif conf['optimizer'] == 'SGD':\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=conf[\"learning_rate\"])\n",
    "\n",
    "teacher_model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")\n",
    "\n",
    "teacher_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, LearningRateScheduler\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By using LearnignRateScheduler\n",
    "initial_learning_rate = conf[\"learning_rate\"]\n",
    "decay_steps = params[\"train_size\"] // conf[\"batch_size\"]\n",
    "batch_size = conf['batch_size']\n",
    "decay_rate = conf['decay_rate']\n",
    "\n",
    "def schedule(epoch):\n",
    "    # calculate new learning rate\n",
    "    learning_rate = initial_learning_rate / (1 + decay_rate * (epoch*batch_size) / decay_steps)\n",
    "    \n",
    "    # update tensorboard\n",
    "    tf.summary.scalar(name='learning_rate', data=learning_rate, step=epoch)\n",
    "    return learning_rate\n",
    "\n",
    "log_dir=\"./logs/{}/\".format(conf[\"model\"]) + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
    "file_writer.set_as_default()\n",
    "\n",
    "lr_schedule_cb = LearningRateScheduler(schedule, verbose=1)\n",
    "earlystopp_cb = EarlyStopping(monitor='val_loss', \n",
    "                              verbose=1, patience=conf[\"early_stopping_patience\"], \n",
    "                              restore_best_weights=True)\n",
    "checkpoint_cb = ModelCheckpoint(filepath='./models/best_cp-{epoch:03d}.hdf', \n",
    "                                monitor='val_loss', save_best_only=True, mode='auto')\n",
    "tensorboard_cb = TensorBoard(log_dir=log_dir, update_freq='batch')\n",
    "\n",
    "callbacks = [tensorboard_cb]\n",
    "if conf[\"early_stopping\"]: callbacks.append(earlystopp_cb)\n",
    "if conf[\"learning_schedule\"]: callbacks.append(lr_schedule_cb)\n",
    "if conf[\"checkpoint\"]: callbacks.append(checkpoint_cb)\n",
    "\n",
    "# Write conf dictionary to text file\n",
    "f = open(log_dir+\"/conf.txt\",\"w\")\n",
    "f.write(str(conf))\n",
    "f.close()\n",
    "\n",
    "# Write params dictionary to text file\n",
    "f = open(log_dir+\"/params.txt\",\"w\")\n",
    "f.write(str(params))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = None\n",
    "\n",
    "if conf[\"class_weight\"]:\n",
    "    assert not conf[\"resample\"], \"Should only use resample or class_weight. Not both.\"\n",
    "    \n",
    "    from utils import calculate_weights\n",
    "\n",
    "    class_weights = calculate_weights(\n",
    "        train_ds.unbatch().take(params[\"train_size\"]), \n",
    "        num_classes=params[\"num_classes\"]\n",
    "    )\n",
    "\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "    print (\"Class weights:\")\n",
    "    print (class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the teacher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "try: \n",
    "    history = teacher_model.fit(\n",
    "        train_ds,\n",
    "        steps_per_epoch = train_steps,\n",
    "        epochs = conf[\"num_epochs\"],\n",
    "        validation_data = test_ds,\n",
    "        validation_steps = test_steps,\n",
    "        validation_freq = 1,\n",
    "        class_weight = class_weights,\n",
    "        callbacks = callbacks,\n",
    "        verbose = 1\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    print (\"exiting\")\n",
    "    \n",
    "finally:\n",
    "    print (\"Time spent on training: {}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the metrics from training\n",
    "f = open(log_dir+\"/history.txt\",\"w\")\n",
    "f.write(str(history.history))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save or restore a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "best_acc =  str(history.history[\"val_sparse_categorical_accuracy\"][-1])[2:4]\n",
    "teacher_model.save(log_dir+'/{}.h5'.format(model_name+'_'+best_acc))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Load a previously saved model\n",
    "time = \"20200424-222542\"\n",
    "log_dir = \"./logs/{}/\".format(conf[\"model\"]) + time\n",
    "teacher_model = load_model(log_dir + \"/30x128x128_hyp-kva-aug_EfficientNetB0_82.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if validation data is cached\n",
    "cache_dir = conf[\"cache_dir\"]\n",
    "img_width = conf[\"img_shape\"][0]\n",
    "ds_info = conf[\"ds_info\"]\n",
    "filename = \"{}/{}_{}_val.tfcache.index\".format(cache_dir, img_width, ds_info)\n",
    "\n",
    "cached = os.path.isfile(filename)\n",
    "if not cached:\n",
    "    # Iterate over dataset to initialize caching\n",
    "    for batch in val_ds.take( (params[\"val_size\"]//conf[\"batch_size\"])+1 ):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_evaluate = teacher_model.evaluate(val_ds, verbose=2, steps=val_steps)\n",
    "\n",
    "# Write evaluate dictionary to text file\n",
    "f = open(log_dir+\"/val_evaluate.txt\",\"w\")\n",
    "f.write( str(teacher_evaluate) )\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['sparse_categorical_accuracy']\n",
    "val_acc = history.history['val_sparse_categorical_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "if conf[\"learning_schedule\"]: lr = history.history['lr']\n",
    "epochs_range = range(history.epoch[-1]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conf[\"learning_schedule\"]:\n",
    "    # Plot the learning rate\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(epochs_range, lr, label='Learning Rate')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learnign rate')\n",
    "    plt.title('Learning Rate development during training');\n",
    "    plt.savefig(log_dir+'/learning_rate.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train-val accuracy and loss\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Subplot 1\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "# plt.ylim([0.5, 1])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# Subplot 2\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylim([0.0, 3])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.savefig(log_dir+'/accuracy_and_loss.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: run prediction on images from the validation dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Take one batch of validation data\n",
    "images, labels = next(iter(val_ds))\n",
    "\n",
    "# Take random image of batch and convert it to numpy\n",
    "idx = np.random.randint(0, conf[\"batch_size\"])\n",
    "img = images.numpy()[idx]\n",
    "lab = labels.numpy()[idx]\n",
    "\n",
    "print (\"label:\", class_names[lab], end='\\n\\n')\n",
    "show_image(img)\n",
    "\n",
    "# Add one dimension\n",
    "img = np.expand_dims(img, 0)\n",
    "prediction = teacher_model.predict(img, verbose=0)\n",
    "for i, pred in enumerate(prediction[0]):\n",
    "    if pred > 0.01: print(\"{:>5.2f}% {}\".format(pred*100, class_names[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: run prediction on images from the unlabeled_test dataset\n",
    "(which are images taken from the training data)  \n",
    "TODO: just remove this?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "def get_filename(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # the last item of parts is the filename\n",
    "    filename = parts[-1]\n",
    "    return filename\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [conf[\"img_shape\"][0], conf[\"img_shape\"][1] ])\n",
    "\n",
    "def process_path(file_path):\n",
    "    filename = get_filename(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, filename\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "data_dir_unlabeled_test = pathlib.Path('/home/henrik/master-thesis/data/hyper-kvasir/unlabeled-test/')\n",
    "\n",
    "ds_size_unlabeled_test = len(list(data_dir_unlabeled_test.glob('*.*g')))\n",
    "\n",
    "files_string = str(data_dir_unlabeled_test/'*.*g')\n",
    "list_ds_unlabeled_test = tf.data.Dataset.list_files(\n",
    "            files_string,\n",
    "            shuffle=conf[\"shuffle_buffer_size\"]>1, \n",
    "            seed=tf.constant(conf[\"seed\"], tf.int64)\n",
    ")\n",
    "\n",
    "unlabeled_ds_test = list_ds_unlabeled_test.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Print some images and confidence levels to see how to model performs\n",
    "# Take one image of unlabeled-test set\n",
    "img, name = next(iter(unlabeled_ds_test))\n",
    "\n",
    "print (\"Filename:\", str(name.numpy())[2:-1])\n",
    "print (\"Label:\", str(name.numpy())[38:-5])\n",
    "show_image(img.numpy())\n",
    "\n",
    "# add dimension and predict\n",
    "img = np.expand_dims(img.numpy(), 0)\n",
    "prediction = teacher_model.predict(img, verbose=0)\n",
    "\n",
    "print ()\n",
    "for i, pred in enumerate(prediction[0]):\n",
    "    if pred > 0.01: print(\"{:>5.2f}% {}\".format(pred*100, class_names[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: use the teacher to generate pseudo labels on unlabeled images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the unlabeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # the last item of parts is the filename\n",
    "    filename = parts[-1]\n",
    "    return filename\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img) # had to remove channels=3 paramter..\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [conf[\"img_shape\"][0], conf[\"img_shape\"][1] ])\n",
    "\n",
    "def process_path(file_path):\n",
    "    filename = get_filename(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "data_dir_unlabeled = pathlib.Path('/home/henrik/master-thesis/data/hyper-kvasir/unlabeled_resized/')\n",
    "\n",
    "ds_size_unlabeled = len(list(data_dir_unlabeled.glob('*.*g')))\n",
    "\n",
    "files_string = str(data_dir_unlabeled/'*.*g')\n",
    "list_ds_unlabeled = tf.data.Dataset.list_files(\n",
    "        files_string, \n",
    "        shuffle=conf[\"shuffle_buffer_size\"]>1, \n",
    "        seed=tf.constant(conf[\"seed\"], tf.int64)\n",
    ")\n",
    "\n",
    "unlabeled_ds = list_ds_unlabeled.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "print (\"Loaded {} images into unlabeled_ds.\".format(ds_size_unlabeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run prediction on 1 image\n",
    "#img, name = next(iter(unlabeled_ds))\n",
    "\n",
    "for img, name in unlabeled_ds.take(1):\n",
    "\n",
    "    print (\"File:\",str(name.numpy())[2:-1], end='\\n\\n')\n",
    "    show_image(img.numpy())\n",
    "\n",
    "    # Add dimension and predict\n",
    "    img = np.expand_dims(img.numpy(), 0)\n",
    "    prediction = teacher_model.predict(img, verbose=0)\n",
    "\n",
    "    # If probability above 1% print info\n",
    "    for i, pred in enumerate(prediction[0]):\n",
    "         if pred > 0.01: print(\"{:>5.2f}% {}\".format(pred*100, class_names[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run predictions on all unlabeled images\n",
    "Using 'append to list and convert to tensor'-method\n",
    "- caching the dataset takes too much space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pred_confidence = 0.60\n",
    "new_samples_counter = 0\n",
    "count = 0\n",
    "img_list = []\n",
    "lab_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = time.time()\n",
    "\n",
    "tqdm_predicting = tqdm(total=ds_size_unlabeled, desc='Predicting', position=0, initial=count)\n",
    "tqdm_findings = tqdm(total=ds_size_unlabeled, desc='Findings', \n",
    "                     position=1, bar_format='{desc}:{bar}{n_fmt}', initial=new_samples_counter)\n",
    "\n",
    "print (\"Press 'Interrupt Kernel' to save and exit.\")\n",
    "try:\n",
    "    for count, (image,label) in enumerate(unlabeled_ds, start=count):\n",
    "        img = np.expand_dims(image, 0)\n",
    "        pred = teacher_model.predict(img)\n",
    "        highest_pred = np.max(pred)\n",
    "        if highest_pred > pred_confidence:\n",
    "            pred_idx = np.argmax(pred).astype(np.int32)\n",
    "            #pred_class = class_names[pred_idx]\n",
    "\n",
    "            img_list.append(image)\n",
    "            lab_list.append(pred_idx)\n",
    "            # pred_list.append(highest_pred)\n",
    "            \n",
    "            new_samples_counter += 1\n",
    "            tqdm_findings.update(1)\n",
    "        tqdm_predicting.update(1)\n",
    "except KeyboardInterrupt:\n",
    "    print (\"Exiting\")\n",
    "\n",
    "finally:\n",
    "    print (\"\\nTotal run time: {:.3f} s\".format( time.time() - total_time ))\n",
    "    print (\"Found {} new samples in unlabeled_ds after looking at {} images.\".format(new_samples_counter, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the image and labels list as pickle dump"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Dump it as a pickle\n",
    "import pickle\n",
    "\n",
    "with open('{}_lab_list.pkl'.format(conf[\"img_shape\"][0]), 'wb') as f:\n",
    "    pickle.dump(lab_list, f)\n",
    "    \n",
    "with open('{}_img_list.pkl'.format(conf[\"img_shape\"][0]), 'wb') as f:\n",
    "    pickle.dump(img_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make bar chart of findings from unlabeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_array = np.array(lab_list)\n",
    "findings = np.bincount(lab_array, minlength=params[\"num_classes\"])\n",
    "assert len(class_names) == len(findings), \"Must be same length.\"\n",
    "\n",
    "# Settings\n",
    "figsize=(15, 10)\n",
    "# x = findings[:,0]\n",
    "x = np.arange(params[\"num_classes\"])\n",
    "width = 0.5\n",
    "\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "# rects1 = ax.bar(x, findings[:,1], width, label='Findings')\n",
    "rects1 = ax.bar(x, findings, width, label='Findings')\n",
    "#rects2 = ax.bar(x + width/2, women_means, width, label='Women')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Number of samples')\n",
    "ax.set_title(\"Found {} new samples in unlabeled_ds after looking at {} images.\".format(new_samples_counter, count))\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(class_names)\n",
    "ax.set_axisbelow(True)\n",
    "ax.legend()\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=25, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "plt.grid(axis='y')\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(log_dir+'/unlab_data_prediction.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the classified images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create images with class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create images with label names\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import textwrap\n",
    "\n",
    "class_label_img = []\n",
    "font_path = '/usr/share/fonts/truetype/ubuntu/UbuntuMono-B.ttf'\n",
    "# img_width = conf[\"img_shape\"][0]\n",
    "img_width = 512\n",
    "font_size = int(img_width*0.15)\n",
    "# print ('font size:',font_size)\n",
    "letters_per_line = 13\n",
    "\n",
    "for i in range(params[\"num_classes\"]):\n",
    "    img = Image.new('RGB', (img_width, img_width), color = (0, 0, 0))\n",
    "    fnt = ImageFont.truetype(font_path, font_size)\n",
    "    d = ImageDraw.Draw(img)\n",
    "    if (len(class_names[i])>letters_per_line):\n",
    "        text = textwrap.fill(class_names[i], width=letters_per_line)\n",
    "    else:\n",
    "        text = class_names[i]\n",
    "    linebreaks = text.count('\\n')\n",
    "    d.text((1,(img_width//2.2)-linebreaks*img_width*0.1), text, font=fnt, fill=(255, 255, 255))\n",
    "    \n",
    "#     show_image(img)\n",
    "    class_label_img.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list containing 6 images from each predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list[num_classes] with 6 sample images per class\n",
    "# TODO: ADD SHUFFLING\n",
    "\n",
    "# black image\n",
    "img_black = Image.new('RGB', (conf[\"img_shape\"][0], conf[\"img_shape\"][1]), color = (0, 0, 0))\n",
    "\n",
    "class_examples = []\n",
    "for class_idx in range(params[\"num_classes\"]):\n",
    "    curr_list = []\n",
    "    \n",
    "    indekser = np.where(lab_array==class_idx)[0]\n",
    "    for i in range(6):\n",
    "        # get 6 finding images from class_idx-class\n",
    "        # no image - index out of bounds\n",
    "        if not indekser.size > i:\n",
    "            curr_list.append(img_black)\n",
    "        # found image\n",
    "        else:\n",
    "            curr_list.append(img_list[indekser[i]])\n",
    "        \n",
    "    class_examples.append(curr_list)\n",
    "\n",
    "assert (len(class_names)==len(class_examples)), 'must be same length'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the predicted images in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "nrows, ncols = params[\"num_classes\"], 7  # array of sub-plots\n",
    "figsize = [ncols*2, params[\"num_classes\"]*2]     # figure size, inches\n",
    "\n",
    "\n",
    "# create figure (fig), and array of axes (ax)\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, \n",
    "                       figsize=figsize, frameon=False, facecolor='white')\n",
    "\n",
    "# plot simple raster image on each sub-plot\n",
    "try:\n",
    "    for i, axi in enumerate(ax.flat):\n",
    "        # i runs from 0 to (nrows*ncols-1)\n",
    "        # axi is equivalent with ax[rowid][colid]\n",
    "        rowid = i // ncols\n",
    "        colid = i % ncols\n",
    "        \n",
    "        if colid == 0:\n",
    "            img = class_label_img[rowid]\n",
    "        else:\n",
    "            img = class_examples[rowid][colid-1]\n",
    "        axi.imshow(img)\n",
    "        \n",
    "        # write row/col indices as axes' title for identification\n",
    "        #axi.set_title(\"Row:\"+str(rowid)+\", Col:\"+str(colid))\n",
    "        axi.set_axis_off()\n",
    "except IndexError:\n",
    "    pass\n",
    "\n",
    "plt.axis('off')\n",
    "plt.tight_layout(True)\n",
    "plt.savefig(\"{}/unlab_data_checkout-{}.pdf\".format(log_dir, 'all'), format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The class we want to show images from\n",
    "checkout = 'pylorus'\n",
    "# checkout = 'polyps'\n",
    "checkout = 'normal-z-line'\n",
    "\n",
    "# Which class number correspond to that class name\n",
    "idx = np.where(class_names == checkout)[0][0]\n",
    "# List of img_list-indexes with images corresponding to that class number\n",
    "idx_list = np.where(lab_list == idx)[0]\n",
    "\n",
    "# This should be a function\n",
    "\n",
    "# settings\n",
    "nrows, ncols = 4, 6  # array of sub-plots\n",
    "figsize = [15, 10]     # figure size, inches\n",
    "\n",
    "\n",
    "# create figure (fig), and array of axes (ax)\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, \n",
    "                       figsize=figsize, frameon=False, facecolor='white')\n",
    "\n",
    "# plot simple raster image on each sub-plot\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    # i runs from 0 to (nrows*ncols-1)\n",
    "    # axi is equivalent with ax[rowid][colid]\n",
    "    img = img_list[idx_list[i]]\n",
    "    axi.imshow(img)\n",
    "    # get indices of row/column\n",
    "    rowid = i // ncols\n",
    "    colid = i % ncols\n",
    "    # write row/col indices as axes' title for identification\n",
    "    #axi.set_title(\"Row:\"+str(rowid)+\", Col:\"+str(colid))\n",
    "    axi.set_axis_off()\n",
    "\n",
    "plt.axis('off')\n",
    "plt.tight_layout(True)\n",
    "plt.savefig(\"{}/unlab_data_checkout-{}.pdf\".format(log_dir, checkout), format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert image and label lists to tensors and combine with training_ds to create a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findings_tensor = tf.data.Dataset.from_tensor_slices((img_list, lab_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine with old ds\n",
    "combined_ds = train_ds.unbatch().take(params[\"train_size\"]).concatenate(findings_tensor)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print (\"Training dataset size:\", params[\"train_size\"])\n",
    "\n",
    "# Careful! This might crash if dataset is too large\n",
    "num_elements = new_train_ds.reduce(0, lambda x, _: x + 1).numpy()\n",
    "print (\"New size:\", num_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Train a student model on the combination of labeled images and pseudo labeled images\n",
    "\n",
    "Now we have trained a teacher model, and used that model to predict on unlabeled dataset to create more samples with psudo-labels.  \n",
    "It's time for swapping the teacher with the student!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_ds = prepare_for_training(\n",
    "        combined_ds, \n",
    "        conf[\"batch_size\"], \n",
    "        cache=None,\n",
    "        shuffle_buffer_size=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the layers. I.E we're just using the pre-trained weights as initial weigths and biases and train over them\n",
    "efficientnet_base.trainable = True\n",
    "\n",
    "# Define model\n",
    "stud_model = Sequential()\n",
    "stud_model.add(efficientnet_base)\n",
    "stud_model.add(layers.GlobalAveragePooling2D())\n",
    "# add Dense layer and dropout?\n",
    "stud_model.add(layers.Dense(params[\"num_classes\"], activation=conf[\"final_activation\"]))\n",
    "\n",
    "if conf['optimizer'] == 'Adam':\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=conf[\"learning_rate\"])\n",
    "elif conf['optimizer'] == 'SGD':\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=conf[\"learning_rate\"])\n",
    "\n",
    "stud_model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = params[\"train_size\"]+new_samples_counter // conf[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = stud_model.fit(\n",
    "    combined_ds,\n",
    "    steps_per_epoch = train_steps, # might have to reduce\n",
    "    epochs = 2,\n",
    "    validation_data = test_ds, # what to use for validation data?\n",
    "    validation_steps = test_steps,\n",
    "    validation_freq = 1,\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Iterate this algorithm a few times by treating the student as a teacher to relabel the unlabeled data and training a new student"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
