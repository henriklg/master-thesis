{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kvasir dataset split into neg/pos and trained using Resnet50 without augmentation. Getting some decent results after training on resampled data with large step-size.  \n",
    "- Class weighting  \n",
    "- Resampling  \n",
    "- Initial Bias-estimation\n",
    "- Decreasing learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Some stuff to make utils-function work\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "from data_prep import create_dataset, print_class_info, show_image\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Jupyter-specific\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('/mnt/sdb/hyper-kvasir/labeled/')\n",
    "\n",
    "config = {\n",
    "    # Dataset\n",
    "    \"data_dir\": data_dir,\n",
    "    \"cache_dir\": \"./cache\",\n",
    "    \"ds_info\": 'hyp-kva',\n",
    "    \"resample\": False,\n",
    "    \"shuffle_buffer_size\": 0,\n",
    "    \"neg_class\": ['normal-cecum'],\n",
    "    \"outcast\": None,\n",
    "    # Model\n",
    "    \"model\": 'EfficientNetB0',\n",
    "    \"num_epochs\": 100,\n",
    "    \"batch_size\": 64,\n",
    "    \"img_shape\": (224, 224, 3),\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"optimizer\": 'Adam',\n",
    "    \"final_activation\": 'softmax',\n",
    "    # Callbacks\n",
    "    \"learning_schedule\": True,\n",
    "    \"checkpoint\": False,\n",
    "    \"early_stopping\": True,\n",
    "    \"early_stopping_patience\": 15,\n",
    "    \"decay_rate\": 0.05,              # higher number gives steeper dropoff\n",
    "    # Misc\n",
    "    \"verbosity\": 1\n",
    "    }\n",
    "\n",
    "model_name = '{}x{}x{}_{}_{}'.format(config[\"num_epochs\"], config[\"batch_size\"], \n",
    "                                     config[\"img_shape\"][1], config[\"ds_info\"], config[\"model\"])\n",
    "\n",
    "fine_tune_from = 130\n",
    "fine_tune_epochs = 30\n",
    "early_stopping_patience = config[\"early_stopping_patience\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training, testing and validation dataset from utils/data_prep.py.  \n",
    "Returns tf.dataset for shuffled, cached and batched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hemorrhoids                 :    6 | 0.06%\n",
      "barretts                    :   41 | 0.38%\n",
      "esophagitis-a               :  403 | 3.78%\n",
      "esophagitis-b-d             :  260 | 2.44%\n",
      "ulcerative-colitis-0-1      :   35 | 0.33%\n",
      "barretts-short-segment      :   53 | 0.50%\n",
      "cecum                       : 1009 | 9.46%\n",
      "pylorus                     :  999 | 9.37%\n",
      "retroflex-rectum            :  391 | 3.67%\n",
      "ulcerative-colitis-grade-2  :  443 | 4.15%\n",
      "ulcerative-colitis-grade-1  :  201 | 1.89%\n",
      "bbps-2-3                    : 1148 | 10.77%\n",
      "bbps-0-1                    :  646 | 6.06%\n",
      "ileum                       :    9 | 0.08%\n",
      "retroflex-stomach           :  764 | 7.17%\n",
      "normal-z-line               :  932 | 8.74%\n",
      "ulcerative-colitis-2-3      :   28 | 0.26%\n",
      "impacted-stool              :  131 | 1.23%\n",
      "polyps                      : 1028 | 9.64%\n",
      "dyed-resection-margins      :  989 | 9.28%\n",
      "dyed-lifted-polyps          : 1002 | 9.40%\n",
      "ulcerative-colitis-grade-3  :  133 | 1.25%\n",
      "ulcerative-colitis-1-2      :   11 | 0.10%\n",
      "\n",
      "Total number of images: 10662, in 23 classes.\n",
      "\n",
      "Dataset.list_files:  /mnt/sdb/hyper-kvasir/labeled/*/*.*g \n",
      "\n",
      "WARNING:tensorflow:Entity <function create_dataset.<locals>.get_label at 0x7fa43a7d8ef0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Cell is empty\n",
      "WARNING: Entity <function create_dataset.<locals>.get_label at 0x7fa43a7d8ef0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Cell is empty\n",
      "[17 15 11 11 18  7  9 11 19 20]\n",
      "[ 3  7 12 12 12 18 14 10 20 12]\n",
      "[ 2  2 20 19 12  6  6 11  9 15]\n",
      "[17 11  3  6 19  8 12 20  8  6]\n",
      "[11 19  6 21 11 15  7  9 18 15]\n",
      "[15 18 11  6 20  2  3 20 19 20]\n",
      "[14 15 18  7 18 12  9 20  7 11]\n",
      "[11  9 18  6 15  6 12 11  2  7]\n",
      "[11 20 12 11 18 20 15 18  6  6]\n",
      "[11 14 11  7 19  7  7  7  6 20]\n",
      "\n",
      "Full dataset sample size:        10662\n",
      "Train dataset sample size:        7463\n",
      "Test dataset sample size:         1599\n",
      "Validation dataset sample size:   1600\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds, val_ds, params = create_dataset(config)\n",
    "\n",
    "train_steps = params[\"train_size\"] // config[\"batch_size\"]\n",
    "test_steps = params[\"test_size\"] // config[\"batch_size\"]\n",
    "val_steps = params[\"val_size\"] // config[\"batch_size\"]\n",
    "class_names = params[\"class_names\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "Train a teacher model on labeled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet import EfficientNetB0 as EfficientNet\n",
    "\n",
    "# from efficientnet import center_crop_and_resize, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_base = EfficientNet(\n",
    "    weights=\"imagenet\", # or weights='noisy-student'\n",
    "    include_top=False, \n",
    "    input_shape=config[\"img_shape\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze layers in resnet\n",
    "efficientnet_base.trainable = True\n",
    "\n",
    "# Define model\n",
    "en_model = Sequential()\n",
    "\n",
    "en_model.add(efficientnet_base)\n",
    "en_model.add(layers.GlobalAveragePooling2D())\n",
    "# en_model.add(layers.Dropout(0.2))\n",
    "# en_model.add(layers.Dense(256, activation='relu'))\n",
    "en_model.add(layers.Dense(params[\"num_classes\"], activation=config[\"final_activation\"]))\n",
    "\n",
    "if config['optimizer'] == 'Adam':\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=config[\"learning_rate\"])\n",
    "elif config['optimizer'] == 'SGD':\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=config[\"learning_rate\"])\n",
    "\n",
    "en_model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, LearningRateScheduler\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By using LearnignRateScheduler\n",
    "initial_learning_rate = config[\"learning_rate\"]\n",
    "decay_steps = params[\"train_size\"] // config[\"batch_size\"]\n",
    "batch_size = config['batch_size']\n",
    "decay_rate = config['decay_rate']\n",
    "\n",
    "def schedule(epoch):\n",
    "    # calculate new learning rate\n",
    "    learning_rate = initial_learning_rate / (1 + decay_rate * (epoch*batch_size) / decay_steps)\n",
    "    \n",
    "    # update tensorboard\n",
    "    tf.summary.scalar(name='learning_rate', data=learning_rate, step=epoch)\n",
    "    return learning_rate\n",
    "\n",
    "log_dir=\"./logs/{}/\".format(config[\"model\"]) + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
    "file_writer.set_as_default()\n",
    "\n",
    "lr_schedule_cb = LearningRateScheduler(schedule, verbose=1)\n",
    "earlystopp_cb = EarlyStopping(monitor='val_loss',verbose=1, patience=early_stopping_patience, restore_best_weights=True)\n",
    "checkpoint_cb = ModelCheckpoint(filepath='./models/best_cp-{epoch:03d}.hdf', monitor='val_loss', save_best_only=True, mode='auto')\n",
    "tensorboard_cb = TensorBoard(log_dir=log_dir, update_freq='batch')\n",
    "\n",
    "callbacks = [tensorboard_cb]\n",
    "if config[\"early_stopping\"]: callbacks.append(earlystopp_cb)\n",
    "if config[\"learning_schedule\"]: callbacks.append(lr_schedule_cb)\n",
    "if config[\"checkpoint\"]: callbacks.append(checkpoint_cb)\n",
    "\n",
    "# Write config dictionary to text file\n",
    "f = open(log_dir+\"/config.txt\",\"w\")\n",
    "f.write(str(config))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 116 steps, validate for 24 steps\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.01.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'depthwise_conv2d/depthwise_kernel:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/kernel:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'depthwise_conv2d_1/depthwise_kernel:0', 'batch_normalization_4/gamma:0', 'batch_normalization_4/beta:0', 'conv2d_5/kernel:0', 'conv2d_5/bias:0', 'conv2d_6/kernel:0', 'conv2d_6/bias:0', 'conv2d_7/kernel:0', 'batch_normalization_5/gamma:0', 'batch_normalization_5/beta:0', 'conv2d_8/kernel:0', 'batch_normalization_6/gamma:0', 'batch_normalization_6/beta:0', 'depthwise_conv2d_2/depthwise_kernel:0', 'batch_normalization_7/gamma:0', 'batch_normalization_7/beta:0', 'conv2d_9/kernel:0', 'conv2d_9/bias:0', 'conv2d_10/kernel:0', 'conv2d_10/bias:0', 'conv2d_11/kernel:0', 'batch_normalization_8/gamma:0', 'batch_normalization_8/beta:0', 'conv2d_12/kernel:0', 'batch_normalization_9/gamma:0', 'batch_normalization_9/beta:0', 'depthwise_conv2d_3/depthwise_kernel:0', 'batch_normalization_10/gamma:0', 'batch_normalization_10/beta:0', 'conv2d_13/kernel:0', 'conv2d_13/bias:0', 'conv2d_14/kernel:0', 'conv2d_14/bias:0', 'conv2d_15/kernel:0', 'batch_normalization_11/gamma:0', 'batch_normalization_11/beta:0', 'conv2d_16/kernel:0', 'batch_normalization_12/gamma:0', 'batch_normalization_12/beta:0', 'depthwise_conv2d_4/depthwise_kernel:0', 'batch_normalization_13/gamma:0', 'batch_normalization_13/beta:0', 'conv2d_17/kernel:0', 'conv2d_17/bias:0', 'conv2d_18/kernel:0', 'conv2d_18/bias:0', 'conv2d_19/kernel:0', 'batch_normalization_14/gamma:0', 'batch_normalization_14/beta:0', 'conv2d_20/kernel:0', 'batch_normalization_15/gamma:0', 'batch_normalization_15/beta:0', 'depthwise_conv2d_5/depthwise_kernel:0', 'batch_normalization_16/gamma:0', 'batch_normalization_16/beta:0', 'conv2d_21/kernel:0', 'conv2d_21/bias:0', 'conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'batch_normalization_17/gamma:0', 'batch_normalization_17/beta:0', 'conv2d_24/kernel:0', 'batch_normalization_18/gamma:0', 'batch_normalization_18/beta:0', 'depthwise_conv2d_6/depthwise_kernel:0', 'batch_normalization_19/gamma:0', 'batch_normalization_19/beta:0', 'conv2d_25/kernel:0', 'conv2d_25/bias:0', 'conv2d_26/kernel:0', 'conv2d_26/bias:0', 'conv2d_27/kernel:0', 'batch_normalization_20/gamma:0', 'batch_normalization_20/beta:0', 'conv2d_28/kernel:0', 'batch_normalization_21/gamma:0', 'batch_normalization_21/beta:0', 'depthwise_conv2d_7/depthwise_kernel:0', 'batch_normalization_22/gamma:0', 'batch_normalization_22/beta:0', 'conv2d_29/kernel:0', 'conv2d_29/bias:0', 'conv2d_30/kernel:0', 'conv2d_30/bias:0', 'conv2d_31/kernel:0', 'batch_normalization_23/gamma:0', 'batch_normalization_23/beta:0', 'conv2d_32/kernel:0', 'batch_normalization_24/gamma:0', 'batch_normalization_24/beta:0', 'depthwise_conv2d_8/depthwise_kernel:0', 'batch_normalization_25/gamma:0', 'batch_normalization_25/beta:0', 'conv2d_33/kernel:0', 'conv2d_33/bias:0', 'conv2d_34/kernel:0', 'conv2d_34/bias:0', 'conv2d_35/kernel:0', 'batch_normalization_26/gamma:0', 'batch_normalization_26/beta:0', 'conv2d_36/kernel:0', 'batch_normalization_27/gamma:0', 'batch_normalization_27/beta:0', 'depthwise_conv2d_9/depthwise_kernel:0', 'batch_normalization_28/gamma:0', 'batch_normalization_28/beta:0', 'conv2d_37/kernel:0', 'conv2d_37/bias:0', 'conv2d_38/kernel:0', 'conv2d_38/bias:0', 'conv2d_39/kernel:0', 'batch_normalization_29/gamma:0', 'batch_normalization_29/beta:0', 'conv2d_40/kernel:0', 'batch_normalization_30/gamma:0', 'batch_normalization_30/beta:0', 'depthwise_conv2d_10/depthwise_kernel:0', 'batch_normalization_31/gamma:0', 'batch_normalization_31/beta:0', 'conv2d_41/kernel:0', 'conv2d_41/bias:0', 'conv2d_42/kernel:0', 'conv2d_42/bias:0', 'conv2d_43/kernel:0', 'batch_normalization_32/gamma:0', 'batch_normalization_32/beta:0', 'conv2d_44/kernel:0', 'batch_normalization_33/gamma:0', 'batch_normalization_33/beta:0', 'depthwise_conv2d_11/depthwise_kernel:0', 'batch_normalization_34/gamma:0', 'batch_normalization_34/beta:0', 'conv2d_45/kernel:0', 'conv2d_45/bias:0', 'conv2d_46/kernel:0', 'conv2d_46/bias:0', 'conv2d_47/kernel:0', 'batch_normalization_35/gamma:0', 'batch_normalization_35/beta:0', 'conv2d_48/kernel:0', 'batch_normalization_36/gamma:0', 'batch_normalization_36/beta:0', 'depthwise_conv2d_12/depthwise_kernel:0', 'batch_normalization_37/gamma:0', 'batch_normalization_37/beta:0', 'conv2d_49/kernel:0', 'conv2d_49/bias:0', 'conv2d_50/kernel:0', 'conv2d_50/bias:0', 'conv2d_51/kernel:0', 'batch_normalization_38/gamma:0', 'batch_normalization_38/beta:0', 'conv2d_52/kernel:0', 'batch_normalization_39/gamma:0', 'batch_normalization_39/beta:0', 'depthwise_conv2d_13/depthwise_kernel:0', 'batch_normalization_40/gamma:0', 'batch_normalization_40/beta:0', 'conv2d_53/kernel:0', 'conv2d_53/bias:0', 'conv2d_54/kernel:0', 'conv2d_54/bias:0', 'conv2d_55/kernel:0', 'batch_normalization_41/gamma:0', 'batch_normalization_41/beta:0', 'conv2d_56/kernel:0', 'batch_normalization_42/gamma:0', 'batch_normalization_42/beta:0', 'depthwise_conv2d_14/depthwise_kernel:0', 'batch_normalization_43/gamma:0', 'batch_normalization_43/beta:0', 'conv2d_57/kernel:0', 'conv2d_57/bias:0', 'conv2d_58/kernel:0', 'conv2d_58/bias:0', 'conv2d_59/kernel:0', 'batch_normalization_44/gamma:0', 'batch_normalization_44/beta:0', 'conv2d_60/kernel:0', 'batch_normalization_45/gamma:0', 'batch_normalization_45/beta:0', 'depthwise_conv2d_15/depthwise_kernel:0', 'batch_normalization_46/gamma:0', 'batch_normalization_46/beta:0', 'conv2d_61/kernel:0', 'conv2d_61/bias:0', 'conv2d_62/kernel:0', 'conv2d_62/bias:0', 'conv2d_63/kernel:0', 'batch_normalization_47/gamma:0', 'batch_normalization_47/beta:0', 'conv2d_64/kernel:0', 'batch_normalization_48/gamma:0', 'batch_normalization_48/beta:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'depthwise_conv2d/depthwise_kernel:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/kernel:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'depthwise_conv2d_1/depthwise_kernel:0', 'batch_normalization_4/gamma:0', 'batch_normalization_4/beta:0', 'conv2d_5/kernel:0', 'conv2d_5/bias:0', 'conv2d_6/kernel:0', 'conv2d_6/bias:0', 'conv2d_7/kernel:0', 'batch_normalization_5/gamma:0', 'batch_normalization_5/beta:0', 'conv2d_8/kernel:0', 'batch_normalization_6/gamma:0', 'batch_normalization_6/beta:0', 'depthwise_conv2d_2/depthwise_kernel:0', 'batch_normalization_7/gamma:0', 'batch_normalization_7/beta:0', 'conv2d_9/kernel:0', 'conv2d_9/bias:0', 'conv2d_10/kernel:0', 'conv2d_10/bias:0', 'conv2d_11/kernel:0', 'batch_normalization_8/gamma:0', 'batch_normalization_8/beta:0', 'conv2d_12/kernel:0', 'batch_normalization_9/gamma:0', 'batch_normalization_9/beta:0', 'depthwise_conv2d_3/depthwise_kernel:0', 'batch_normalization_10/gamma:0', 'batch_normalization_10/beta:0', 'conv2d_13/kernel:0', 'conv2d_13/bias:0', 'conv2d_14/kernel:0', 'conv2d_14/bias:0', 'conv2d_15/kernel:0', 'batch_normalization_11/gamma:0', 'batch_normalization_11/beta:0', 'conv2d_16/kernel:0', 'batch_normalization_12/gamma:0', 'batch_normalization_12/beta:0', 'depthwise_conv2d_4/depthwise_kernel:0', 'batch_normalization_13/gamma:0', 'batch_normalization_13/beta:0', 'conv2d_17/kernel:0', 'conv2d_17/bias:0', 'conv2d_18/kernel:0', 'conv2d_18/bias:0', 'conv2d_19/kernel:0', 'batch_normalization_14/gamma:0', 'batch_normalization_14/beta:0', 'conv2d_20/kernel:0', 'batch_normalization_15/gamma:0', 'batch_normalization_15/beta:0', 'depthwise_conv2d_5/depthwise_kernel:0', 'batch_normalization_16/gamma:0', 'batch_normalization_16/beta:0', 'conv2d_21/kernel:0', 'conv2d_21/bias:0', 'conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'batch_normalization_17/gamma:0', 'batch_normalization_17/beta:0', 'conv2d_24/kernel:0', 'batch_normalization_18/gamma:0', 'batch_normalization_18/beta:0', 'depthwise_conv2d_6/depthwise_kernel:0', 'batch_normalization_19/gamma:0', 'batch_normalization_19/beta:0', 'conv2d_25/kernel:0', 'conv2d_25/bias:0', 'conv2d_26/kernel:0', 'conv2d_26/bias:0', 'conv2d_27/kernel:0', 'batch_normalization_20/gamma:0', 'batch_normalization_20/beta:0', 'conv2d_28/kernel:0', 'batch_normalization_21/gamma:0', 'batch_normalization_21/beta:0', 'depthwise_conv2d_7/depthwise_kernel:0', 'batch_normalization_22/gamma:0', 'batch_normalization_22/beta:0', 'conv2d_29/kernel:0', 'conv2d_29/bias:0', 'conv2d_30/kernel:0', 'conv2d_30/bias:0', 'conv2d_31/kernel:0', 'batch_normalization_23/gamma:0', 'batch_normalization_23/beta:0', 'conv2d_32/kernel:0', 'batch_normalization_24/gamma:0', 'batch_normalization_24/beta:0', 'depthwise_conv2d_8/depthwise_kernel:0', 'batch_normalization_25/gamma:0', 'batch_normalization_25/beta:0', 'conv2d_33/kernel:0', 'conv2d_33/bias:0', 'conv2d_34/kernel:0', 'conv2d_34/bias:0', 'conv2d_35/kernel:0', 'batch_normalization_26/gamma:0', 'batch_normalization_26/beta:0', 'conv2d_36/kernel:0', 'batch_normalization_27/gamma:0', 'batch_normalization_27/beta:0', 'depthwise_conv2d_9/depthwise_kernel:0', 'batch_normalization_28/gamma:0', 'batch_normalization_28/beta:0', 'conv2d_37/kernel:0', 'conv2d_37/bias:0', 'conv2d_38/kernel:0', 'conv2d_38/bias:0', 'conv2d_39/kernel:0', 'batch_normalization_29/gamma:0', 'batch_normalization_29/beta:0', 'conv2d_40/kernel:0', 'batch_normalization_30/gamma:0', 'batch_normalization_30/beta:0', 'depthwise_conv2d_10/depthwise_kernel:0', 'batch_normalization_31/gamma:0', 'batch_normalization_31/beta:0', 'conv2d_41/kernel:0', 'conv2d_41/bias:0', 'conv2d_42/kernel:0', 'conv2d_42/bias:0', 'conv2d_43/kernel:0', 'batch_normalization_32/gamma:0', 'batch_normalization_32/beta:0', 'conv2d_44/kernel:0', 'batch_normalization_33/gamma:0', 'batch_normalization_33/beta:0', 'depthwise_conv2d_11/depthwise_kernel:0', 'batch_normalization_34/gamma:0', 'batch_normalization_34/beta:0', 'conv2d_45/kernel:0', 'conv2d_45/bias:0', 'conv2d_46/kernel:0', 'conv2d_46/bias:0', 'conv2d_47/kernel:0', 'batch_normalization_35/gamma:0', 'batch_normalization_35/beta:0', 'conv2d_48/kernel:0', 'batch_normalization_36/gamma:0', 'batch_normalization_36/beta:0', 'depthwise_conv2d_12/depthwise_kernel:0', 'batch_normalization_37/gamma:0', 'batch_normalization_37/beta:0', 'conv2d_49/kernel:0', 'conv2d_49/bias:0', 'conv2d_50/kernel:0', 'conv2d_50/bias:0', 'conv2d_51/kernel:0', 'batch_normalization_38/gamma:0', 'batch_normalization_38/beta:0', 'conv2d_52/kernel:0', 'batch_normalization_39/gamma:0', 'batch_normalization_39/beta:0', 'depthwise_conv2d_13/depthwise_kernel:0', 'batch_normalization_40/gamma:0', 'batch_normalization_40/beta:0', 'conv2d_53/kernel:0', 'conv2d_53/bias:0', 'conv2d_54/kernel:0', 'conv2d_54/bias:0', 'conv2d_55/kernel:0', 'batch_normalization_41/gamma:0', 'batch_normalization_41/beta:0', 'conv2d_56/kernel:0', 'batch_normalization_42/gamma:0', 'batch_normalization_42/beta:0', 'depthwise_conv2d_14/depthwise_kernel:0', 'batch_normalization_43/gamma:0', 'batch_normalization_43/beta:0', 'conv2d_57/kernel:0', 'conv2d_57/bias:0', 'conv2d_58/kernel:0', 'conv2d_58/bias:0', 'conv2d_59/kernel:0', 'batch_normalization_44/gamma:0', 'batch_normalization_44/beta:0', 'conv2d_60/kernel:0', 'batch_normalization_45/gamma:0', 'batch_normalization_45/beta:0', 'depthwise_conv2d_15/depthwise_kernel:0', 'batch_normalization_46/gamma:0', 'batch_normalization_46/beta:0', 'conv2d_61/kernel:0', 'conv2d_61/bias:0', 'conv2d_62/kernel:0', 'conv2d_62/bias:0', 'conv2d_63/kernel:0', 'batch_normalization_47/gamma:0', 'batch_normalization_47/beta:0', 'conv2d_64/kernel:0', 'batch_normalization_48/gamma:0', 'batch_normalization_48/beta:0'] when minimizing the loss.\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.7720 - sparse_categorical_accuracy: 0.7640WARNING:tensorflow:From /home/henrik/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./models/best_cp-001.hdf/assets\n",
      "116/116 [==============================] - 53s 460ms/step - loss: 0.7688 - sparse_categorical_accuracy: 0.7650 - val_loss: 1.1298 - val_sparse_categorical_accuracy: 0.6829\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.009731543624161074.\n",
      "Epoch 2/100\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.4180 - sparse_categorical_accuracy: 0.8554INFO:tensorflow:Assets written to: ./models/best_cp-002.hdf/assets\n",
      "116/116 [==============================] - 47s 408ms/step - loss: 0.4173 - sparse_categorical_accuracy: 0.8556 - val_loss: 0.7185 - val_sparse_categorical_accuracy: 0.7760\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.009477124183006535.\n",
      "Epoch 3/100\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.3113 - sparse_categorical_accuracy: 0.8891"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b9b7bf678333>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mvalidation_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m                       total_epochs=1)\n\u001b[1;32m    371\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[0;32m--> 372\u001b[0;31m                                  prefix='val_')\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF2/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[0;34m(self, epoch, mode)\u001b[0m\n\u001b[1;32m    683\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;31m# Epochs only apply to `fit`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    963\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_worker_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0;31m# For multi-worker training, back up the weights and current training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    999\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    973\u001b[0m     \"\"\"\n\u001b[1;32m    974\u001b[0m     saving.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m--> 975\u001b[0;31m                       signatures, options)\n\u001b[0m\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    113\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0;32m--> 115\u001b[0;31m                           signatures, options)\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options)\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0;31m# default learning phase placeholder.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0msave_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m    881\u001b[0m   \u001b[0;31m# Note we run this twice since, while constructing the view the first time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   \u001b[0;31m# there can be side effects of creating variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SaveableView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_graph_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m   \u001b[0msaveable_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SaveableView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_graph_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, checkpoint_view)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mseen_function_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes_without_functions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheckpoint_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\u001b[0m in \u001b[0;36mlist_functions\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mobj_functions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m       obj_functions = obj._list_functions_for_serialization(  # pylint: disable=protected-access\n\u001b[0;32m--> 141\u001b[0;31m           self._serialization_cache)\n\u001b[0m\u001b[1;32m    142\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/tracking.py\u001b[0m in \u001b[0;36m_list_functions_for_serialization\u001b[0;34m(self, unused_serialization_cache)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;31m# attribute accessor is broken.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mattribute_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m       if isinstance(attribute_value, (def_function.Function,\n\u001b[0m\u001b[1;32m    111\u001b[0m                                       defun.ConcreteFunction)):\n\u001b[1;32m    112\u001b[0m         \u001b[0mfunctions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattribute_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattribute_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = en_model.fit(\n",
    "    train_ds,\n",
    "    steps_per_epoch = train_steps,\n",
    "    epochs = config[\"num_epochs\"],\n",
    "    validation_data = test_ds,\n",
    "    validation_steps = test_steps,\n",
    "    validation_freq = 1,\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc =  str(history.history[\"val_sparse_categorical_accuracy\"][-1])[2:4]\n",
    "en_model.save('./models/{}.h5'.format(model_name+best_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_evaluate = en_model.evaluate(val_ds, verbose=2, steps=val_steps)\n",
    "\n",
    "# Write evaluate dictionary to text file\n",
    "f = open(log_dir+\"/evaluate.txt\",\"w\")\n",
    "f.write( str(en_evaluate) )\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['sparse_categorical_accuracy']\n",
    "val_acc = history.history['val_sparse_categorical_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "if config[\"learning_schedule\"]: lr = history.history['lr']\n",
    "epochs_range = range(history.epoch[-1]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"learning_schedule\"]:\n",
    "    # Plot the learning rate\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(epochs_range, lr, label='Learning Rate')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learnign rate')\n",
    "    plt.savefig(log_dir+'/learning_rate.png')\n",
    "    plt.title('Adaptive Learning Rate');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train-val accuracy and loss\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Subplot 1\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "# plt.ylim([0.5, 1])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# Subplot 2\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylim([0.0, 3])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.savefig(log_dir+'/accuracy_and_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the predictions on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take one batch of validation data\n",
    "idx = np.random.randint(0, config[\"batch_size\"])\n",
    "for images, labels in val_ds.take(1):\n",
    "    # Take one image and convert it to numpy\n",
    "    img = images.numpy()[idx]\n",
    "    lab = labels.numpy()[idx]\n",
    "    # Add one dimension\n",
    "    print (\"label:\", class_names[lab], end='\\n\\n')\n",
    "    show_image(img)\n",
    "    img = np.expand_dims(img, 0)\n",
    "    \n",
    "    prediction = en_model.predict(img, verbose=0)\n",
    "    for i, pred in enumerate(prediction[0]):\n",
    "        if pred > 0.01: print(\"{:>5.2f}% {}\".format(pred*100, class_names[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # the last item of parts is the filename\n",
    "    filename = parts[-1]\n",
    "    print (type(filename))\n",
    "    return filename\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [config[\"img_shape\"][0], config[\"img_shape\"][1] ])\n",
    "\n",
    "def process_path(file_path):\n",
    "    filename = get_filename(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the unlabeled `test` dataset (which are images taken from the training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "data_dir_unlabeled_test = pathlib.Path('/mnt/sdb/hyper-kvasir/unlabeled-test/')\n",
    "\n",
    "ds_size_unlabeled_test = len(list(data_dir_unlabeled_test.glob('*.*g')))\n",
    "\n",
    "files_string = str(data_dir_unlabeled_test/'*.*g')\n",
    "list_ds_unlabeled_test = tf.data.Dataset.list_files(files_string)\n",
    "\n",
    "unlabeled_ds_test = list_ds_unlabeled_test.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next hurdle: get access to both dataset sample and prediction.  \n",
    "- Predict one and one image?\n",
    "- Predict all at once?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method works, but predicts one image at a time.. Slow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take one image of unlabeled-test set\n",
    "for img, name in unlabeled_ds_test.take(1):\n",
    "    # Convert to numpy and add dimension\n",
    "    print (\"Filename:\", str(name.numpy())[2:-1], end='\\n\\n')\n",
    "    show_image(img.numpy())\n",
    "    img = np.expand_dims(img.numpy(), 0)\n",
    "    prediction = en_model.predict(img, verbose=0)\n",
    "    for i, pred in enumerate(prediction[0]):\n",
    "        if pred > 0.01: print(\"{:>5.2f}% {}\".format(pred*100, class_names[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the `full` unlabeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_unlabeled = pathlib.Path('/mnt/sdb/hyper-kvasir/unlabeled/')\n",
    "\n",
    "ds_size_unlabeled = len(list(data_dir_unlabeled.glob('*.*g')))\n",
    "\n",
    "files_string = str(data_dir_unlabeled/'*.*g')\n",
    "list_ds_unlabeled = tf.data.Dataset.list_files(files_string)\n",
    "\n",
    "unlabeled_ds = list_ds_unlabeled.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take one image of unlabeled-test set\n",
    "for img, name in unlabeled_ds.take(1):\n",
    "    # Convert to numpy and add dimension\n",
    "    print (\"File:\",str(name.numpy())[2:-1], end='\\n\\n')\n",
    "    show_image(img.numpy())\n",
    "    img = np.expand_dims(img.numpy(), 0)\n",
    "    prediction = en_model.predict(img, verbose=0)\n",
    "    \n",
    "    for i, pred in enumerate(prediction[0]):\n",
    "         if pred > 0.01: print(\"{:>5.2f}% {}\".format(pred*100, class_names[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
