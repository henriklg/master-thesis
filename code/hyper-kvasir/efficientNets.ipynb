{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kvasir dataset split into neg/pos and trained using Resnet50 without augmentation. Getting some decent results after training on resampled data with large step-size.  \n",
    "- Class weighting  \n",
    "- Resampling  \n",
    "- Initial Bias-estimation\n",
    "- Decreasing learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Some stuff to make utils-function work\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "from data_prep import create_dataset, print_class_info, show_image\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Jupyter-specific\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('/mnt/sdb/hyper-kvasir/labeled/')\n",
    "\n",
    "config = {\n",
    "    # Dataset\n",
    "    \"data_dir\": data_dir,\n",
    "    \"cache_dir\": \"./cache\",\n",
    "    \"ds_info\": 'complete',\n",
    "    \"resample\": False,\n",
    "    \"shuffle_buffer_size\": 0,\n",
    "    \"neg_class\": ['normal-cecum'],\n",
    "    \"outcast\": None,\n",
    "    # Model\n",
    "    \"model\": 'EfficientNetB3',\n",
    "    \"num_epochs\": 100,\n",
    "    \"batch_size\": 64,\n",
    "    \"img_shape\": (224, 224, 3),\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"optimizer\": 'Adam',\n",
    "    \"final_activation\": 'softmax',\n",
    "    # Callbacks\n",
    "    \"learning_schedule\": True,\n",
    "    \"checkpoint\": True,\n",
    "    \"early_stopping\": False,\n",
    "    \"early_stopping_patience\": 15,\n",
    "    \"decay_rate\": 0.05,              # higher number gives steeper dropoff\n",
    "    # Misc\n",
    "    \"verbosity\": 1\n",
    "    }\n",
    "\n",
    "model_name = '{}x{}x{}_{}_{}'.format(config[\"num_epochs\"], config[\"batch_size\"], \n",
    "                                     config[\"img_shape\"][1], config[\"ds_info\"], config[\"model\"])\n",
    "\n",
    "fine_tune_from = 130\n",
    "fine_tune_epochs = 30\n",
    "early_stopping_patience = config[\"early_stopping_patience\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training, testing and validation dataset from utils/data_prep.py.  \n",
    "Returns tf.dataset for shuffled, cached and batched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hemorrhoids                 :    6 | 0.06%\n",
      "barretts                    :   41 | 0.38%\n",
      "esophagitis-a               :  403 | 3.78%\n",
      "esophagitis-b-d             :  260 | 2.44%\n",
      "ulcerative-colitis-0-1      :   35 | 0.33%\n",
      "barretts-short-segment      :   53 | 0.50%\n",
      "cecum                       : 1009 | 9.46%\n",
      "pylorus                     :  999 | 9.37%\n",
      "retroflex-rectum            :  391 | 3.67%\n",
      "ulcerative-colitis-grade-2  :  443 | 4.15%\n",
      "ulcerative-colitis-grade-1  :  201 | 1.89%\n",
      "bbps-2-3                    : 1148 | 10.77%\n",
      "bbps-0-1                    :  646 | 6.06%\n",
      "ileum                       :    9 | 0.08%\n",
      "retroflex-stomach           :  764 | 7.17%\n",
      "normal-z-line               :  932 | 8.74%\n",
      "ulcerative-colitis-2-3      :   28 | 0.26%\n",
      "impacted-stool              :  131 | 1.23%\n",
      "polyps                      : 1028 | 9.64%\n",
      "dyed-resection-margins      :  989 | 9.28%\n",
      "dyed-lifted-polyps          : 1002 | 9.40%\n",
      "ulcerative-colitis-grade-3  :  133 | 1.25%\n",
      "ulcerative-colitis-1-2      :   11 | 0.10%\n",
      "\n",
      "Total number of images: 10662, in 23 classes.\n",
      "\n",
      "Dataset.list_files:  /mnt/sdb/hyper-kvasir/labeled/*/*.*g \n",
      "\n",
      "WARNING:tensorflow:Entity <function create_dataset.<locals>.get_label at 0x7f6a073d6ef0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Cell is empty\n",
      "WARNING: Entity <function create_dataset.<locals>.get_label at 0x7f6a073d6ef0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Cell is empty\n",
      "[11 12 19 18  7 11 20  6 12 18]\n",
      "[ 9 12 19 11 11  7 12 11  7 14]\n",
      "[19  9 19 20 20 19 14  7 20 11]\n",
      "[15  7  6 18 18 14  7  6  9 11]\n",
      "[ 6 19 12  7 12  8 18 11 20 20]\n",
      "[20 11  9  7 14  7  3  7 15 15]\n",
      "[ 6 18 11 20 14 20 11  7 18  6]\n",
      "[ 6  7 20  6 20 12 15 11  6 20]\n",
      "[15 11 19 18 18  6 11  9  7 20]\n",
      "[11  6  7 14  7  3 11  6 12 19]\n",
      "\n",
      "Full dataset sample size:        10662\n",
      "Train dataset sample size:        7463\n",
      "Test dataset sample size:         1599\n",
      "Validation dataset sample size:   1600\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds, val_ds, params = create_dataset(config)\n",
    "\n",
    "train_steps = params[\"train_size\"] // config[\"batch_size\"]\n",
    "test_steps = params[\"test_size\"] // config[\"batch_size\"]\n",
    "val_steps = params[\"val_size\"] // config[\"batch_size\"]\n",
    "class_names = params[\"class_names\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "Train a teacher model on labeled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from efficientnet import EfficientNetB0 as Net\n",
    "from efficientnet import center_crop_and_resize, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_base = Net(\n",
    "    weights=\"imagenet\", # or weights='noisy-student'\n",
    "    include_top=False, \n",
    "    input_shape=config[\"img_shape\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze layers in resnet\n",
    "efficientnet_base.trainable = True\n",
    "\n",
    "# Define model\n",
    "en_model = Sequential()\n",
    "\n",
    "en_model.add(efficientnet_base)\n",
    "en_model.add(layers.GlobalAveragePooling2D())\n",
    "en_model.add(layers.Dense(params[\"num_classes\"], activation=config[\"final_activation\"]))\n",
    "\n",
    "if config['optimizer'] == 'Adam':\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=config[\"learning_rate\"])\n",
    "elif config['optimizer'] == 'SGD':\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=config[\"learning_rate\"])\n",
    "\n",
    "en_model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b0 (Model)      (None, 7, 7, 1280)        4049564   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 23)                29463     \n",
      "=================================================================\n",
      "Total params: 4,079,027\n",
      "Trainable params: 4,037,011\n",
      "Non-trainable params: 42,016\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "en_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, LearningRateScheduler\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By using LearnignRateScheduler\n",
    "initial_learning_rate = config[\"learning_rate\"]\n",
    "decay_steps = params[\"train_size\"] // config[\"batch_size\"]\n",
    "batch_size = config['batch_size']\n",
    "decay_rate = config['decay_rate']\n",
    "\n",
    "def schedule(epoch):\n",
    "    # calculate new learning rate\n",
    "    learning_rate = initial_learning_rate / (1 + decay_rate * (epoch*batch_size) / decay_steps)\n",
    "    \n",
    "    # update tensorboard\n",
    "    tf.summary.scalar(name='learning_rate', data=learning_rate, step=epoch)\n",
    "    return learning_rate\n",
    "\n",
    "log_dir=\"./logs/{}/\".format(config[\"model\"]) + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
    "file_writer.set_as_default()\n",
    "\n",
    "lr_schedule_cb = LearningRateScheduler(schedule, verbose=1)\n",
    "earlystopp_cb = EarlyStopping(monitor='val_loss',verbose=1, patience=early_stopping_patience, restore_best_weights=True)\n",
    "checkpoint_cb = ModelCheckpoint(filepath='./models/best_cp-{epoch:03d}.hdf', monitor='val_loss', save_best_only=True, mode='auto')\n",
    "tensorboard_cb = TensorBoard(log_dir=log_dir, update_freq='batch')\n",
    "\n",
    "callbacks = [tensorboard_cb]\n",
    "if config[\"early_stopping\"]: callbacks.append(earlystopp_cb)\n",
    "if config[\"learning_schedule\"]: callbacks.append(lr_schedule_cb)\n",
    "if config[\"checkpoint\"]: callbacks.append(checkpoint_cb)\n",
    "\n",
    "# Write config dictionary to text file\n",
    "f = open(log_dir+\"/config.txt\",\"w\")\n",
    "f.write(str(config))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 116 steps, validate for 24 steps\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.01.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'depthwise_conv2d/depthwise_kernel:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/kernel:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'depthwise_conv2d_1/depthwise_kernel:0', 'batch_normalization_4/gamma:0', 'batch_normalization_4/beta:0', 'conv2d_5/kernel:0', 'conv2d_5/bias:0', 'conv2d_6/kernel:0', 'conv2d_6/bias:0', 'conv2d_7/kernel:0', 'batch_normalization_5/gamma:0', 'batch_normalization_5/beta:0', 'conv2d_8/kernel:0', 'batch_normalization_6/gamma:0', 'batch_normalization_6/beta:0', 'depthwise_conv2d_2/depthwise_kernel:0', 'batch_normalization_7/gamma:0', 'batch_normalization_7/beta:0', 'conv2d_9/kernel:0', 'conv2d_9/bias:0', 'conv2d_10/kernel:0', 'conv2d_10/bias:0', 'conv2d_11/kernel:0', 'batch_normalization_8/gamma:0', 'batch_normalization_8/beta:0', 'conv2d_12/kernel:0', 'batch_normalization_9/gamma:0', 'batch_normalization_9/beta:0', 'depthwise_conv2d_3/depthwise_kernel:0', 'batch_normalization_10/gamma:0', 'batch_normalization_10/beta:0', 'conv2d_13/kernel:0', 'conv2d_13/bias:0', 'conv2d_14/kernel:0', 'conv2d_14/bias:0', 'conv2d_15/kernel:0', 'batch_normalization_11/gamma:0', 'batch_normalization_11/beta:0', 'conv2d_16/kernel:0', 'batch_normalization_12/gamma:0', 'batch_normalization_12/beta:0', 'depthwise_conv2d_4/depthwise_kernel:0', 'batch_normalization_13/gamma:0', 'batch_normalization_13/beta:0', 'conv2d_17/kernel:0', 'conv2d_17/bias:0', 'conv2d_18/kernel:0', 'conv2d_18/bias:0', 'conv2d_19/kernel:0', 'batch_normalization_14/gamma:0', 'batch_normalization_14/beta:0', 'conv2d_20/kernel:0', 'batch_normalization_15/gamma:0', 'batch_normalization_15/beta:0', 'depthwise_conv2d_5/depthwise_kernel:0', 'batch_normalization_16/gamma:0', 'batch_normalization_16/beta:0', 'conv2d_21/kernel:0', 'conv2d_21/bias:0', 'conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'batch_normalization_17/gamma:0', 'batch_normalization_17/beta:0', 'conv2d_24/kernel:0', 'batch_normalization_18/gamma:0', 'batch_normalization_18/beta:0', 'depthwise_conv2d_6/depthwise_kernel:0', 'batch_normalization_19/gamma:0', 'batch_normalization_19/beta:0', 'conv2d_25/kernel:0', 'conv2d_25/bias:0', 'conv2d_26/kernel:0', 'conv2d_26/bias:0', 'conv2d_27/kernel:0', 'batch_normalization_20/gamma:0', 'batch_normalization_20/beta:0', 'conv2d_28/kernel:0', 'batch_normalization_21/gamma:0', 'batch_normalization_21/beta:0', 'depthwise_conv2d_7/depthwise_kernel:0', 'batch_normalization_22/gamma:0', 'batch_normalization_22/beta:0', 'conv2d_29/kernel:0', 'conv2d_29/bias:0', 'conv2d_30/kernel:0', 'conv2d_30/bias:0', 'conv2d_31/kernel:0', 'batch_normalization_23/gamma:0', 'batch_normalization_23/beta:0', 'conv2d_32/kernel:0', 'batch_normalization_24/gamma:0', 'batch_normalization_24/beta:0', 'depthwise_conv2d_8/depthwise_kernel:0', 'batch_normalization_25/gamma:0', 'batch_normalization_25/beta:0', 'conv2d_33/kernel:0', 'conv2d_33/bias:0', 'conv2d_34/kernel:0', 'conv2d_34/bias:0', 'conv2d_35/kernel:0', 'batch_normalization_26/gamma:0', 'batch_normalization_26/beta:0', 'conv2d_36/kernel:0', 'batch_normalization_27/gamma:0', 'batch_normalization_27/beta:0', 'depthwise_conv2d_9/depthwise_kernel:0', 'batch_normalization_28/gamma:0', 'batch_normalization_28/beta:0', 'conv2d_37/kernel:0', 'conv2d_37/bias:0', 'conv2d_38/kernel:0', 'conv2d_38/bias:0', 'conv2d_39/kernel:0', 'batch_normalization_29/gamma:0', 'batch_normalization_29/beta:0', 'conv2d_40/kernel:0', 'batch_normalization_30/gamma:0', 'batch_normalization_30/beta:0', 'depthwise_conv2d_10/depthwise_kernel:0', 'batch_normalization_31/gamma:0', 'batch_normalization_31/beta:0', 'conv2d_41/kernel:0', 'conv2d_41/bias:0', 'conv2d_42/kernel:0', 'conv2d_42/bias:0', 'conv2d_43/kernel:0', 'batch_normalization_32/gamma:0', 'batch_normalization_32/beta:0', 'conv2d_44/kernel:0', 'batch_normalization_33/gamma:0', 'batch_normalization_33/beta:0', 'depthwise_conv2d_11/depthwise_kernel:0', 'batch_normalization_34/gamma:0', 'batch_normalization_34/beta:0', 'conv2d_45/kernel:0', 'conv2d_45/bias:0', 'conv2d_46/kernel:0', 'conv2d_46/bias:0', 'conv2d_47/kernel:0', 'batch_normalization_35/gamma:0', 'batch_normalization_35/beta:0', 'conv2d_48/kernel:0', 'batch_normalization_36/gamma:0', 'batch_normalization_36/beta:0', 'depthwise_conv2d_12/depthwise_kernel:0', 'batch_normalization_37/gamma:0', 'batch_normalization_37/beta:0', 'conv2d_49/kernel:0', 'conv2d_49/bias:0', 'conv2d_50/kernel:0', 'conv2d_50/bias:0', 'conv2d_51/kernel:0', 'batch_normalization_38/gamma:0', 'batch_normalization_38/beta:0', 'conv2d_52/kernel:0', 'batch_normalization_39/gamma:0', 'batch_normalization_39/beta:0', 'depthwise_conv2d_13/depthwise_kernel:0', 'batch_normalization_40/gamma:0', 'batch_normalization_40/beta:0', 'conv2d_53/kernel:0', 'conv2d_53/bias:0', 'conv2d_54/kernel:0', 'conv2d_54/bias:0', 'conv2d_55/kernel:0', 'batch_normalization_41/gamma:0', 'batch_normalization_41/beta:0', 'conv2d_56/kernel:0', 'batch_normalization_42/gamma:0', 'batch_normalization_42/beta:0', 'depthwise_conv2d_14/depthwise_kernel:0', 'batch_normalization_43/gamma:0', 'batch_normalization_43/beta:0', 'conv2d_57/kernel:0', 'conv2d_57/bias:0', 'conv2d_58/kernel:0', 'conv2d_58/bias:0', 'conv2d_59/kernel:0', 'batch_normalization_44/gamma:0', 'batch_normalization_44/beta:0', 'conv2d_60/kernel:0', 'batch_normalization_45/gamma:0', 'batch_normalization_45/beta:0', 'depthwise_conv2d_15/depthwise_kernel:0', 'batch_normalization_46/gamma:0', 'batch_normalization_46/beta:0', 'conv2d_61/kernel:0', 'conv2d_61/bias:0', 'conv2d_62/kernel:0', 'conv2d_62/bias:0', 'conv2d_63/kernel:0', 'batch_normalization_47/gamma:0', 'batch_normalization_47/beta:0', 'conv2d_64/kernel:0', 'batch_normalization_48/gamma:0', 'batch_normalization_48/beta:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'depthwise_conv2d/depthwise_kernel:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/kernel:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'depthwise_conv2d_1/depthwise_kernel:0', 'batch_normalization_4/gamma:0', 'batch_normalization_4/beta:0', 'conv2d_5/kernel:0', 'conv2d_5/bias:0', 'conv2d_6/kernel:0', 'conv2d_6/bias:0', 'conv2d_7/kernel:0', 'batch_normalization_5/gamma:0', 'batch_normalization_5/beta:0', 'conv2d_8/kernel:0', 'batch_normalization_6/gamma:0', 'batch_normalization_6/beta:0', 'depthwise_conv2d_2/depthwise_kernel:0', 'batch_normalization_7/gamma:0', 'batch_normalization_7/beta:0', 'conv2d_9/kernel:0', 'conv2d_9/bias:0', 'conv2d_10/kernel:0', 'conv2d_10/bias:0', 'conv2d_11/kernel:0', 'batch_normalization_8/gamma:0', 'batch_normalization_8/beta:0', 'conv2d_12/kernel:0', 'batch_normalization_9/gamma:0', 'batch_normalization_9/beta:0', 'depthwise_conv2d_3/depthwise_kernel:0', 'batch_normalization_10/gamma:0', 'batch_normalization_10/beta:0', 'conv2d_13/kernel:0', 'conv2d_13/bias:0', 'conv2d_14/kernel:0', 'conv2d_14/bias:0', 'conv2d_15/kernel:0', 'batch_normalization_11/gamma:0', 'batch_normalization_11/beta:0', 'conv2d_16/kernel:0', 'batch_normalization_12/gamma:0', 'batch_normalization_12/beta:0', 'depthwise_conv2d_4/depthwise_kernel:0', 'batch_normalization_13/gamma:0', 'batch_normalization_13/beta:0', 'conv2d_17/kernel:0', 'conv2d_17/bias:0', 'conv2d_18/kernel:0', 'conv2d_18/bias:0', 'conv2d_19/kernel:0', 'batch_normalization_14/gamma:0', 'batch_normalization_14/beta:0', 'conv2d_20/kernel:0', 'batch_normalization_15/gamma:0', 'batch_normalization_15/beta:0', 'depthwise_conv2d_5/depthwise_kernel:0', 'batch_normalization_16/gamma:0', 'batch_normalization_16/beta:0', 'conv2d_21/kernel:0', 'conv2d_21/bias:0', 'conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'batch_normalization_17/gamma:0', 'batch_normalization_17/beta:0', 'conv2d_24/kernel:0', 'batch_normalization_18/gamma:0', 'batch_normalization_18/beta:0', 'depthwise_conv2d_6/depthwise_kernel:0', 'batch_normalization_19/gamma:0', 'batch_normalization_19/beta:0', 'conv2d_25/kernel:0', 'conv2d_25/bias:0', 'conv2d_26/kernel:0', 'conv2d_26/bias:0', 'conv2d_27/kernel:0', 'batch_normalization_20/gamma:0', 'batch_normalization_20/beta:0', 'conv2d_28/kernel:0', 'batch_normalization_21/gamma:0', 'batch_normalization_21/beta:0', 'depthwise_conv2d_7/depthwise_kernel:0', 'batch_normalization_22/gamma:0', 'batch_normalization_22/beta:0', 'conv2d_29/kernel:0', 'conv2d_29/bias:0', 'conv2d_30/kernel:0', 'conv2d_30/bias:0', 'conv2d_31/kernel:0', 'batch_normalization_23/gamma:0', 'batch_normalization_23/beta:0', 'conv2d_32/kernel:0', 'batch_normalization_24/gamma:0', 'batch_normalization_24/beta:0', 'depthwise_conv2d_8/depthwise_kernel:0', 'batch_normalization_25/gamma:0', 'batch_normalization_25/beta:0', 'conv2d_33/kernel:0', 'conv2d_33/bias:0', 'conv2d_34/kernel:0', 'conv2d_34/bias:0', 'conv2d_35/kernel:0', 'batch_normalization_26/gamma:0', 'batch_normalization_26/beta:0', 'conv2d_36/kernel:0', 'batch_normalization_27/gamma:0', 'batch_normalization_27/beta:0', 'depthwise_conv2d_9/depthwise_kernel:0', 'batch_normalization_28/gamma:0', 'batch_normalization_28/beta:0', 'conv2d_37/kernel:0', 'conv2d_37/bias:0', 'conv2d_38/kernel:0', 'conv2d_38/bias:0', 'conv2d_39/kernel:0', 'batch_normalization_29/gamma:0', 'batch_normalization_29/beta:0', 'conv2d_40/kernel:0', 'batch_normalization_30/gamma:0', 'batch_normalization_30/beta:0', 'depthwise_conv2d_10/depthwise_kernel:0', 'batch_normalization_31/gamma:0', 'batch_normalization_31/beta:0', 'conv2d_41/kernel:0', 'conv2d_41/bias:0', 'conv2d_42/kernel:0', 'conv2d_42/bias:0', 'conv2d_43/kernel:0', 'batch_normalization_32/gamma:0', 'batch_normalization_32/beta:0', 'conv2d_44/kernel:0', 'batch_normalization_33/gamma:0', 'batch_normalization_33/beta:0', 'depthwise_conv2d_11/depthwise_kernel:0', 'batch_normalization_34/gamma:0', 'batch_normalization_34/beta:0', 'conv2d_45/kernel:0', 'conv2d_45/bias:0', 'conv2d_46/kernel:0', 'conv2d_46/bias:0', 'conv2d_47/kernel:0', 'batch_normalization_35/gamma:0', 'batch_normalization_35/beta:0', 'conv2d_48/kernel:0', 'batch_normalization_36/gamma:0', 'batch_normalization_36/beta:0', 'depthwise_conv2d_12/depthwise_kernel:0', 'batch_normalization_37/gamma:0', 'batch_normalization_37/beta:0', 'conv2d_49/kernel:0', 'conv2d_49/bias:0', 'conv2d_50/kernel:0', 'conv2d_50/bias:0', 'conv2d_51/kernel:0', 'batch_normalization_38/gamma:0', 'batch_normalization_38/beta:0', 'conv2d_52/kernel:0', 'batch_normalization_39/gamma:0', 'batch_normalization_39/beta:0', 'depthwise_conv2d_13/depthwise_kernel:0', 'batch_normalization_40/gamma:0', 'batch_normalization_40/beta:0', 'conv2d_53/kernel:0', 'conv2d_53/bias:0', 'conv2d_54/kernel:0', 'conv2d_54/bias:0', 'conv2d_55/kernel:0', 'batch_normalization_41/gamma:0', 'batch_normalization_41/beta:0', 'conv2d_56/kernel:0', 'batch_normalization_42/gamma:0', 'batch_normalization_42/beta:0', 'depthwise_conv2d_14/depthwise_kernel:0', 'batch_normalization_43/gamma:0', 'batch_normalization_43/beta:0', 'conv2d_57/kernel:0', 'conv2d_57/bias:0', 'conv2d_58/kernel:0', 'conv2d_58/bias:0', 'conv2d_59/kernel:0', 'batch_normalization_44/gamma:0', 'batch_normalization_44/beta:0', 'conv2d_60/kernel:0', 'batch_normalization_45/gamma:0', 'batch_normalization_45/beta:0', 'depthwise_conv2d_15/depthwise_kernel:0', 'batch_normalization_46/gamma:0', 'batch_normalization_46/beta:0', 'conv2d_61/kernel:0', 'conv2d_61/bias:0', 'conv2d_62/kernel:0', 'conv2d_62/bias:0', 'conv2d_63/kernel:0', 'batch_normalization_47/gamma:0', 'batch_normalization_47/beta:0', 'conv2d_64/kernel:0', 'batch_normalization_48/gamma:0', 'batch_normalization_48/beta:0'] when minimizing the loss.\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.7827 - sparse_categorical_accuracy: 0.7587WARNING:tensorflow:From /home/henrik/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./models/best_cp-001.hdf/assets\n",
      "116/116 [==============================] - 54s 469ms/step - loss: 0.7801 - sparse_categorical_accuracy: 0.7589 - val_loss: 1.0635 - val_sparse_categorical_accuracy: 0.6960\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.009731543624161074.\n",
      "Epoch 2/100\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.4190 - sparse_categorical_accuracy: 0.8533INFO:tensorflow:Assets written to: ./models/best_cp-002.hdf/assets\n",
      "116/116 [==============================] - 46s 400ms/step - loss: 0.4185 - sparse_categorical_accuracy: 0.8536 - val_loss: 0.6463 - val_sparse_categorical_accuracy: 0.7975\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.009477124183006535.\n",
      "Epoch 3/100\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.3095 - sparse_categorical_accuracy: 0.8857INFO:tensorflow:Assets written to: ./models/best_cp-003.hdf/assets\n",
      "116/116 [==============================] - 47s 407ms/step - loss: 0.3099 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.3703 - val_sparse_categorical_accuracy: 0.8796\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.009235668789808919.\n",
      "Epoch 4/100\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.2724 - sparse_categorical_accuracy: 0.9041INFO:tensorflow:Assets written to: ./models/best_cp-004.hdf/assets\n",
      "116/116 [==============================] - 47s 402ms/step - loss: 0.2738 - sparse_categorical_accuracy: 0.9037 - val_loss: 0.2931 - val_sparse_categorical_accuracy: 0.9108\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.009006211180124225.\n",
      "Epoch 5/100\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.2382 - sparse_categorical_accuracy: 0.9143INFO:tensorflow:Assets written to: ./models/best_cp-005.hdf/assets\n",
      "116/116 [==============================] - 47s 408ms/step - loss: 0.2379 - sparse_categorical_accuracy: 0.9143 - val_loss: 0.2702 - val_sparse_categorical_accuracy: 0.9206\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.008787878787878787.\n",
      "Epoch 6/100\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.2011 - sparse_categorical_accuracy: 0.9298INFO:tensorflow:Assets written to: ./models/best_cp-006.hdf/assets\n",
      "116/116 [==============================] - 48s 418ms/step - loss: 0.2011 - sparse_categorical_accuracy: 0.9297 - val_loss: 0.2670 - val_sparse_categorical_accuracy: 0.9206\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.008579881656804733.\n",
      "Epoch 7/100\n",
      "116/116 [==============================] - 15s 134ms/step - loss: 0.1934 - sparse_categorical_accuracy: 0.9287 - val_loss: 0.2761 - val_sparse_categorical_accuracy: 0.9128\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.008381502890173411.\n",
      "Epoch 8/100\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.1765 - sparse_categorical_accuracy: 0.9374INFO:tensorflow:Assets written to: ./models/best_cp-008.hdf/assets\n",
      "116/116 [==============================] - 47s 401ms/step - loss: 0.1769 - sparse_categorical_accuracy: 0.9372 - val_loss: 0.2412 - val_sparse_categorical_accuracy: 0.9310\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.008192090395480226.\n",
      "Epoch 9/100\n",
      "116/116 [==============================] - 16s 134ms/step - loss: 0.1627 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.2429 - val_sparse_categorical_accuracy: 0.9316\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.008011049723756906.\n",
      "Epoch 10/100\n",
      "116/116 [==============================] - 15s 134ms/step - loss: 0.1586 - sparse_categorical_accuracy: 0.9441 - val_loss: 0.2611 - val_sparse_categorical_accuracy: 0.9284\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.007837837837837838.\n",
      "Epoch 11/100\n",
      "116/116 [==============================] - 16s 134ms/step - loss: 0.1428 - sparse_categorical_accuracy: 0.9502 - val_loss: 0.2479 - val_sparse_categorical_accuracy: 0.9336\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.007671957671957671.\n",
      "Epoch 12/100\n",
      "116/116 [==============================] - 15s 133ms/step - loss: 0.1425 - sparse_categorical_accuracy: 0.9473 - val_loss: 0.2480 - val_sparse_categorical_accuracy: 0.9290\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.007512953367875648.\n",
      "Epoch 13/100\n",
      "116/116 [==============================] - 15s 133ms/step - loss: 0.1463 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.2467 - val_sparse_categorical_accuracy: 0.9316\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.007360406091370559.\n",
      "Epoch 14/100\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.1389 - sparse_categorical_accuracy: 0.9538INFO:tensorflow:Assets written to: ./models/best_cp-014.hdf/assets\n",
      "116/116 [==============================] - 47s 402ms/step - loss: 0.1387 - sparse_categorical_accuracy: 0.9539 - val_loss: 0.2332 - val_sparse_categorical_accuracy: 0.9342\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.007213930348258706.\n",
      "Epoch 15/100\n",
      "116/116 [==============================] - 16s 134ms/step - loss: 0.1302 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.2432 - val_sparse_categorical_accuracy: 0.9329\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.007073170731707317.\n",
      "Epoch 16/100\n",
      "116/116 [==============================] - 16s 134ms/step - loss: 0.1323 - sparse_categorical_accuracy: 0.9541 - val_loss: 0.2497 - val_sparse_categorical_accuracy: 0.9414\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.006937799043062201.\n",
      "Epoch 17/100\n",
      "116/116 [==============================] - 15s 134ms/step - loss: 0.1166 - sparse_categorical_accuracy: 0.9595 - val_loss: 0.2433 - val_sparse_categorical_accuracy: 0.9395\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.006807511737089202.\n",
      "Epoch 18/100\n",
      "116/116 [==============================] - 15s 134ms/step - loss: 0.1192 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.2633 - val_sparse_categorical_accuracy: 0.9342\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.006682027649769585.\n",
      "Epoch 19/100\n",
      "116/116 [==============================] - 16s 134ms/step - loss: 0.1089 - sparse_categorical_accuracy: 0.9608 - val_loss: 0.2533 - val_sparse_categorical_accuracy: 0.9375\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.006561085972850678.\n",
      "Epoch 20/100\n",
      "116/116 [==============================] - 15s 134ms/step - loss: 0.1214 - sparse_categorical_accuracy: 0.9543 - val_loss: 0.2811 - val_sparse_categorical_accuracy: 0.9401\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.0064444444444444445.\n",
      "Epoch 21/100\n",
      "116/116 [==============================] - 16s 135ms/step - loss: 0.1040 - sparse_categorical_accuracy: 0.9639 - val_loss: 0.2722 - val_sparse_categorical_accuracy: 0.9395\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.006331877729257642.\n",
      "Epoch 22/100\n",
      "116/116 [==============================] - 15s 133ms/step - loss: 0.1168 - sparse_categorical_accuracy: 0.9584 - val_loss: 0.2728 - val_sparse_categorical_accuracy: 0.9421\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.006223175965665236.\n",
      "Epoch 23/100\n",
      "116/116 [==============================] - 15s 134ms/step - loss: 0.1103 - sparse_categorical_accuracy: 0.9634 - val_loss: 0.2696 - val_sparse_categorical_accuracy: 0.9440\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.006118143459915612.\n",
      "Epoch 24/100\n",
      "116/116 [==============================] - 15s 133ms/step - loss: 0.0964 - sparse_categorical_accuracy: 0.9646 - val_loss: 0.2817 - val_sparse_categorical_accuracy: 0.9382\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.006016597510373444.\n",
      "Epoch 25/100\n",
      "116/116 [==============================] - 15s 134ms/step - loss: 0.0993 - sparse_categorical_accuracy: 0.9659 - val_loss: 0.2793 - val_sparse_categorical_accuracy: 0.9414\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.005918367346938775.\n",
      "Epoch 26/100\n",
      "116/116 [==============================] - 16s 135ms/step - loss: 0.1052 - sparse_categorical_accuracy: 0.9627 - val_loss: 0.2593 - val_sparse_categorical_accuracy: 0.9453\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.005823293172690763.\n",
      "Epoch 27/100\n",
      "116/116 [==============================] - 15s 133ms/step - loss: 0.0927 - sparse_categorical_accuracy: 0.9671 - val_loss: 0.2726 - val_sparse_categorical_accuracy: 0.9447\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.005731225296442688.\n",
      "Epoch 28/100\n",
      "116/116 [==============================] - 15s 133ms/step - loss: 0.1130 - sparse_categorical_accuracy: 0.9611 - val_loss: 0.2941 - val_sparse_categorical_accuracy: 0.9427\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.005642023346303501.\n",
      "Epoch 29/100\n",
      "116/116 [==============================] - 15s 131ms/step - loss: 0.1041 - sparse_categorical_accuracy: 0.9634 - val_loss: 0.2858 - val_sparse_categorical_accuracy: 0.9375\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 0.005555555555555556.\n",
      "Epoch 30/100\n",
      "116/116 [==============================] - 15s 130ms/step - loss: 0.1044 - sparse_categorical_accuracy: 0.9642 - val_loss: 0.2756 - val_sparse_categorical_accuracy: 0.9479\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 0.005471698113207548.\n",
      "Epoch 31/100\n",
      "116/116 [==============================] - 15s 132ms/step - loss: 0.0955 - sparse_categorical_accuracy: 0.9690 - val_loss: 0.2898 - val_sparse_categorical_accuracy: 0.9408\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 0.005390334572490707.\n",
      "Epoch 32/100\n",
      "116/116 [==============================] - 15s 132ms/step - loss: 0.0930 - sparse_categorical_accuracy: 0.9679 - val_loss: 0.2820 - val_sparse_categorical_accuracy: 0.9447\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 0.005311355311355312.\n",
      "Epoch 33/100\n",
      "116/116 [==============================] - 15s 131ms/step - loss: 0.0883 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.2958 - val_sparse_categorical_accuracy: 0.9473\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 0.005234657039711191.\n",
      "Epoch 34/100\n",
      "116/116 [==============================] - 15s 129ms/step - loss: 0.0947 - sparse_categorical_accuracy: 0.9681 - val_loss: 0.2814 - val_sparse_categorical_accuracy: 0.9453\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 0.0051601423487544484.\n",
      "Epoch 35/100\n",
      " 93/116 [=======================>......] - ETA: 2s - loss: 0.1014 - sparse_categorical_accuracy: 0.9647"
     ]
    }
   ],
   "source": [
    "history = en_model.fit(\n",
    "    train_ds,\n",
    "    steps_per_epoch = train_steps,\n",
    "    epochs = config[\"num_epochs\"],\n",
    "    validation_data = test_ds,\n",
    "    validation_steps = test_steps,\n",
    "    validation_freq = 1,\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc =  str(history.history[\"val_sparse_categorical_accuracy\"][-1])[2:4]\n",
    "en_model.save('./models/{}.h5'.format(model_name+best_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_evaluate = en_model.evaluate(val_ds, verbose=2, steps=val_steps)\n",
    "\n",
    "# Write evaluate dictionary to text file\n",
    "f = open(log_dir+\"/evaluate.txt\",\"w\")\n",
    "f.write( str(en_evaluate) )\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['sparse_categorical_accuracy']\n",
    "val_acc = history.history['val_sparse_categorical_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "if config[\"learning_schedule\"]: lr = history.history['lr']\n",
    "epochs_range = range(history.epoch[-1]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"learning_schedule\"]:\n",
    "    # Plot the learning rate\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(epochs_range, lr, label='Learning Rate')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learnign rate')\n",
    "    plt.savefig(log_dir+'/learning_rate.png')\n",
    "    plt.title('Adaptive Learning Rate');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train-val accuracy and loss\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Subplot 1\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "# plt.ylim([0.5, 1])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# Subplot 2\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylim([0.0, 3])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.savefig(log_dir+'/accuracy_and_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the predictions on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take one batch of validation data\n",
    "for images, labels in val_ds.take(1):\n",
    "    # Take one image and convert it to numpy\n",
    "    img = images.numpy()[0]\n",
    "    lab = labels.numpy()[0]\n",
    "    # Add one dimension\n",
    "    print (\"label:\", class_names[lab], end='\\n\\n')\n",
    "    show_image(img)\n",
    "    img = np.expand_dims(img, 0)\n",
    "    \n",
    "    prediction = en_model.predict(img, verbose=0)\n",
    "    for i, pred in enumerate(prediction[0]):\n",
    "        if pred > 0.01: print(\"{:>5.2f}% {}\".format(pred*100, class_names[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # the last item of parts is the filename\n",
    "    filename = parts[-1]\n",
    "    print (type(filename))\n",
    "    return filename\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [config[\"img_shape\"][0], config[\"img_shape\"][1] ])\n",
    "\n",
    "def process_path(file_path):\n",
    "    filename = get_filename(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the unlabeled `test` dataset (which are images taken from the training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "data_dir_unlabeled_test = pathlib.Path('/mnt/sdb/hyper-kvasir/unlabeled-test/')\n",
    "\n",
    "ds_size_unlabeled_test = len(list(data_dir_unlabeled_test.glob('*.*g')))\n",
    "\n",
    "files_string = str(data_dir_unlabeled_test/'*.*g')\n",
    "list_ds_unlabeled_test = tf.data.Dataset.list_files(files_string)\n",
    "\n",
    "unlabeled_ds_test = list_ds_unlabeled_test.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next hurdle: get access to both dataset sample and prediction.  \n",
    "- Predict one and one image?\n",
    "- Predict all at once?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method works, but predicts one image at a time.. Slow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take one image of unlabeled-test set\n",
    "for img, name in unlabeled_ds_test.take(1):\n",
    "    # Convert to numpy and add dimension\n",
    "    print (\"Filename:\", str(name.numpy())[2:-1], end='\\n\\n')\n",
    "    show_image(img.numpy())\n",
    "    img = np.expand_dims(img.numpy(), 0)\n",
    "    prediction = en_model.predict(img, verbose=0)\n",
    "    for i, pred in enumerate(prediction[0]):\n",
    "        if pred > 0.01: print(\"{:>5.2f}% {}\".format(pred*100, class_names[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the `full` unlabeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_unlabeled = pathlib.Path('/mnt/sdb/hyper-kvasir/unlabeled/')\n",
    "\n",
    "ds_size_unlabeled = len(list(data_dir_unlabeled.glob('*.*g')))\n",
    "\n",
    "files_string = str(data_dir_unlabeled/'*.*g')\n",
    "list_ds_unlabeled = tf.data.Dataset.list_files(files_string)\n",
    "\n",
    "unlabeled_ds = list_ds_unlabeled.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take one image of unlabeled-test set\n",
    "for img, name in unlabeled_ds.take(1):\n",
    "    # Convert to numpy and add dimension\n",
    "    print (\"File:\",str(name.numpy())[2:-1], end='\\n\\n')\n",
    "    show_image(img.numpy())\n",
    "    img = np.expand_dims(img.numpy(), 0)\n",
    "    prediction = en_model.predict(img, verbose=0)\n",
    "    \n",
    "    for i, pred in enumerate(prediction[0]):\n",
    "         if pred > 0.01: print(\"{:>5.2f}% {}\".format(pred*100, class_names[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
