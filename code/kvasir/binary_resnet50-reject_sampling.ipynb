{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kvasir dataset split into neg/pos and trained using resnet50 witouth augmentation. With rejection resampling (see https://www.tensorflow.org/guide/data#resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading images\n",
    "https://www.tensorflow.org/tutorials/load_data/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import IPython.display as display\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL = 'resnet50'\n",
    "DS_INFO = 'binary'\n",
    "NUM_EPOCHS = 2\n",
    "BATCH_SIZE = 1024\n",
    "IMG_HEIGHT = 32  #224\n",
    "IMG_WIDTH = 32\n",
    "\n",
    "NUM_CHANNELS = 3\n",
    "NUM_CLASSES = 2\n",
    "IMG_SIZE = (IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS)\n",
    "\n",
    "# epoch*batch_size*img_size\n",
    "model_name = '{}x{}x{}_{}_{}'.format(NUM_EPOCHS, BATCH_SIZE, IMG_WIDTH, DS_INFO, MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_class_info(names, pos, neg):\n",
    "    # Extract and print info about the class split \n",
    "    \n",
    "    list_class = [pos, neg]\n",
    "    idx = 0\n",
    "    for class_ in list_class:\n",
    "        print (\"{} class names:\".format(names[idx]))\n",
    "        for cl in class_:\n",
    "            print (\"{}- {}\".format(\" \"*8, cl))\n",
    "        idx += 1\n",
    "    \n",
    "    neg_count = 0\n",
    "    pos_count = 0\n",
    "    for class_name in original_class_names:\n",
    "        # Number of samples in 'class_name' folder\n",
    "        class_samples = len(list(data_dir.glob(class_name+'/*.jpg')))\n",
    "\n",
    "        if (class_name == neg_class_name[0]):\n",
    "            neg_count += class_samples\n",
    "        else:\n",
    "            pos_count += class_samples\n",
    "\n",
    "    print ('\\nNegative samples: {0:5} | {1:5.2f}%'.format(neg_count, neg_count/DATASET_SIZE*100))\n",
    "    print ('Positive samples: {0:5} | {1:5.2f}%'.format(pos_count, pos_count/DATASET_SIZE*100))\n",
    "    # Print number of images in dataset (excluded samples in outcast)\n",
    "    print ('\\nTotal number of images:', DATASET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes in data_dir:  ['normal-cecum' 'polyps' 'normal-pylorus' 'esophagitis' 'normal-z-line'\n",
      " 'ulcerative-colitis' 'dyed-resection-margins' 'dyed-lifted-polyps']\n",
      "\n",
      "Removed outcast:  polyps \n",
      "\n",
      "Negative class names:\n",
      "        - normal-cecum\n",
      "        - esophagitis\n",
      "        - normal-z-line\n",
      "        - ulcerative-colitis\n",
      "        - dyed-resection-margins\n",
      "        - dyed-lifted-polyps\n",
      "Positive class names:\n",
      "        - normal-pylorus\n",
      "\n",
      "Negative samples:  1000 | 14.29%\n",
      "Positive samples:  6000 | 85.71%\n",
      "\n",
      "Total number of images: 7000\n"
     ]
    }
   ],
   "source": [
    "# data_dir = pathlib.Path('/mnt/sdb/kvasir-dataset-v2/')\n",
    "data_dir = pathlib.Path('/home/henriklg/master-thesis/data/kvasir-dataset-v2/')\n",
    "outcast = 'polyps'\n",
    "\n",
    "DATASET_SIZE = len(list(data_dir.glob('[!'+str(outcast)+']*/*.jpg')))\n",
    "class_names = np.array([item.name for item in data_dir.glob('*') if item.name != 'metadata.json'])\n",
    "print (\"Classes in data_dir: \", class_names)\n",
    "\n",
    "# Remove outcasts\n",
    "original_class_names = np.delete(class_names, np.where(outcast == class_names))\n",
    "print (\"\\nRemoved outcast: \", outcast, \"\\n\")\n",
    "\n",
    "class_names = np.array(['Negative', 'Positive'])\n",
    "neg_class_name = ['normal-pylorus']\n",
    "pos_class_names = np.delete(original_class_names, np.where(neg_class_name == original_class_names))\n",
    "\n",
    "print_class_info(class_names, pos_class_names, neg_class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset of the file paths | data_dir/*/* but subract class\n",
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'[!')+str(outcast+']*/*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up pipeline for loading images from given list of paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_int(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    bc = parts[-2] == pos_class_names\n",
    "    nz_cnt = tf.math.count_nonzero(bc)\n",
    "    if (nz_cnt > 0):\n",
    "        return tf.reshape(tf.dtypes.cast(tf.fill([1, 1], value=1), tf.int32),[-1])\n",
    "    return tf.reshape(tf.dtypes.cast(tf.fill([1, 1], value=0), tf.int32),[-1])\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label_int(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label\n",
    "\n",
    "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing an example image/label pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD8CAYAAACM5bN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAXRklEQVR4nO2deZBc1XnFz+t9Vs2MRhokoQUJUIHYShAIxhgSwHGcEFJOSJwQB5wKIeUsVMXEzkLFOImx8UKSioEkLlLgSkGcilOuECpJ2dgEmzUWOzaIRWgkJDHS7DPd0+vLH69VGib3fEjtbvEB51c11dL93n193+s+fbvvufd+URzHEEL4I/VWN0AIEUbiFMIpEqcQTpE4hXCKxCmEUyROIZwicb4zuAFADODCI6izoVnnjra3RrQFifNHI17yVwdwAMC3AVzxFrbrIDGA+9/qRojWiDQJ4Ufi4M37dPMxC2AzgJ8HkAbwVwD+4Ci0Y7j5NwqguKR9/4Nwj5oFsAnANIC9HW6faAGJ80fj4M2LlpRfBOCbzX9vBPDq0WrQEixxCufoa21nuA/A80hE+2NLYr8E4AEkPVYJwDMA/hhAPnCe0wDcjUTcZQD7ATwO4K+R9HwHuQFv/M15FQ59cFyAN371vqFZvgH//zfnfzfLTifX9eFm/AtLyocAfBbAD5vXNI3kHryfnEccBhJn5zjYmy7+anIjgK8BOAnAXQC+3DzuRiTCWCy40wA8CuAyAI8AuBnAvyAR6McQFvNBnsShr9o7m/8++He/Ue+O5uOvk/jB8jsXla0HsA3AHzXb9nc4dI3/BeBq4/mERRzH+mv97yBLyy+O47jR/FvfLDu3eexoHMfHLDo2E8fxPc3Ynywq/1Kz7LLA+QfjOE4t+v8NzWMvDLTvftL2Dc34HYvKCnEcT8VxvK/ZrsXHHxPHcS2O421Lyu9vXueHl5QPxHH8ZBzHpTiOR96C1+Zt/6eesz3c0Pz7DIB/RdJjREi+fu5sHvMbzce/BLBvUd0agI8DaAD4zcC5S4Gyyebx7WYBSe88AuCnlsR+Dckg1+Je83QkX5u/DuCflxw/BeBTAAoAfqEDbX3Hk3mrG/AO4VPNxxjJm/K7AG4H8E+LjtnafPx2oP52ALsBHAdgoHmOrwG4FsA3kAj+WwAeBPBym9u+lDuQfBW9EsC9i8qvBFBF8nX8IOc2H5fh0G/ZxaxoPp7U1ha+S5A428PS0doQy5qPzLbYC2Bd87gpAI8BOB/AnwL4RQAfaR73ApLfjne32tg34SEkHxY/B2AQSS+9FcApSD4oDiw6dnnz8ZLmH6O3/c1856OvtUeP6ebjMSS+aslxAPAwgJ9FIpLzAPwFkq+cdwG4uANtPMhXkQw4/XLz/1c2H+9cctzBtl6L5AOK/X20g219xyJxHj2eaD5eGIgdD+BYADuQ9JpLKSPp0f4MwO83yy47jOdsIPmdeKR8tVn3SiQjyL+CpMe8d8lxjzQfz2/hOcSbIHEePf6x+Xg9Dv0WAxLxfBHJa3H7ovLzceir8GJGmo/FQGwp4wDWHlkzAQC7kPw2/nEkveIKJL11dclx30fy+/pDODTgtZRTAaxsoQ3vevSb8+jxEIDPA/gEgGeRDPLMA/hpJL/nvoc3mvsfR2Li3w/gFQBzALY0j58E8A+H8Zz3IZk4cA8SL7KGZALEA4dR904kX51vXPT/EL+KRMi3I+nVH0XS+x+LxKs9BcnA0dhhPKdYhMR5dPkkkq+3v4vE0M8iGX29HsCXAFQWHXsrEhGeg+T3ZgbJiO6tzWN34s25FskI8kUAPoikd/40Dk+c/wbgFgD9SD5MHifH7QZwJoDfQ2KZXIHk28A+AD8A8LdIZkGJI0Rza4Vwin5zCuEUiVMIp0icQjhF4hTCKeZobTqb4qNFDR6KyWS2KDL88Eb9iM8HAFEr41lGO2IY7TCeKzLaaNcjFc1KrT7Xkdez5iVGxgsTt/TCGO2IrH6EP1dkxGz487Fri4ybT19nALVaIxhUzymEUyROIZwicQrhFIlTCKdInEI4ReIUwinm3NoozcfDrZFyXukwW3UEDCzji+wbjfA2O305bqXUa3xrnu7BARrr7zcW+6ctCyl8t0qGdTC+f5LGuvt6aGzj1rNobNVgaHUaUKrXaJ39xaUryA5RqXJL6rgzt9LYQndfsHwsxe9hNPoqjT3ymT+nMYuWHLqWngloNMKelHpOIZwicQrhFIlTCKdInEI4ReIUwikSpxBOsfcQMjb8jw1ZM5vFHp7mA9Hd3TxnT8pakUBWAhgLalA12tGT4xedNyypXFeBxuYWiB1RroTLAQwN9dNYVOBWSrkUyuyQMJMOX3d3gbc9Z9zIWprfq7G9u2js5HPOC5ZvGh4JlgPAnk0baGyowu/jvV/4HI2ZkPdVbL7Dj9xoUc8phFMkTiGcInEK4RSJUwinSJxCOKX1Hd+tkVy2X4oxuheR0UIAyBixhtGQuB6efF1JZ4PlAFCs8IneVeOa68bk9tICHzFs1MMnjY39edJd4cnhALBq1Qoaq2f4y10phEfEu7L8uvqNyehZfhsxNTVPYz3d4f5icN2qYDkAbB7ho9flLSfQ2L1fvInGzCF9NiprDtYe+VR69ZxCOEXiFMIpEqcQTpE4hXCKxCmEUyROIZzSmeS5LeT87Onik9vjmO9HUzP8jVw6FywvssnmADKGJVIzbJtyzUpPwX2F0X3hhM/HrefZ4ufr3JrJ58LXDPDJ7QAQTU8HywtrVvM6ht3QqPO3VmahSGMz5blg+Un9/LpOIzYQAJyS5RP3d257ksZu3no6jbW0wVALddRzCuEUiVMIp0icQjhF4hTCKRKnEE6ROIVwSmesFEJXj7EXUMpYxhBzeyNnWB+VOGx91I0VHz093TQWga9mKde43TNZWqCxkeVDwfL5Iq9jZQG3XtCIrIABgHQufG3VKrdtCjn+ek4Vw5YIAGTTvJXZHa8Hy0vncS9iudXHGKtBPrtlE439zZp1NFbfPcqfr42o5xTCKRKnEE6ROIVwisQphFMkTiGcInEK4ZSOWCnZbPi0P3nBBbTOow9/j8bYfmGAkc4AQEw+e1Ip/pnU3c2tlP0zszSWKfB6PXluwbBVJLOG/bJhFU9NwDY1AwA0+L0qI7x6I2ds4lVr8BcmT7KKA0DdsDe27Xg5WH7S2AFaZ3wobEcBwGpzNQhv4/wrz9BYIRfOAt5u1HMK4RSJUwinSJxCOEXiFMIpEqcQTpE4hXBKR6yUDMkA/ejDD9I6dSPzb7nMLYC68fnCNqDKFIxNsGZ59ueBfp6TY6LI660aHKCxuYVysHz9ykFaJ9/TS2Olcvh8AJBP8euuZsK2Qs1YXVIxzheTFUEAkKnyFUhxI2zdlJ58itaZPJGvLrH6nzgy3jtG+6++5Y5g+Vd+5yqjHUeOek4hnCJxCuEUiVMIp0icQjhF4hTCKVFspE6IohbS8QLo7QvvLZM39o6JjVQBcyW+j43VwCyZVJ7v6aJ1IuPzqru3h8YKxghw2rju/kz4uvfvn+TtaPDRzk1nnEFjcwU+AT9D9lUa7uUjw6kM30OoZLyvpkp8ZHueTLS/4ISNtM45111LYz9jjChH1ooKg4V62D1Y1rW8pfPFJI25ek4hnCJxCuEUiVMIp0icQjhF4hTCKRKnEE7pyMT3z930+WD5H153Ha0TZfmQ9wcuuZjGvnP/AzTWIJPpGxVuReR7+2is0M2tlMmx/TQ2PMDPWSf70Zx12om0zrZtP6Cxqddeo7GujdyOqJKJ3sUKt7F6DCsiJhP6ASCV5/cxNUcm2h+zktbJGJPUrf2K0kb7LROxkOaWVDtRzymEUyROIZwicQrhFIlTCKdInEI4ReIUwikdsVJu/fItwXLLLqkZaQS++R1ul3R1h9MIAECDpF2IjL1jMhmefmB6aorGhoyM2P2DfPv+2f1jwfLsxlW0zrFbNtPYsNH+WcPeSBfISh0jC3i9bqxoMl7r2d27eIzYFJGxumTv6B4aGz2e20cbuQNjEhtpHNqJek4hnCJxCuEUiVMIp0icQjhF4hTCKRKnEE7piJVy0803B8uvvOqjtE5xnm/7f9ttYWsGAD52zW/TWM+ycBqETBdfVTDYx1eQlCvcisgZe0U9+/jTNHbZhy4LlteM50KNp6foG1lBY/PGRmndZBkG38ILSIPbXzPzPDP34CDPRD28LJzyYnLXKK1zXOo8GttlpH7YaKwuIXtuNWltY7AjRT2nEE6ROIVwisQphFMkTiGcInEK4RSJUwindCRXSvdgeIVGBL5iolozVkwY9fI9fLOobpKJOpXiDlKN5MEAgOFhIxdGjdsUa1YM01jfUNhWmJzh1tLqQZ6/BDlufoxPztBYaW94ZcfI8SfQOhljdc8+tlEXgArJOA4AgyMjwfL+YW4RXXRp2I4CgJlVfEXQb42spjEzCQ+hkOfPZaFcKUK8zZA4hXCKxCmEUyROIZwicQrhFIlTCKd0ZFVKox6etR8Zqxgyab6BUyZjpA7P8pUFtXLYFskU+GfSgGHN5AyboqfPsDfyvN5MKWwhjfTz8xUr/D52d3HbCTW+MVWGrN6o1blFVDdeswXeRKxdwy2MLNlobOpAeCM0ANi5byeNrT7mdBrbnuJ+yWbDSjHcx7ainlMIp0icQjhF4hTCKRKnEE6ROIVwSkdGa1vZYcVKkZBOG58hxpNl8+GR3EyKV2IpHACgYcyGzvaH9ysCgKjBRzzjTPgliI37ke/hKSjKZIQaAA7s3k1jx54cnuBeNUZ4UzHfn6dU4e3o7uWpK7LkuseNt+pqsngAAKrzJRp7sThPY5sLfC8pK0VFO1HPKYRTJE4hnCJxCuEUiVMIp0icQjhF4hTCKR2yUsKWQyOyhqC5TWFNNM6n+SXsnwjvmbN2TXifGsC2dOKITyqvVLl1kK7xWeDDfWG7JzY+N7Npfh/HF7i90Zjn1sHU2GSwvHtwkNaZqXCLKBPxdnT18oUAcRy+7mVVfg9nJ8JtB4CZ6SKNRVmjb1rHFx6Yb+M2op5TCKdInEI4ReIUwikSpxBOkTiFcIrEKYRTOmKlVMleQZmGsReQYQ9EWW5hWHsIrVkT3h6/qye8Tw0AZCK+4iOK+XB+yrBL4jxvfz0Xbv/MxCytszzi+xw15rhdkjfSSeTJnkX1GrdExqZ4G7duWkdjqTpf6VIhb4NsF39dYsPbmNr+Ao1VU9z+eum4DTR2vLE/UjtRzymEUyROIZwicQrhFIlTCKdInEI4ReIUwikdsVJSjbB1EKf4GHQ6yzd9ymSNZhrD8hH57Onq5xmIa8ZKi0KWWxiZnNHGtGGllMNWRV8/f65yg9sb5VlupbD0FABQIZtWlScnaJ3CHN88a2gonFUcAMoLCzTWP0Cykfdx+6tY5/fjmDxfXfJ6hb93XjDeB5uMNBTtRD2nEE6ROIVwisQphFMkTiGcInEK4RSJUwindMRKYURk8yYAaBi7eNWMFR+pDN8sKkUySk9Nhjf+AoA+IzN0DP5cVh6VgpGbpcqu28g1kjespSjLh/nzeb6yo1EOZ9iuG2+RnS9up7H3XfJeGstwBwMLJPnNsojf32XGyqS5AW6lZKvhawaAYonbM7N9slKEeFcjcQrhFIlTCKdInEI4ReIUwikdGa199oknguVZYyRx69ln01gOfAT10W/dR2MXXX55uB1GyoXIyFoc5Xg7cjk+Emol5u7qCU9wjxf4SOJ8g49cloxJ4CgYeyfF4Wt7eWw/rbPlg5fSWN2YOJ5fxrOAz9bCo9QrlvPFCmOv8YzdvcuGaaxkZL0uG+kf5lrK3X7kqOcUwikSpxBOkTiFcIrEKYRTJE4hnCJxCuGUzlgpP3wuWH71NdfQOuUGH7puGEPX533g/bwhufBE9XQX36+I1QGArGHpVEtz/JwFfs4qSZ+wYg1PZ1DL8HYMrD2RxsZn+H5AOx99OFi+ct16WsfKbI08t21iYxJ7noSqhu1RGBiisVdfeZnG+lfze/zanr009u/jB2isnajnFMIpEqcQTpE4hXCKxCmEUyROIZwicQrhlJatlLSxL871o+FVKaf+/Y20zmMz+2gsW+WfISXwDWkyZM+iSWMof8LYyygyVrNs/o//pbH0ArccMhtOCD/XmlW0Tm2WZ5Te+dQzNFaemaIxpMN2T5asmgGARsb4bI+43VOZL9LYLGnHxOvcBqrs4itnKkam78a642gMu/n7ca7I7387Uc8phFMkTiGcInEK4RSJUwinSJxCOEXiFMIpra9KMSyH3f3h4fDdU2O0TpafDhVj//7I2Nq/Qd0ebgNZK2DimK+c6TVSJAyccAqNvYBwuoCFF3bSOs89/RSN5Qa49bF8mG92le8Pt6NO0jQAPIM5AMzP81U6DeNd10OslDjFN1B7efQlGlu5YS2NTY3x1SXVKt8o7aXHv09j7UQ9pxBOkTiFcIrEKYRTJE4hnCJxCuEUiVMIp3QmszWxRVLGapCGEQPJ4wEAseGlMFPEcF8QGxZR2sqxsmIjjb1U5tmV893h/DG7tj1G62RzfIOydIZbDsUGtwfiYnilyIGpaVrntHPOorHJCrdgVlqLWebCWcdfHt1D6wz38zwqZeOaM2W+WmjP88/T2PSu12isnajnFMIpEqcQTpE4hXCKxCmEUyROIZzS8mitNeKJiI2TGiOyRqoDux7/fGmwemZiYn5ldeO5Xn36ERrrPusSGlsgo5NlY0S2kOfpHV5/8UUa23DaFhqbLIXbUZmapHXOOPNMGivXFmgstWM7jc2XwmkXTljN91QaK/FR14lxvvdQcYLvBVQe5/sSze3nsXainlMIp0icQjhF4hTCKRKnEE6ROIVwisQphFNatlIsVVMLw/YwOFY1y2Whtgg/Ycq0dDh5I/1Az0LYpgCAkaEVwfK9RZ7JuW5MKs8ZKRIm9ozS2Oye8MTy4bU8s/VXbrmVxi7/yBU09tJTL9DY+mNXBsvnqvyFLlWrNFYs8tj07DiN3fbJT9DYBRf+BI21E/WcQjhF4hTCKRKnEE6ROIVwisQphFMkTiGcEll75kQR39gnbdgbz+x4JVj+nu/eTevElidi2iW8IRmE94+pR5aDxM8XGffqvffyFAlDmzbR2J5a+PNx+4N8D6HZcZ6humd4gMYqRV4vJnvt1Io8rcLIRn5dm9ceS2PdVcMmIq9ZKdNF6xyY5lbV5AxfeTI/zq2U1557jsbqJW5ltUIcx8E3nXpOIZwicQrhFIlTCKdInEI4ReIUwikSpxBO6Ug6hvc8cFewPDxgnGCtBWnQDcOAupHGoRaHL89wRBBZvo3Rjtcn+aZP5e18ZcT6M7YGy7OXXkrrjD3DbZtt/3kPjQ0OD9EYGuGs3RMTPPvzxtNPpbEdL/Fs00P9PGXEcH/YCpqd53bJzCTfxKteMVaszPBzttsuaQX1nEI4ReIUwikSpxBOkTiFcIrEKYRTJE4hnNK6lWLImq0wSdf508UpI/uKYWFY1TIkp0V9ZJi3wzhfyrBZSjM8A/TULF+F8eyL3wiWr998Iq1z7tlh+wUA5nbxjMzLV4Y3zwIA1MOWQzp9Mq2Si8P2CwA08vy17i9wK+V1Yt2UeYJqRGVue1Sn+etyYDu3ezygnlMIp0icQjhF4hTCKRKnEE6ROIVwisQphFNat1IMy2FL//uC5SdPPkHrfD3iG0m1mixlYSSchyRjtN2iYeVYSRm3ssothxSxI+b37KB1Hrp3F4319PbSWFThlk6B7NjWlc7ROny9B5Af4O2YnJ6nsTRZHZM2PK6ozNPOT09N0ph31HMK4RSJUwinSJxCOEXiFMIpEqcQTml5tNbKkPD8zAPB8ueMHA5WOgZrwnk94qN4uQbZQ8gYao6MSfZWG4152cgb45q9Q+FJ4L1dPP1AOpWnsQXj4zZrfBYXp8ITxMs9/JpzBd7GBplIDwCFDL/H1Ua4jekKH/G2RmQnRvfSmHfUcwrhFIlTCKdInEI4ReIUwikSpxBOkTiFcErLma3fFrAR+1avqrX593a9dp/vaLbDotU2en+uDqDM1kK8zZA4hXCKxCmEUyROIZwicQrhFIlTCKeYVooQ4q1DPacQTpE4hXCKxCmEUyROIZwicQrhFIlTCKf8H8agUyGGuZTEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_image(img):\n",
    "    for image, label in img:\n",
    "        plt.figure();\n",
    "        plt.figure(frameon=False, facecolor='white')\n",
    "        plt.title(class_names[label.numpy()][0], fontdict={'color':'white','size':20})\n",
    "        plt.imshow(image.numpy())\n",
    "        plt.axis('off')\n",
    "\n",
    "show_image(labeled_ds.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling the dataset to a 50/50 distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_ds = labeled_ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(counts, batch):\n",
    "        features, labels = batch\n",
    "        class_1 = labels[0] == 1\n",
    "#         class_1 = tf.cast(class_1, tf.uint8)\n",
    "        class_1 = tf.cast(class_1, tf.int32)\n",
    "\n",
    "        class_0 = labels[0] == 0\n",
    "#         class_0 = tf.cast(class_0, tf.uint8)\n",
    "        class_0 = tf.cast(class_0, tf.int32)\n",
    "\n",
    "        counts['class_0'] += tf.reduce_sum(class_0)\n",
    "        counts['class_1'] += tf.reduce_sum(class_1)\n",
    "\n",
    "        return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2857143  0.71428573]\n"
     ]
    }
   ],
   "source": [
    "counts = labeled_ds.take(10).reduce(\n",
    "        initial_state={'class_0': 0, 'class_1': 0},\n",
    "        reduce_func = count)\n",
    "\n",
    "counts = np.array([counts['class_0'].numpy(),\n",
    "                   counts['class_1'].numpy()]).astype(np.float32)\n",
    "\n",
    "fractions = counts/counts.sum()\n",
    "print(fractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.experimental.rejection_resample takes a class_func argument. This class_func is applied to each dataset element, \n",
    "# and is used to determine which class an example belongs to for the purposes of balancing.\n",
    "\n",
    "def class_func(features, label):\n",
    "    return label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The resampler also needs a target distribution, and optionally an initial distribution estimate:\n",
    "\n",
    "resampler = tf.data.experimental.rejection_resample(\n",
    "        class_func, target_dist=[0.5, 0.5], initial_dist=fractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_ds = labeled_ds.unbatch().apply(resampler).batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_ds = resample_ds.map(lambda extra_label, features_and_label: features_and_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 0 1 1 1 1]\n",
      "ones:  8\n",
      "zeros:  2\n",
      "total:  10\n",
      "[1 1 1 0 1 1 1 0 1 1]\n",
      "ones:  8\n",
      "zeros:  2\n",
      "total:  10\n",
      "[1 1 0 1 1 1 1 0 1 1]\n",
      "ones:  8\n",
      "zeros:  2\n",
      "total:  10\n"
     ]
    }
   ],
   "source": [
    "for images, labels in balanced_ds.take(3):\n",
    "    labels = labels.numpy()\n",
    "    total = len(labels)\n",
    "    labels = np.resize(labels,(1,total))[-1]\n",
    "    \n",
    "    ones = np.count_nonzero(labels)\n",
    "    zeros = total - ones\n",
    "    \n",
    "    print (labels)\n",
    "    print (\"ones: \", ones)\n",
    "    print (\"zeros: \", zeros)\n",
    "    print (\"total: \", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99511576 0.00488422]\n"
     ]
    }
   ],
   "source": [
    "# Verify that it has been resampled\n",
    "\n",
    "counts = resample_ds.take(10).reduce(\n",
    "        initial_state={'class_0': 0, 'class_1': 0},\n",
    "        reduce_func = count)\n",
    "\n",
    "counts = np.array([counts['class_0'].numpy(),\n",
    "                   counts['class_1'].numpy()]).astype(np.float32)\n",
    "\n",
    "fractions = counts/counts.sum()\n",
    "print(fractions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into training, test and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "val_size = int(0.15 * DATASET_SIZE)\n",
    "test_size = int(0.15 * DATASET_SIZE)\n",
    "\n",
    "shuffled_ds = labeled_ds#.shuffle(buffer_size=10000)\n",
    "\n",
    "train_ds = shuffled_ds.take(train_size)\n",
    "test_ds = shuffled_ds.skip(train_size)\n",
    "val_ds = test_ds.skip(val_size)\n",
    "test_ds = test_ds.take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print info about the dataset split\n",
    "def get_size(ds):\n",
    "    return tf.data.experimental.cardinality(ds).numpy()\n",
    "\n",
    "print (\"{:32} {:>5}\".format(\"Full dataset sample size:\", get_size(shuffled_ds)))\n",
    "print (\"{:32} {:>5}\".format(\"Train dataset sample size:\", get_size(train_ds)))\n",
    "print (\"{:32} {:>5}\".format(\"Test dataset sample size:\", get_size(test_ds)))\n",
    "print (\"{:32} {:>5}\".format(\"Validation dataset sample size:\", get_size(val_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=3000):\n",
    "    # This is a small dataset, only load it once, and keep it in memory.\n",
    "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "    # fit in memory.\n",
    "    if cache:\n",
    "      if isinstance(cache, str):\n",
    "        ds = ds.cache(cache)\n",
    "      else:\n",
    "        ds = ds.cache()\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    # Repeat forever\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# Create training, test and validation dataset\n",
    "train_ds = prepare_for_training(train_ds, cache=\"./cache/train_{}.tfcache\".format(IMG_WIDTH))\n",
    "test_ds = prepare_for_training(test_ds, cache=\"./cache/test_{}.tfcache\".format(IMG_WIDTH))\n",
    "val_ds = prepare_for_training(val_ds, cache=\"./cache/val_{}.tfcache\".format(IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "https://adventuresinmachinelearning.com/transfer-learning-tensorflow-2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_net = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_net.trainable = False\n",
    "\n",
    "global_average_layer = layers.GlobalAveragePooling2D()\n",
    "output_layer = layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "tl_model = tf.keras.Sequential([\n",
    "        res_net,\n",
    "        global_average_layer,\n",
    "        output_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./logs/transfer_learning_model', update_freq='batch')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = tl_model.fit(\n",
    "        train_ds,\n",
    "        steps_per_epoch = train_size // BATCH_SIZE,\n",
    "        epochs = NUM_EPOCHS,\n",
    "        validation_data = test_ds,\n",
    "        validation_steps = test_size // BATCH_SIZE,\n",
    "        validation_freq = 1,\n",
    "        callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Keras`\n",
    "Save/load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_model.save('models/{}.h5'.format(model_name))\n",
    "# tl_model = tf.keras.models.load_model('models/{}.h5'.format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the results\n",
    "\n",
    "`Tensorboard`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs (move to .old instead?)\n",
    "# !rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tensorboard import notebook\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "notebook.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kill 20058"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tl_model.evaluate(\n",
    "            val_ds,\n",
    "            steps = val_size//BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch one batch\n",
    "images, labels = next(iter(val_ds))\n",
    "\n",
    "# Convert from tensor to numpy array\n",
    "images = images.numpy()\n",
    "labels = labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random image and label\n",
    "idx = np.random.randint(0, BATCH_SIZE)\n",
    "idx = 4\n",
    "image = images[idx]\n",
    "label = labels[idx]\n",
    "\n",
    "# Predict one image\n",
    "result = tl_model.predict(np.expand_dims(image, axis=0))[0][0]\n",
    "\n",
    "print (\"True label:\", class_names[label[0]])\n",
    "print ('Probabibity of Positive: {:.5f}%'.format((result)*100))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(image)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict one batch\n",
    "results = tl_model.predict(images)\n",
    "\n",
    "print ('{:3}  {:7}  {:3}%'.format('idx', 'true_label', 'pred_prob'))\n",
    "print ('---  ---------   ----------')\n",
    "idx = 0\n",
    "for result in results:\n",
    "    true_label = class_names[labels[idx]][0]\n",
    "    pred_prob = result[0]\n",
    "    print ('{:3}  {:10}  {:05f}%'.format(idx, true_label, pred_prob))\n",
    "    idx += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
