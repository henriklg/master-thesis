{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kvasir V2 dataset trained on all classes with resnet50 without augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading images\n",
    "https://www.tensorflow.org/tutorials/load_data/images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Some stuff to make utils-function work\n",
    "import sys\n",
    "sys.path.append('/home/henrik/master_thesis/code/utils')\n",
    "from data_prep import create_dataset, print_class_info, show_image\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Jupyter-specific\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('/mnt/sdb/kvasir-dataset-v2/')\n",
    "\n",
    "config = {\n",
    "    \"data_dir\": data_dir,\n",
    "    \"cache_dir\": \"./cache\",\n",
    "    \"MODEL\": 'resnet50',\n",
    "    \"DS_INFO\": 'complete',\n",
    "    \"resample\": False,\n",
    "    \"neg_class\": ['polyp'],\n",
    "    \"NUM_EPOCHS\": 100,\n",
    "    \"BATCH_SIZE\": 64,\n",
    "    \"IMG_SIZE\": (32, 32, 3),\n",
    "    \"outcast\": None,\n",
    "    \"verbosity\": 1\n",
    "    }\n",
    "\n",
    "model_name = '{}x{}x{}_{}_{}'.format(config[\"NUM_EPOCHS\"], config[\"BATCH_SIZE\"], \n",
    "                                     config[\"IMG_SIZE\"][1], config[\"DS_INFO\"], config[\"MODEL\"])\n",
    "\n",
    "learning_rate = 0.01\n",
    "fine_tune_at = 130\n",
    "fine_tune_epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training, testing and validation dataset from utils/data_prep.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories:  ['esophagitis' 'normal-pylorus' 'ulcerative-colitis' 'normal-cecum'\n",
      " 'normal-z-line' 'polyps' 'dyed-resection-margins' 'dyed-lifted-polyps']\n",
      "\n",
      "esophagitis       : 1000\n",
      "normal-pylorus    : 1000\n",
      "ulcerative-colitis: 1000\n",
      "normal-cecum      : 1000\n",
      "normal-z-line     : 1000\n",
      "polyps            : 1000\n",
      "dyed-resection-margins: 1000\n",
      "dyed-lifted-polyps: 1000\n",
      "\n",
      "Total number of images: 8000, in 8 classes\n",
      "Dataset.list_files:  /mnt/sdb/kvasir-dataset-v2/*/*.*g \n",
      "\n",
      "WARNING:tensorflow:Entity <function create_dataset.<locals>.get_label at 0x7fbeef3cdd40> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Cell is empty\n",
      "WARNING: Entity <function create_dataset.<locals>.get_label at 0x7fbeef3cdd40> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Cell is empty\n",
      "[6 1 4 5 1 5 7 0 3 5]\n",
      "[4 4 3 3 7 2 3 3 6 2]\n",
      "[3 6 1 4 1 4 0 1 3 7]\n",
      "[7 2 7 1 0 5 4 3 5 0]\n",
      "[7 2 3 3 0 5 5 4 7 4]\n",
      "[0 6 2 6 2 3 1 3 7 6]\n",
      "[1 0 4 5 3 3 6 7 4 0]\n",
      "[4 3 1 5 4 4 4 7 7 1]\n",
      "[1 0 4 4 5 5 0 7 7 6]\n",
      "[5 3 7 2 3 2 4 6 3 6]\n",
      "\n",
      "Full dataset sample size:         8000\n",
      "Train dataset sample size:        5600\n",
      "Test dataset sample size:         1200\n",
      "Validation dataset sample size:   1200\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds, val_ds, params = create_dataset(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet50 transfer learning\n",
    "see: https://adventuresinmachinelearning.com/transfer-learning-tensorflow-2/  \n",
    "fine-tuning: https://www.tensorflow.org/tutorials/images/transfer_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 32, 32, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for image_batch, label_batch in train_ds.take(1):\n",
    "    pass\n",
    "\n",
    "image_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.ResNet50(\n",
    "                weights='imagenet', \n",
    "                include_top=False, \n",
    "                input_shape=config[\"IMG_SIZE\"])\n",
    "\n",
    "feature_batch = base_model(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "global_average_layer = layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "\n",
    "\n",
    "prediction_layer = layers.Dense(params[\"NUM_CLASSES\"], activation='softmax')\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "\n",
    "resnet50_model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        global_average_layer,\n",
    "        prediction_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 1, 1, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 16392     \n",
      "=================================================================\n",
      "Total params: 23,604,104\n",
      "Trainable params: 23,550,984\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if config[\"verbosity\"] > 0:\n",
    "    resnet50_model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Save image of layers\n",
    "tf.keras.utils.plot_model(resnet50_model, 'models/{}.png'.format(model_name), show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "resnet50_model.compile(\n",
    "        optimizer=opt,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "callbacks = [tf.keras.callbacks.TensorBoard(\n",
    "                log_dir='./logs/resnet50_model', \n",
    "                update_freq='batch')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 87 steps, validate for 18 steps\n",
      "Epoch 1/100\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 4.3013 - accuracy: 0.1620 - val_loss: 27157515.1111 - val_accuracy: 0.1363\n",
      "Epoch 2/100\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 3.2259 - accuracy: 0.2051 - val_loss: 2.0877 - val_accuracy: 0.1267\n",
      "Epoch 3/100\n",
      "87/87 [==============================] - 4s 43ms/step - loss: 2.2194 - accuracy: 0.2920 - val_loss: 2.8408 - val_accuracy: 0.1293\n",
      "Epoch 4/100\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 4.0288 - accuracy: 0.2821 - val_loss: 341564.5260 - val_accuracy: 0.1285\n",
      "Epoch 5/100\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 2.0620 - accuracy: 0.2940 - val_loss: 4.4817 - val_accuracy: 0.1658\n",
      "Epoch 6/100\n",
      "87/87 [==============================] - 4s 42ms/step - loss: 1.7168 - accuracy: 0.3628 - val_loss: 5.7315 - val_accuracy: 0.1181\n",
      "Epoch 7/100\n",
      "81/87 [==========================>...] - ETA: 0s - loss: 1.3412 - accuracy: 0.4657"
     ]
    }
   ],
   "source": [
    "history = resnet50_model.fit(\n",
    "        train_ds,\n",
    "        steps_per_epoch = params[\"train_size\"] // config[\"BATCH_SIZE\"],\n",
    "        epochs = config[\"NUM_EPOCHS\"],\n",
    "        validation_data = test_ds,\n",
    "        validation_steps = params[\"test_size\"] // config[\"BATCH_SIZE\"],\n",
    "        validation_freq = 1,\n",
    "        callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Keras`\n",
    "Save/load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet50_model.save('models/{}.h5'.format(model_name))\n",
    "# resnet50_model = tf.keras.models.load_model('models/{}.h5'.format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_evaluate = resnet50_model.evaluate(val_ds, verbose=2, steps=params[\"val_size\"] // config[\"BATCH_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(config[\"NUM_EPOCHS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Subplot 1\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "# plt.ylim([0.5, 1])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# Subplot 2\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "# plt.ylim([0.5, 1])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = fine_tune_at\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate/10)\n",
    "\n",
    "resnet50_model.compile(\n",
    "        optimizer=opt,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(resnet50_model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_epochs = fine_tune_epochs\n",
    "total_epochs = config[\"NUM_EPOCHS\"] + fine_tune_epochs\n",
    "\n",
    "history_fine = resnet50_model.fit(\n",
    "        train_ds,\n",
    "        steps_per_epoch = params[\"train_size\"] // config[\"BATCH_SIZE\"],\n",
    "        epochs = total_epochs,\n",
    "        initial_epoch = history.epoch[-1],\n",
    "        validation_data = test_ds,\n",
    "        validation_steps = params[\"test_size\"] // config[\"BATCH_SIZE\"],\n",
    "        validation_freq = 1,\n",
    "        callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For fine-tuning\n",
    "acc += history_fine.history['accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "# plt.ylim([0.2, 1])\n",
    "plt.plot([config[\"NUM_EPOCHS\"]-1,config[\"NUM_EPOCHS\"]-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.ylim([0, 3.0])\n",
    "plt.plot([config[\"NUM_EPOCHS\"]-1,config[\"NUM_EPOCHS\"]-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Tensorboard`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tensorboard import notebook\n",
    "# Load the TensorBoard notebook extension\n",
    "# %load_ext tensorboard\n",
    "\n",
    "# Start tensorboard\n",
    "# %tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Clear any logs from previous runs (move to .old instead?)\n",
    "!rm -rf ./logs/\n",
    "\n",
    "# Stop tensorboard\n",
    "notebook.list()\n",
    "!kill 20058"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch one batch\n",
    "images, labels = next(iter(val_ds))\n",
    "\n",
    "# Convert from tensor to numpy array\n",
    "images = images.numpy()\n",
    "labels = labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random image and label\n",
    "rand = np.random.randint(0, config[\"BATCH_SIZE\"])\n",
    "image = images[rand]\n",
    "label = labels[rand]\n",
    "\n",
    "# Predict one image\n",
    "predictions = resnet50_model.predict(np.expand_dims(image, axis=0))[0]\n",
    "\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(\"{:0.4f} {}\".format(pred,params[\"class_names\"][i]))\n",
    "\n",
    "print (\"\\nLabel:\", params[\"class_names\"][label])\n",
    "print (\"Predicton:\", params[\"class_names\"][np.argmax(predictions)])\n",
    "\n",
    "plt.figure(frameon=False, facecolor='white')\n",
    "plt.imshow(image)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict one batch\n",
    "predictions = resnet50_model.predict(images)\n",
    "\n",
    "print ('{:3}  {:<25} {:25}'.format('idx', 'label', 'pred'))\n",
    "print ('---  {} {}'.format(25*'-', 25*'-'), end='')\n",
    "\n",
    "for i, pred in enumerate(predictions):\n",
    "    label = params[\"class_names\"][labels[i]]\n",
    "    prediction = params[\"class_names\"][np.argmax(pred)]\n",
    "    print ('\\n{:3}  {:25} {:25}'.format(i, label, prediction), end='')\n",
    "    if (label != prediction): print (\"  Wrong\", end='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
