{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kvasir dataset split into neg/pos and trained using resnet50 without augmentation. With rejection resampling (see https://www.tensorflow.org/guide/data#resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading images\n",
    "https://www.tensorflow.org/tutorials/load_data/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import IPython.display as display\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL = 'resnet56' \n",
    "DS_INFO = 'binary'\n",
    "NUM_EPOCHS = 60\n",
    "BATCH_SIZE = 64\n",
    "IMG_HEIGHT = 32  #224\n",
    "IMG_WIDTH = 32\n",
    "\n",
    "NUM_CHANNELS = 3\n",
    "NUM_CLASSES = 2\n",
    "IMG_SIZE = (IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS)\n",
    "\n",
    "# Resnet56-specific variables\n",
    "NUM_GPUS = 1\n",
    "BS_PER_GPU = 128\n",
    "BASE_LEARNING_RATE = 0.1\n",
    "LR_SCHEDULE = [(0.1, 30), (0.01, 45)]\n",
    "\n",
    "# epoch*batch_size*img_size\n",
    "model_name = '{}x{}x{}_{}_{}'.format(NUM_EPOCHS, BATCH_SIZE, IMG_WIDTH, DS_INFO, MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_class_info(class_names, neg, pos):\n",
    "    # Extract and print info about the class split \n",
    "    \n",
    "    idx = 0\n",
    "    for class_ in [neg, pos]:\n",
    "        print (\"{} class names:\".format(class_names[idx]))\n",
    "        for cl in class_:\n",
    "            print (\"{}- {}\".format(\" \"*8, cl))\n",
    "        idx += 1\n",
    "    \n",
    "    neg_count = pos_count = 0\n",
    "    for dir_name in original_class_names:\n",
    "        # Number of samples in 'class_name' folder\n",
    "        class_samples = len(list(data_dir.glob(dir_name+'/*.*g')))\n",
    "\n",
    "        if (dir_name == neg_class_name[0]):\n",
    "            neg_count += class_samples\n",
    "        else:\n",
    "            pos_count += class_samples\n",
    "\n",
    "    print ('\\nNegative samples: {0:5} | {1:5.2f}%'.format(neg_count, neg_count/DATASET_SIZE*100))\n",
    "    print ('Positive samples: {0:5} | {1:5.2f}%'.format(pos_count, pos_count/DATASET_SIZE*100))\n",
    "    # Print number of images in dataset (excluded samples in outcast)\n",
    "    print ('\\nTotal number of images:', DATASET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes in data_dir:  ['cat' 'airplane' 'deer' 'automobile' 'ship' 'horse' 'truck' 'dog' 'bird'\n",
      " 'frog']\n",
      "\n",
      "Removed outcast:  None \n",
      "\n",
      "Negative class names:\n",
      "        - ship\n",
      "Positive class names:\n",
      "        - cat\n",
      "        - airplane\n",
      "        - deer\n",
      "        - automobile\n",
      "        - horse\n",
      "        - truck\n",
      "        - dog\n",
      "        - bird\n",
      "        - frog\n",
      "\n",
      "Negative samples:  5000 | 10.00%\n",
      "Positive samples: 45000 | 90.00%\n",
      "\n",
      "Total number of images: 50000\n"
     ]
    }
   ],
   "source": [
    "data_dir = pathlib.Path('/mnt/sdb/cifar10/train/')\n",
    "# data_dir = pathlib.Path('/home/henriklg/master-thesis/data/kvasir-dataset-v2/')\n",
    "outcast = 'None'\n",
    "\n",
    "DATASET_SIZE = len(list(data_dir.glob('[!'+str(outcast)+']*/*.*g')))\n",
    "class_names = np.array([item.name for item in data_dir.glob('*') if item.name != 'metadata.json'])\n",
    "print (\"Classes in data_dir: \", class_names)\n",
    "\n",
    "# Remove outcasts\n",
    "original_class_names = np.delete(class_names, np.where(outcast == class_names))\n",
    "print (\"\\nRemoved outcast: \", outcast, \"\\n\")\n",
    "\n",
    "class_names = np.array(['Negative','Positive'])\n",
    "neg_class_name = ['ship'] # 'normal'-class\n",
    "pos_class_names = np.delete(original_class_names, np.where(neg_class_name == original_class_names))\n",
    "\n",
    "print_class_info(class_names, neg_class_name, pos_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset of the file paths | data_dir/*/* but subract class\n",
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'[!')+str(outcast+']*/*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up pipeline for loading images from given list of paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    bc = parts[-2] == pos_class_names\n",
    "    nz_cnt = tf.math.count_nonzero(bc)\n",
    "    if (nz_cnt > 0):\n",
    "        return tf.constant(1, tf.int32)\n",
    "    return tf.constant(0, tf.int32)\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label\n",
    "\n",
    "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing an example image/label pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_image(img):\n",
    "    if (isinstance(img, tf.data.Dataset)):\n",
    "        for image, label in img:\n",
    "            plt.figure(frameon=False, facecolor='white')\n",
    "            title = class_names[label.numpy()]+\" [\"+str(label.numpy())+\"]\"\n",
    "            plt.title(title, fontdict={'color':'white','size':20})\n",
    "            plt.imshow(image.numpy())\n",
    "            plt.axis('off')\n",
    "    else:\n",
    "        plt.figure(frameon=False, facecolor='white')\n",
    "        plt.title(\"None\", fontdict={'color':'white','size':20})\n",
    "        plt.imshow(img.numpy())\n",
    "        plt.axis('off')\n",
    "\n",
    "# Take one image\n",
    "show_image(labeled_ds.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling the dataset to a 50/50 distribution\n",
    "https://www.tensorflow.org/guide/data#resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make large batches to be certain a good amount of minority class makes it in\n",
    "labeled_ds = labeled_ds.batch(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(counts, batch):\n",
    "        images, labels = batch\n",
    "        \n",
    "        class_1 = labels == 1\n",
    "        class_1 = tf.cast(class_1, tf.int32)\n",
    "\n",
    "        class_0 = labels == 0\n",
    "        class_0 = tf.cast(class_0, tf.int32)\n",
    "\n",
    "        counts['class_0'] += tf.reduce_sum(class_0)\n",
    "        counts['class_1'] += tf.reduce_sum(class_1)\n",
    "\n",
    "        return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fractions:  [0.10009766 0.89990234]\n",
      "Counts:  [1025. 9215.]\n"
     ]
    }
   ],
   "source": [
    "counts = labeled_ds.take(10).reduce(\n",
    "        initial_state={'class_0': 0, 'class_1': 0},\n",
    "        reduce_func = count)\n",
    "\n",
    "counts = np.array([counts['class_0'].numpy(),\n",
    "                   counts['class_1'].numpy()]).astype(np.float32)\n",
    "\n",
    "counts_sum = counts.sum()\n",
    "assert counts_sum != 0, \"Can't divide by zero\"\n",
    "\n",
    "fractions = counts/counts_sum\n",
    "print(\"Fractions: \", fractions)\n",
    "print(\"Counts: \", counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_ds = labeled_ds.unbatch().filter(lambda image, label: label==0).repeat()\n",
    "positive_ds = labeled_ds.unbatch().filter(lambda image, label: label==1).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_ds = tf.data.experimental.sample_from_datasets(\n",
    "    [negative_ds, positive_ds], [0.5, 0.5]).batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 1 1 0 1 1]\n",
      "[0 0 0 1 0 1 0 0 1 0]\n",
      "[1 0 0 1 1 0 1 0 0 1]\n",
      "[0 1 1 1 0 0 1 0 0 1]\n",
      "[1 0 0 1 1 0 0 1 1 1]\n",
      "[1 0 0 1 1 1 1 1 1 0]\n",
      "[0 0 0 0 0 1 0 1 1 1]\n",
      "[1 0 0 1 1 1 1 0 1 1]\n",
      "[1 1 1 1 0 0 0 0 1 0]\n",
      "[0 1 1 1 0 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "for features, labels in balanced_ds.take(10):\n",
    "  print(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47666666 0.5233333 ]\n"
     ]
    }
   ],
   "source": [
    "# Verify that it has been resampled\n",
    "counts = balanced_ds.take(30).reduce(\n",
    "        initial_state={'class_0': 0, 'class_1': 0},\n",
    "        reduce_func = count)\n",
    "\n",
    "counts = np.array([counts['class_0'].numpy(),\n",
    "                   counts['class_1'].numpy()]).astype(np.float32)\n",
    "\n",
    "print(counts/counts.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into training, test and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "val_size = int(0.15 * DATASET_SIZE)\n",
    "test_size = int(0.15 * DATASET_SIZE)\n",
    "\n",
    "shuffled_ds = balanced_ds.unbatch()#.shuffle(buffer_size=10000)\n",
    "\n",
    "train_ds = shuffled_ds.take(train_size)\n",
    "test_ds = shuffled_ds.skip(train_size)\n",
    "val_ds = test_ds.skip(val_size)\n",
    "test_ds = test_ds.take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset sample size:           -2\n",
      "Train dataset sample size:          -2\n",
      "Test dataset sample size:           -2\n",
      "Validation dataset sample size:     -2\n"
     ]
    }
   ],
   "source": [
    "# Print info about the dataset split\n",
    "def get_size(ds):\n",
    "    return tf.data.experimental.cardinality(ds).numpy()\n",
    "\n",
    "print (\"{:32} {:>5}\".format(\"Full dataset sample size:\", get_size(shuffled_ds)))\n",
    "print (\"{:32} {:>5}\".format(\"Train dataset sample size:\", get_size(train_ds)))\n",
    "print (\"{:32} {:>5}\".format(\"Test dataset sample size:\", get_size(test_ds)))\n",
    "print (\"{:32} {:>5}\".format(\"Validation dataset sample size:\", get_size(val_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=3000):\n",
    "    # This is a small dataset, only load it once, and keep it in memory.\n",
    "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "    # fit in memory.\n",
    "    if cache:\n",
    "      if isinstance(cache, str):\n",
    "        ds = ds.cache(cache)\n",
    "      else:\n",
    "        ds = ds.cache()\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    # Repeat forever\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# Create training, test and validation dataset\n",
    "train_ds = prepare_for_training(train_ds, cache=\"./cache/{}_train.tfcache\".format(IMG_WIDTH))\n",
    "test_ds = prepare_for_training(test_ds, cache=\"./cache/{}_test.tfcache\".format(IMG_WIDTH))\n",
    "val_ds = prepare_for_training(val_ds, cache=\"./cache/{}_val.tfcache\".format(IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet56 (no transfer learning)\n",
    "See https://lambdalabs.com/blog/tensorflow-2-0-tutorial-01-image-classification-basics/\n",
    "\n",
    "https://github.com/lambdal/TensorFlow2-tutorial/tree/master/01-basic-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resnet\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/home/henrik/anaconda3/envs/TF2/bin:/home/henrik/anaconda3/envs/TF2/bin:/home/henrik/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/henrik/.dotnet/tools\n"
     ]
    }
   ],
   "source": [
    "PATH = os.getenv('PATH')\n",
    "%env PATH=/home/henrik/anaconda3/envs/TF2/bin:$PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule(epoch):\n",
    "    initial_learning_rate = BASE_LEARNING_RATE * BS_PER_GPU / 128\n",
    "    learning_rate = initial_learning_rate\n",
    "    for mult, start_epoch in LR_SCHEDULE:\n",
    "        if epoch >= start_epoch:\n",
    "            learning_rate = initial_learning_rate * mult\n",
    "        else:\n",
    "            break\n",
    "    tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "    return learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS)\n",
    "img_input = tf.keras.layers.Input(shape=input_shape)\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "\n",
    "if NUM_GPUS == 1:\n",
    "    resnet56_model = resnet.resnet56(img_input=img_input, classes=NUM_CLASSES)\n",
    "    resnet56_model.compile(\n",
    "              optimizer=opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "else:\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():\n",
    "        resnet56_model = resnet.resnet56(img_input=img_input, classes=NUM_CLASSES)\n",
    "        resnet56_model.compile(\n",
    "                optimizer=opt,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['sparse_categorical_accuracy'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet56\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 34, 34, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, 32, 16)   448         conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 32, 32, 16)   64          conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 16)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res2block_0_branch2a (Conv2D)   (None, 32, 32, 16)   2320        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn2block_0_branch2a (BatchNorma (None, 32, 32, 16)   64          res2block_0_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           bn2block_0_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2block_0_branch2b (Conv2D)   (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2block_0_branch1 (Conv2D)    (None, 32, 32, 16)   272         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn2block_0_branch2b (BatchNorma (None, 32, 32, 16)   64          res2block_0_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn2block_0_branch1 (BatchNormal (None, 32, 32, 16)   64          res2block_0_branch1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 32, 16)   0           bn2block_0_branch2b[0][0]        \n",
      "                                                                 bn2block_0_branch1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res2block_1_branch2a (Conv2D)   (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2block_1_branch2a (BatchNorma (None, 32, 32, 16)   64          res2block_1_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           bn2block_1_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2block_1_branch2b (Conv2D)   (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2block_1_branch2b (BatchNorma (None, 32, 32, 16)   64          res2block_1_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 16)   0           bn2block_1_branch2b[0][0]        \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2block_2_branch2a (Conv2D)   (None, 32, 32, 16)   2320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2block_2_branch2a (BatchNorma (None, 32, 32, 16)   64          res2block_2_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 16)   0           bn2block_2_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2block_2_branch2b (Conv2D)   (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2block_2_branch2b (BatchNorma (None, 32, 32, 16)   64          res2block_2_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 16)   0           bn2block_2_branch2b[0][0]        \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2block_3_branch2a (Conv2D)   (None, 32, 32, 16)   2320        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2block_3_branch2a (BatchNorma (None, 32, 32, 16)   64          res2block_3_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 16)   0           bn2block_3_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2block_3_branch2b (Conv2D)   (None, 32, 32, 16)   2320        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2block_3_branch2b (BatchNorma (None, 32, 32, 16)   64          res2block_3_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 16)   0           bn2block_3_branch2b[0][0]        \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2block_4_branch2a (Conv2D)   (None, 32, 32, 16)   2320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2block_4_branch2a (BatchNorma (None, 32, 32, 16)   64          res2block_4_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 16)   0           bn2block_4_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2block_4_branch2b (Conv2D)   (None, 32, 32, 16)   2320        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2block_4_branch2b (BatchNorma (None, 32, 32, 16)   64          res2block_4_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 16)   0           bn2block_4_branch2b[0][0]        \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 16)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2block_5_branch2a (Conv2D)   (None, 32, 32, 16)   2320        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2block_5_branch2a (BatchNorma (None, 32, 32, 16)   64          res2block_5_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 16)   0           bn2block_5_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2block_5_branch2b (Conv2D)   (None, 32, 32, 16)   2320        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2block_5_branch2b (BatchNorma (None, 32, 32, 16)   64          res2block_5_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 16)   0           bn2block_5_branch2b[0][0]        \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 16)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2block_6_branch2a (Conv2D)   (None, 32, 32, 16)   2320        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2block_6_branch2a (BatchNorma (None, 32, 32, 16)   64          res2block_6_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 16)   0           bn2block_6_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2block_6_branch2b (Conv2D)   (None, 32, 32, 16)   2320        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2block_6_branch2b (BatchNorma (None, 32, 32, 16)   64          res2block_6_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 32, 16)   0           bn2block_6_branch2b[0][0]        \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 16)   0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2block_7_branch2a (Conv2D)   (None, 32, 32, 16)   2320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2block_7_branch2a (BatchNorma (None, 32, 32, 16)   64          res2block_7_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 16)   0           bn2block_7_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2block_7_branch2b (Conv2D)   (None, 32, 32, 16)   2320        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2block_7_branch2b (BatchNorma (None, 32, 32, 16)   64          res2block_7_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 16)   0           bn2block_7_branch2b[0][0]        \n",
      "                                                                 activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 16)   0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2block_8_branch2a (Conv2D)   (None, 32, 32, 16)   2320        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2block_8_branch2a (BatchNorma (None, 32, 32, 16)   64          res2block_8_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 16)   0           bn2block_8_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2block_8_branch2b (Conv2D)   (None, 32, 32, 16)   2320        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2block_8_branch2b (BatchNorma (None, 32, 32, 16)   64          res2block_8_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 32, 16)   0           bn2block_8_branch2b[0][0]        \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 16)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3block_0_branch2a (Conv2D)   (None, 16, 16, 32)   4640        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3block_0_branch2a (BatchNorma (None, 16, 16, 32)   128         res3block_0_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 32)   0           bn3block_0_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3block_0_branch2b (Conv2D)   (None, 16, 16, 32)   9248        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3block_0_branch1 (Conv2D)    (None, 16, 16, 32)   544         activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3block_0_branch2b (BatchNorma (None, 16, 16, 32)   128         res3block_0_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn3block_0_branch1 (BatchNormal (None, 16, 16, 32)   128         res3block_0_branch1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 32)   0           bn3block_0_branch2b[0][0]        \n",
      "                                                                 bn3block_0_branch1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 32)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3block_1_branch2a (Conv2D)   (None, 16, 16, 32)   9248        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3block_1_branch2a (BatchNorma (None, 16, 16, 32)   128         res3block_1_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 32)   0           bn3block_1_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3block_1_branch2b (Conv2D)   (None, 16, 16, 32)   9248        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3block_1_branch2b (BatchNorma (None, 16, 16, 32)   128         res3block_1_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 32)   0           bn3block_1_branch2b[0][0]        \n",
      "                                                                 activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 32)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3block_2_branch2a (Conv2D)   (None, 16, 16, 32)   9248        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3block_2_branch2a (BatchNorma (None, 16, 16, 32)   128         res3block_2_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 32)   0           bn3block_2_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3block_2_branch2b (Conv2D)   (None, 16, 16, 32)   9248        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3block_2_branch2b (BatchNorma (None, 16, 16, 32)   128         res3block_2_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 32)   0           bn3block_2_branch2b[0][0]        \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 32)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3block_3_branch2a (Conv2D)   (None, 16, 16, 32)   9248        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3block_3_branch2a (BatchNorma (None, 16, 16, 32)   128         res3block_3_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 32)   0           bn3block_3_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3block_3_branch2b (Conv2D)   (None, 16, 16, 32)   9248        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3block_3_branch2b (BatchNorma (None, 16, 16, 32)   128         res3block_3_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 16, 16, 32)   0           bn3block_3_branch2b[0][0]        \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 32)   0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3block_4_branch2a (Conv2D)   (None, 16, 16, 32)   9248        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3block_4_branch2a (BatchNorma (None, 16, 16, 32)   128         res3block_4_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 32)   0           bn3block_4_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3block_4_branch2b (Conv2D)   (None, 16, 16, 32)   9248        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3block_4_branch2b (BatchNorma (None, 16, 16, 32)   128         res3block_4_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 32)   0           bn3block_4_branch2b[0][0]        \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 32)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3block_5_branch2a (Conv2D)   (None, 16, 16, 32)   9248        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3block_5_branch2a (BatchNorma (None, 16, 16, 32)   128         res3block_5_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 32)   0           bn3block_5_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3block_5_branch2b (Conv2D)   (None, 16, 16, 32)   9248        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3block_5_branch2b (BatchNorma (None, 16, 16, 32)   128         res3block_5_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 16, 16, 32)   0           bn3block_5_branch2b[0][0]        \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 32)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3block_6_branch2a (Conv2D)   (None, 16, 16, 32)   9248        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3block_6_branch2a (BatchNorma (None, 16, 16, 32)   128         res3block_6_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 32)   0           bn3block_6_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3block_6_branch2b (Conv2D)   (None, 16, 16, 32)   9248        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3block_6_branch2b (BatchNorma (None, 16, 16, 32)   128         res3block_6_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 16, 16, 32)   0           bn3block_6_branch2b[0][0]        \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 32)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3block_7_branch2a (Conv2D)   (None, 16, 16, 32)   9248        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3block_7_branch2a (BatchNorma (None, 16, 16, 32)   128         res3block_7_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 32)   0           bn3block_7_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3block_7_branch2b (Conv2D)   (None, 16, 16, 32)   9248        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3block_7_branch2b (BatchNorma (None, 16, 16, 32)   128         res3block_7_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 16, 16, 32)   0           bn3block_7_branch2b[0][0]        \n",
      "                                                                 activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 32)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3block_8_branch2a (Conv2D)   (None, 16, 16, 32)   9248        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3block_8_branch2a (BatchNorma (None, 16, 16, 32)   128         res3block_8_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 32)   0           bn3block_8_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3block_8_branch2b (Conv2D)   (None, 16, 16, 32)   9248        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3block_8_branch2b (BatchNorma (None, 16, 16, 32)   128         res3block_8_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 16, 16, 32)   0           bn3block_8_branch2b[0][0]        \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 32)   0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4block_0_branch2a (Conv2D)   (None, 8, 8, 64)     18496       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4block_0_branch2a (BatchNorma (None, 8, 8, 64)     256         res4block_0_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 64)     0           bn4block_0_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4block_0_branch2b (Conv2D)   (None, 8, 8, 64)     36928       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4block_0_branch1 (Conv2D)    (None, 8, 8, 64)     2112        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4block_0_branch2b (BatchNorma (None, 8, 8, 64)     256         res4block_0_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn4block_0_branch1 (BatchNormal (None, 8, 8, 64)     256         res4block_0_branch1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 8, 8, 64)     0           bn4block_0_branch2b[0][0]        \n",
      "                                                                 bn4block_0_branch1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 8, 8, 64)     0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4block_1_branch2a (Conv2D)   (None, 8, 8, 64)     36928       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4block_1_branch2a (BatchNorma (None, 8, 8, 64)     256         res4block_1_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 8, 8, 64)     0           bn4block_1_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4block_1_branch2b (Conv2D)   (None, 8, 8, 64)     36928       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4block_1_branch2b (BatchNorma (None, 8, 8, 64)     256         res4block_1_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 8, 8, 64)     0           bn4block_1_branch2b[0][0]        \n",
      "                                                                 activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 8, 8, 64)     0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4block_2_branch2a (Conv2D)   (None, 8, 8, 64)     36928       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4block_2_branch2a (BatchNorma (None, 8, 8, 64)     256         res4block_2_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 8, 8, 64)     0           bn4block_2_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4block_2_branch2b (Conv2D)   (None, 8, 8, 64)     36928       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4block_2_branch2b (BatchNorma (None, 8, 8, 64)     256         res4block_2_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 8, 8, 64)     0           bn4block_2_branch2b[0][0]        \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 8, 8, 64)     0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4block_3_branch2a (Conv2D)   (None, 8, 8, 64)     36928       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4block_3_branch2a (BatchNorma (None, 8, 8, 64)     256         res4block_3_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 8, 8, 64)     0           bn4block_3_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4block_3_branch2b (Conv2D)   (None, 8, 8, 64)     36928       activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4block_3_branch2b (BatchNorma (None, 8, 8, 64)     256         res4block_3_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 8, 8, 64)     0           bn4block_3_branch2b[0][0]        \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 8, 8, 64)     0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4block_4_branch2a (Conv2D)   (None, 8, 8, 64)     36928       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4block_4_branch2a (BatchNorma (None, 8, 8, 64)     256         res4block_4_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 8, 8, 64)     0           bn4block_4_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4block_4_branch2b (Conv2D)   (None, 8, 8, 64)     36928       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4block_4_branch2b (BatchNorma (None, 8, 8, 64)     256         res4block_4_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 8, 8, 64)     0           bn4block_4_branch2b[0][0]        \n",
      "                                                                 activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 8, 8, 64)     0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4block_5_branch2a (Conv2D)   (None, 8, 8, 64)     36928       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4block_5_branch2a (BatchNorma (None, 8, 8, 64)     256         res4block_5_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 8, 8, 64)     0           bn4block_5_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4block_5_branch2b (Conv2D)   (None, 8, 8, 64)     36928       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4block_5_branch2b (BatchNorma (None, 8, 8, 64)     256         res4block_5_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 8, 8, 64)     0           bn4block_5_branch2b[0][0]        \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 8, 8, 64)     0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4block_6_branch2a (Conv2D)   (None, 8, 8, 64)     36928       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4block_6_branch2a (BatchNorma (None, 8, 8, 64)     256         res4block_6_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 8, 8, 64)     0           bn4block_6_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4block_6_branch2b (Conv2D)   (None, 8, 8, 64)     36928       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4block_6_branch2b (BatchNorma (None, 8, 8, 64)     256         res4block_6_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 8, 8, 64)     0           bn4block_6_branch2b[0][0]        \n",
      "                                                                 activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 8, 8, 64)     0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4block_7_branch2a (Conv2D)   (None, 8, 8, 64)     36928       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4block_7_branch2a (BatchNorma (None, 8, 8, 64)     256         res4block_7_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 8, 64)     0           bn4block_7_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4block_7_branch2b (Conv2D)   (None, 8, 8, 64)     36928       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4block_7_branch2b (BatchNorma (None, 8, 8, 64)     256         res4block_7_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 8, 8, 64)     0           bn4block_7_branch2b[0][0]        \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 8, 64)     0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4block_8_branch2a (Conv2D)   (None, 8, 8, 64)     36928       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4block_8_branch2a (BatchNorma (None, 8, 8, 64)     256         res4block_8_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 8, 8, 64)     0           bn4block_8_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4block_8_branch2b (Conv2D)   (None, 8, 8, 64)     36928       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4block_8_branch2b (BatchNorma (None, 8, 8, 64)     256         res4block_8_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 8, 8, 64)     0           bn4block_8_branch2b[0][0]        \n",
      "                                                                 activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 8, 8, 64)     0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 64)           0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fc10 (Dense)                    (None, 2)            130         avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 861,970\n",
      "Trainable params: 857,682\n",
      "Non-trainable params: 4,288\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet56_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir=\"logs/resnet56/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
    "file_writer.set_as_default()\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        update_freq='batch',\n",
    "        histogram_freq=1)\n",
    "\n",
    "lr_schedule_callback = LearningRateScheduler(schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 546 steps, validate for 117 steps\n",
      "Epoch 1/60\n",
      "546/546 [==============================] - 35s 64ms/step - loss: 1.4000 - sparse_categorical_accuracy: 0.8057 - val_loss: 1.2178 - val_sparse_categorical_accuracy: 0.7878\n",
      "Epoch 2/60\n",
      "546/546 [==============================] - 21s 38ms/step - loss: 0.9523 - sparse_categorical_accuracy: 0.8654 - val_loss: 1.5998 - val_sparse_categorical_accuracy: 0.5897\n",
      "Epoch 3/60\n",
      "546/546 [==============================] - 21s 38ms/step - loss: 0.6978 - sparse_categorical_accuracy: 0.8882 - val_loss: 0.7865 - val_sparse_categorical_accuracy: 0.7938\n",
      "Epoch 4/60\n",
      "546/546 [==============================] - 21s 38ms/step - loss: 0.5276 - sparse_categorical_accuracy: 0.9060 - val_loss: 0.5772 - val_sparse_categorical_accuracy: 0.8570\n",
      "Epoch 5/60\n",
      "546/546 [==============================] - 21s 38ms/step - loss: 0.4254 - sparse_categorical_accuracy: 0.9161 - val_loss: 2.0581 - val_sparse_categorical_accuracy: 0.5724\n",
      "Epoch 6/60\n",
      "546/546 [==============================] - 21s 38ms/step - loss: 0.3602 - sparse_categorical_accuracy: 0.9243 - val_loss: 0.5200 - val_sparse_categorical_accuracy: 0.8194\n",
      "Epoch 7/60\n",
      "546/546 [==============================] - 21s 39ms/step - loss: 0.3100 - sparse_categorical_accuracy: 0.9327 - val_loss: 0.3100 - val_sparse_categorical_accuracy: 0.9278\n",
      "Epoch 8/60\n",
      "546/546 [==============================] - 21s 38ms/step - loss: 0.2768 - sparse_categorical_accuracy: 0.9407 - val_loss: 0.4421 - val_sparse_categorical_accuracy: 0.8596\n",
      "Epoch 9/60\n",
      "546/546 [==============================] - 21s 38ms/step - loss: 0.2522 - sparse_categorical_accuracy: 0.9455 - val_loss: 0.3379 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 10/60\n",
      "546/546 [==============================] - 21s 38ms/step - loss: 0.2453 - sparse_categorical_accuracy: 0.9481 - val_loss: 0.4768 - val_sparse_categorical_accuracy: 0.8761\n",
      "Epoch 11/60\n",
      "546/546 [==============================] - 21s 39ms/step - loss: 0.2271 - sparse_categorical_accuracy: 0.9529 - val_loss: 1.6436 - val_sparse_categorical_accuracy: 0.6488\n",
      "Epoch 12/60\n",
      "546/546 [==============================] - 21s 39ms/step - loss: 0.2177 - sparse_categorical_accuracy: 0.9567 - val_loss: 0.2911 - val_sparse_categorical_accuracy: 0.9323\n",
      "Epoch 13/60\n",
      "546/546 [==============================] - 21s 39ms/step - loss: 0.2171 - sparse_categorical_accuracy: 0.9583 - val_loss: 0.7700 - val_sparse_categorical_accuracy: 0.7906\n",
      "Epoch 14/60\n",
      "546/546 [==============================] - 21s 39ms/step - loss: 0.2065 - sparse_categorical_accuracy: 0.9623 - val_loss: 0.4635 - val_sparse_categorical_accuracy: 0.8747\n",
      "Epoch 15/60\n",
      "546/546 [==============================] - 21s 39ms/step - loss: 0.2067 - sparse_categorical_accuracy: 0.9628 - val_loss: 0.2242 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 16/60\n",
      "546/546 [==============================] - 21s 39ms/step - loss: 0.2016 - sparse_categorical_accuracy: 0.9659 - val_loss: 0.4987 - val_sparse_categorical_accuracy: 0.8624\n",
      "Epoch 17/60\n",
      "546/546 [==============================] - 21s 39ms/step - loss: 0.2033 - sparse_categorical_accuracy: 0.9666 - val_loss: 0.3895 - val_sparse_categorical_accuracy: 0.9056\n",
      "Epoch 18/60\n",
      "546/546 [==============================] - 21s 39ms/step - loss: 0.1981 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.3613 - val_sparse_categorical_accuracy: 0.8974\n",
      "Epoch 19/60\n",
      "546/546 [==============================] - 21s 39ms/step - loss: 0.1964 - sparse_categorical_accuracy: 0.9706 - val_loss: 0.3500 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 20/60\n",
      "546/546 [==============================] - 21s 39ms/step - loss: 0.1945 - sparse_categorical_accuracy: 0.9699 - val_loss: 0.3541 - val_sparse_categorical_accuracy: 0.9207\n",
      "Epoch 21/60\n",
      "546/546 [==============================] - 22s 40ms/step - loss: 0.1958 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.4354 - val_sparse_categorical_accuracy: 0.8873\n",
      "Epoch 22/60\n",
      "546/546 [==============================] - 21s 39ms/step - loss: 0.1909 - sparse_categorical_accuracy: 0.9712 - val_loss: 0.7863 - val_sparse_categorical_accuracy: 0.7906\n",
      "Epoch 23/60\n",
      "546/546 [==============================] - 21s 39ms/step - loss: 0.1960 - sparse_categorical_accuracy: 0.9716 - val_loss: 0.2583 - val_sparse_categorical_accuracy: 0.9489\n",
      "Epoch 24/60\n",
      "546/546 [==============================] - 21s 39ms/step - loss: 0.1914 - sparse_categorical_accuracy: 0.9724 - val_loss: 0.3423 - val_sparse_categorical_accuracy: 0.9058\n",
      "Epoch 25/60\n",
      "546/546 [==============================] - 21s 38ms/step - loss: 0.1921 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.4851 - val_sparse_categorical_accuracy: 0.8638\n",
      "Epoch 26/60\n",
      "546/546 [==============================] - 21s 38ms/step - loss: 0.1940 - sparse_categorical_accuracy: 0.9728 - val_loss: 0.4173 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 27/60\n",
      "546/546 [==============================] - 21s 38ms/step - loss: 0.1869 - sparse_categorical_accuracy: 0.9747 - val_loss: 0.8877 - val_sparse_categorical_accuracy: 0.7700\n",
      "Epoch 28/60\n",
      "546/546 [==============================] - 21s 39ms/step - loss: 0.1861 - sparse_categorical_accuracy: 0.9755 - val_loss: 0.2525 - val_sparse_categorical_accuracy: 0.9499\n",
      "Epoch 29/60\n",
      "546/546 [==============================] - 21s 39ms/step - loss: 0.1847 - sparse_categorical_accuracy: 0.9755 - val_loss: 0.2634 - val_sparse_categorical_accuracy: 0.9431\n",
      "Epoch 30/60\n",
      "546/546 [==============================] - 21s 39ms/step - loss: 0.1849 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.3294 - val_sparse_categorical_accuracy: 0.9184\n",
      "Epoch 31/60\n",
      "541/546 [============================>.] - ETA: 0s - loss: 0.1505 - sparse_categorical_accuracy: 0.9904"
     ]
    }
   ],
   "source": [
    "history = resnet56_model.fit(\n",
    "        train_ds,\n",
    "        steps_per_epoch = train_size // BATCH_SIZE,\n",
    "        epochs = NUM_EPOCHS,\n",
    "        validation_data = test_ds,\n",
    "        validation_steps = test_size // BATCH_SIZE,\n",
    "        validation_freq = 1,\n",
    "        callbacks = [tensorboard_callback, lr_schedule_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Keras`\n",
    "Save/load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet56_model.save('models/{}.h5'.format(model_name))\n",
    "# tl_model = tf.keras.models.load_model('models/{}.h5'.format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['sparse_categorical_accuracy']\n",
    "val_acc = history.history['val_sparse_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(NUM_EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Subplot 1\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "# plt.ylim([0.5, 1])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# Subplot 2\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "# plt.ylim([0.5, 1])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet56_evaluate = resnet56_model.evaluate(val_ds, verbose=2, steps=val_size//BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Tensorboard`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard import notebook"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Clear any logs from previous runs (move to .old instead?)\n",
    "!rm -rf ./logs/\n",
    "\n",
    "# Stop tensorboard\n",
    "notebook.list()\n",
    "!kill 20058"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "# %load_ext tensorboard\n",
    "\n",
    "# Start tensorboard\n",
    "# %tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch one batch\n",
    "images, labels = next(iter(val_ds))\n",
    "\n",
    "# Convert from tensor to numpy array\n",
    "images = images.numpy()\n",
    "labels = labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random image and label\n",
    "idx = np.random.randint(0, BATCH_SIZE)\n",
    "image = images[idx]\n",
    "label = labels[idx]\n",
    "\n",
    "# Predict one image\n",
    "result = resnet56_model.predict(np.expand_dims(image, axis=0))[0][0]\n",
    "\n",
    "pred = ('Boat') if result<0.5 else ('Not boat')\n",
    "\n",
    "print (\"Image {} of {}\".format(idx,BATCH_SIZE))\n",
    "# print (\"True label:\", class_names[label])\n",
    "# print ('Probabibity of Negative: {:.5f}%'.format((result)*100))\n",
    "\n",
    "plt.figure(frameon=False, facecolor='white');\n",
    "plt.title(pred, fontdict={'color':'white','size':20})\n",
    "plt.imshow(image)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict one batch\n",
    "results = resnet56_model.predict(images)\n",
    "\n",
    "print ('{:3}  {:7}  {:3}%'.format('idx', 'true_label', 'pred_prob'))\n",
    "print ('---  ---------   ----------')\n",
    "idx = 0\n",
    "for result in results:\n",
    "    true_label = class_names[labels[idx]]\n",
    "    pred_prob = result[0]*100\n",
    "    print ('{:3}  {:10}  {:05f}%'.format(idx, true_label, pred_prob))\n",
    "    idx += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
