{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kvasir dataset split into neg/pos and trained using Resnet50 without augmentation. Getting some decent results after training on resampled data with large step-size.  \n",
    "- Class weighting  \n",
    "- Resampling  \n",
    "- Initial Bias-estimation\n",
    "- Decreasing learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading images\n",
    "https://www.tensorflow.org/tutorials/load_data/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "# Some stuff to make utils-function work\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "from pipeline import *\n",
    "from create_model import *\n",
    "from utils import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Jupyter-specific\n",
    "%matplotlib inline\n",
    "\n",
    "project_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = pathlib.Path('/home/henriklg/master-thesis/data/kvasir-v2/')\n",
    "data_dir = pathlib.Path('/home/henriklg/master-thesis/data/hyper-kvasir/labeled_ttv/')\n",
    "\n",
    "dir_name = \"resnet50\"\n",
    "experiment = \"imbalance\"\n",
    "log_dir = \"./logs/{}_{}/{}\".format(project_time, experiment, dir_name)\n",
    "\n",
    "conf = {\n",
    "    # Dataset\n",
    "    \"data_dir\": data_dir,\n",
    "    \"ds_info\": 'binary',\n",
    "    \"augment\": [\"crop\",\"flip\",\"brightness\",\"saturation\",\"contrast\",\"rotate\"],\n",
    "    \"aug_mult\": 0,\n",
    "    \"resample\": False,\n",
    "    \"class_weight\": False,\n",
    "    \"shuffle_buffer_size\": 2000,        # 0=no shuffling\n",
    "    \"seed\": 2511,\n",
    "    \"neg_class\": \"pylorus\",                 # select neg class for binary ds (normal class)\n",
    "    \"outcast\": None,                   # list of folders to drop - currently only works for 1 item\n",
    "    # Model\n",
    "    \"model\": 'EfficientNetB0',\n",
    "    \"weights\": None,                   # which weights to initialize the model with\n",
    "    \"dropout\": 0.2,\n",
    "    \"num_epochs\": 10,\n",
    "    \"batch_size\": 16,\n",
    "    \"img_shape\": (128, 128, 3),\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer\": 'Adam',\n",
    "    \"final_activation\": 'sigmoid',     # sigmoid for binary ds\n",
    "    # Callbacks\n",
    "    \"tensorboard\": False,\n",
    "    \"learning_schedule\": False,\n",
    "    \"decay_rate\": 0,                   # 128:0.25   64:1.0   32:4.0   16:16   8:64\n",
    "    \"checkpoint\": False,\n",
    "    \"early_stopp\": False,\n",
    "    \"early_stopp_patience\": 7,\n",
    "    # Misc\n",
    "    \"verbosity\": 1,\n",
    "    \"keep_threshold\": 0.0,\n",
    "    \"log_dir\": log_dir,\n",
    "    \"cache_dir\": \"./cache\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training, testing and validation dataset from utils/data_prep.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Negative                          :   999 | 9.37%\n",
      "---------------------------------------------\n",
      "     - pylorus                    :   999 | 9.37%\n",
      "\n",
      "Positive                          :  9663 | 90.63%\n",
      "---------------------------------------------\n",
      "     - barretts-short-segment     :    53 | 0.50%\n",
      "     - retroflex-stomach          :   764 | 7.17%\n",
      "     - ulcerative-colitis-0-1     :    35 | 0.33%\n",
      "     - ulcerative-colitis-grade-3 :   133 | 1.25%\n",
      "     - esophagitis-b-d            :   260 | 2.44%\n",
      "     - dyed-resection-margins     :   989 | 9.28%\n",
      "     - hemorrhoids                :     6 | 0.06%\n",
      "     - normal-z-line              :   932 | 8.74%\n",
      "     - esophagitis-a              :   403 | 3.78%\n",
      "     - ulcerative-colitis-1-2     :    11 | 0.10%\n",
      "     - barretts                   :    41 | 0.38%\n",
      "     - bbps-2-3                   :  1148 | 10.77%\n",
      "     - ileum                      :     9 | 0.08%\n",
      "     - bbps-0-1                   :   646 | 6.06%\n",
      "     - impacted-stool             :   131 | 1.23%\n",
      "     - cecum                      :  1009 | 9.46%\n",
      "     - ulcerative-colitis-grade-2 :   443 | 4.15%\n",
      "     - ulcerative-colitis-2-3     :    28 | 0.26%\n",
      "     - retroflex-rectum           :   391 | 3.67%\n",
      "     - ulcerative-colitis-grade-1 :   201 | 1.89%\n",
      "     - polyps                     :  1028 | 9.64%\n",
      "     - dyed-lifted-polyps         :  1002 | 9.40%\n",
      "\n",
      "Total number of image       : 10662\n",
      "\n",
      "Category                    : train | test  | val   | total | % of total \n",
      "------------------------------------------------------------------------\n",
      "Negative                    :   699 |   150 |   150 |     0 |  0.00%\n",
      "Positive                    :  6755 |  1448 |  1460 |     0 |  0.00%\n",
      "------------------------------------------------------------------------\n",
      "Total                       :  7454 |  1598 |  1610 | 10662 | \n"
     ]
    }
   ],
   "source": [
    "ds = create_dataset(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet50 transfer learning\n",
    "see https://adventuresinmachinelearning.com/transfer-learning-tensorflow-2/  \n",
    "imbalanced-data: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "        tf.keras.metrics.TruePositives(name='tp'),\n",
    "        tf.keras.metrics.FalsePositives(name='fp'),\n",
    "        tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "        tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.AUC(name='auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_net = tf.keras.applications.ResNet50(\n",
    "                weights='imagenet', \n",
    "                include_top=False, \n",
    "                input_shape=conf[\"img_shape\"])\n",
    "\n",
    "res_net.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    \n",
    "    global_average_layer = GlobalAveragePooling2D()\n",
    "    output_layer = Dense(1, activation=conf[\"final_activation\"],\n",
    "                         bias_initializer=output_bias)\n",
    "\n",
    "    resnet50_model = tf.keras.Sequential([\n",
    "            res_net,\n",
    "            global_average_layer,\n",
    "            output_layer])\n",
    "    \n",
    "    if conf['optimizer'] == 'Adam':\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=conf[\"learning_rate\"])\n",
    "    elif conf['optimizer'] == 'SGD':\n",
    "        opt = tf.keras.optimizers.SGD(learning_rate=conf[\"learning_rate\"])\n",
    "\n",
    "    resnet50_model.compile(\n",
    "            optimizer=opt,\n",
    "            loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "            metrics=metrics)\n",
    "    \n",
    "    return resnet50_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = create_callbacks(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set correct initial bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16182473],\n",
       "       [0.16980207],\n",
       "       [0.17290497],\n",
       "       [0.1681541 ],\n",
       "       [0.17086743],\n",
       "       [0.17005058],\n",
       "       [0.16597866],\n",
       "       [0.17113271],\n",
       "       [0.17005381],\n",
       "       [0.1708837 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_model = make_model()\n",
    "\n",
    "# Test run the model and show 10 first predictions of one epoch\n",
    "bias_model.predict(ds[\"train\"].take(1))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.6231\n"
     ]
    }
   ],
   "source": [
    "results = bias_model.evaluate(ds[\"train\"], verbose=0, steps=conf[\"steps\"][\"train\"])\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial bias should then be: 2.2693\n"
     ]
    }
   ],
   "source": [
    "initial_bias = np.log([conf[\"pos_count\"]/conf[\"neg_count\"]])\n",
    "print (\"The initial bias should then be: {:.4f}\".format(initial_bias[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial guess should be around: 0.9063027574563872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.93139756],\n",
       "       [0.9313035 ],\n",
       "       [0.9309217 ],\n",
       "       [0.9301199 ],\n",
       "       [0.93065846],\n",
       "       [0.930574  ],\n",
       "       [0.93035424],\n",
       "       [0.9308209 ],\n",
       "       [0.9314193 ],\n",
       "       [0.9312885 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_bias_model = make_model(output_bias = initial_bias)\n",
    "new_bias_model.predict(ds[\"train\"], verbose=0, steps=conf[\"steps\"][\"train\"])\n",
    "\n",
    "print (\"Initial guess should be around:\", conf[\"pos_count\"]/conf[\"ds_sizes\"][\"total\"])\n",
    "new_bias_model.predict(ds[\"train\"].take(1))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3165\n"
     ]
    }
   ],
   "source": [
    "results = new_bias_model.evaluate(ds[\"train\"], verbose=0, steps=conf[\"steps\"][\"train\"])\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = os.path.join(conf[\"log_dir\"],'initial_weights')\n",
    "new_bias_model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirm that the bias fix helps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "def plot_loss(history, label, n):\n",
    "    # Use a log scale to show the wide range of values.\n",
    "    plt.semilogy(history.epoch,  history.history['loss'],\n",
    "               color=colors[n], label='Train '+label)\n",
    "    plt.semilogy(history.epoch,  history.history['val_loss'],\n",
    "          color=colors[n], label='Val '+label,\n",
    "          linestyle=\"--\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 16\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = make_model()\n",
    "model.load_weights(initial_weights)\n",
    "model.layers[-1].bias.assign([0.0])\n",
    "zero_bias_history = model.fit(\n",
    "    train_ds,\n",
    "    steps_per_epoch = conf[\"steps\"][\"train\"],\n",
    "    epochs = 10,\n",
    "    validation_data = test_ds,\n",
    "    validation_steps = conf[\"steps\"][\"test\"],\n",
    "    validation_freq = 1,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = make_model()\n",
    "model.load_weights(initial_weights)\n",
    "careful_bias_history = model.fit(\n",
    "    train_ds,\n",
    "    steps_per_epoch = conf[\"steps\"][\"train\"],\n",
    "    epochs = 10,\n",
    "    validation_data = test_ds,\n",
    "    validation_steps = conf[\"steps\"][\"test\"],\n",
    "    validation_freq = 1,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plot_loss(zero_bias_history, \"Zero Bias\", 0)\n",
    "plot_loss(careful_bias_history, \"Careful Bias\", 1)\n",
    "plt.savefig(conf[\"log_dir\"]+\"/bias_zero_vs_careful.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    metrics =  ['loss', 'auc', 'precision', 'recall']\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    for n, metric in enumerate(metrics):\n",
    "        name = metric.replace(\"_\",\" \").capitalize()\n",
    "        plt.subplot(2,2,n+1)\n",
    "        plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "        plt.plot(history.epoch, history.history['val_'+metric],\n",
    "                 color=colors[0], linestyle=\"--\", label='Val')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(name)\n",
    "        if metric == 'loss':\n",
    "            plt.ylim([0, plt.ylim()[1]])\n",
    "        elif metric == 'auc':\n",
    "            plt.ylim([0.8,1])\n",
    "        else:\n",
    "            plt.ylim([0,1])\n",
    "\n",
    "        plt.legend()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "    cm = confusion_matrix(labels, predictions > p)\n",
    "    \n",
    "    metrics_list = np.asarray([['tn', 'fp'], ['fn', 'tp']])\n",
    "    labels = (np.asarray([\"{0}\\n{1:.0f}\".format(metrics_list,cm) for metrics_list, cm in zip(metrics_list.flatten(), cm.flatten())])).reshape(2,2)\n",
    "    \n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=labels, fmt=\"\", robust=True, annot_kws={'size':16})\n",
    "    plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    plt.ylim(2,0)\n",
    "\n",
    "    print('Legitimate Lesions Detected (True Negatives): ', cm[0][0])\n",
    "    print('Legitimate Lesions Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "    print('Fraudulent Lesions Missed (False Negatives): ', cm[1][0])\n",
    "    print('Fraudulent Lesions Detected (True Positives): ', cm[1][1])\n",
    "    print('Total Fraudulent Lesions: ', np.sum(cm[1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "    fp, tp, _ = roc_curve(labels, predictions)\n",
    "\n",
    "    plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('False positives [%]')\n",
    "    plt.ylabel('True positives [%]')\n",
    "    plt.xlim([-0.5,20])\n",
    "    plt.ylim([80,100.5])\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpify(dataset, model, samples=4000):\n",
    "    ds_eval = dataset.unbatch().take(samples)\n",
    "    labels = []\n",
    "    images = []\n",
    "    for img, lab in ds_eval:\n",
    "        labels.append(lab.numpy())\n",
    "        images.append(img.numpy())\n",
    "\n",
    "    pred = model.predict(np.expand_dims(images, axis=0)[-1])\n",
    "    \n",
    "    return (labels, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 465 steps, validate for 99 steps\n",
      "Epoch 1/10\n",
      "465/465 [==============================] - 33s 72ms/step - loss: 0.1398 - tp: 6640.0000 - fp: 287.0000 - tn: 409.0000 - fn: 104.0000 - accuracy: 0.9474 - precision: 0.9586 - recall: 0.9846 - auc: 0.9559 - val_loss: 6.9511 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 148.0000 - val_fn: 1436.0000 - val_accuracy: 0.0934 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 2/10\n",
      "165/465 [=========>....................] - ETA: 16s - loss: 0.0843 - tp: 2362.0000 - fp: 51.0000 - tn: 189.0000 - fn: 38.0000 - accuracy: 0.9663 - precision: 0.9789 - recall: 0.9842 - auc: 0.9864"
     ]
    }
   ],
   "source": [
    "baseline_model = make_model()\n",
    "baseline_model.load_weights(initial_weights)\n",
    "\n",
    "baseline_history = baseline_model.fit(\n",
    "    ds[\"train\"],\n",
    "    steps_per_epoch = conf[\"steps\"][\"train\"],\n",
    "    epochs = conf[\"num_epochs\"],\n",
    "    validation_data = ds[\"test\"],\n",
    "    validation_steps = conf[\"steps\"][\"test\"],\n",
    "    validation_freq = 1,\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(baseline_history)\n",
    "plt.savefig(conf[\"log_dir\"]+\"figures/baseline_metrics_plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = baseline_model.evaluate(ds[\"val\"], verbose=2, steps=conf[\"steps\"][\"val\"])\n",
    "print()\n",
    "\n",
    "f = open(conf[\"log_dir\"]+\"/baseline_val_results.txt\",\"w\")\n",
    "for name, value in zip(baseline_model.metrics_names, baseline_results):\n",
    "    line = \"{} : {}\\n\".format(name, value)\n",
    "    print(line, end='')\n",
    "    f.write(line)\n",
    "f.close()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_baseline, train_predictions_baseline = numpify(ds[\"train\"], baseline_model, samples=5000)\n",
    "val_labels_baseline, val_predictions_baseline = numpify(ds[\"val\"], baseline_model, samples=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(train_labels_baseline, train_predictions_baseline)\n",
    "plt.savefig(conf[\"log_dir\"]+\"/baseline_cm_plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plot_roc(\"Train Baseline\", train_labels_baseline, train_predictions_baseline, color=colors[0])\n",
    "plot_roc(\"Test Baseline\", val_labels_baseline, val_predictions_baseline, color=colors[0], linestyle='--')\n",
    "\n",
    "plt.legend(loc='lower right');\n",
    "plt.savefig(conf[\"log_dir\"]+\"/baseline_roc_plot.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate class weights\n",
    "See https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_for_0 = (1/conf[\"neg_count\"])*(conf[\"ds_sizes\"][\"total\"])/2.0\n",
    "weight_for_1 = (1/conf[\"pos_count\"])*(conf[\"ds_sizes\"][\"total\"])/2.0\n",
    "\n",
    "class_weight = {0: weight_for_0,\n",
    "                1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_model = make_model()\n",
    "weighted_model.load_weights(initial_weights)\n",
    "\n",
    "weighted_history = weighted_model.fit(\n",
    "    ds[\"train\"],\n",
    "    steps_per_epoch = conf[\"steps\"][\"train\"],\n",
    "    epochs = conf[\"num_epochs\"],\n",
    "    validation_data = ds[\"test\"],\n",
    "    validation_steps = conf[\"steps\"][\"test\"],\n",
    "    validation_freq = 1,\n",
    "    class_weight = class_weight,\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(weighted_history)\n",
    "plt.savefig(conf[\"log_dir\"]+\"/weighted_metrics_plot.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_results = weighted_model.evaluate(ds[\"val\"], verbose=2, steps=conf[\"steps\"][\"val\"])\n",
    "print()\n",
    "\n",
    "f = open(conf[\"log_dir\"]+\"/weighted_val_results.txt\",\"w\")\n",
    "for name, value in zip(baseline_model.metrics_names, weighted_results):\n",
    "    line = \"{} : {}\\n\".format(name, value)\n",
    "    print(line, end='')\n",
    "    f.write(line)\n",
    "f.close()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_weighted, train_predictions_weighted = numpify(ds[\"train\"], weighted_model, samples=5000)\n",
    "val_labels_weighted, val_predictions_weighted = numpify(ds[\"val\"], weighted_model, samples=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(train_labels_weighted, train_predictions_weighted)\n",
    "plt.savefig(conf[\"log_dir\"]+\"/weighted_cm_plot.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plot_roc(\"Train Baseline\", train_labels_baseline, train_predictions_baseline, color=colors[0])\n",
    "plot_roc(\"Val Baseline\", val_labels_baseline, val_predictions_baseline, color=colors[0], linestyle='--')\n",
    "\n",
    "plot_roc(\"Train Weighted\", train_labels_weighted, train_predictions_weighted, color=colors[1])\n",
    "plot_roc(\"Val Weighted\", val_labels_weighted, val_predictions_weighted, color=colors[1], linestyle='--')\n",
    "\n",
    "plt.legend(loc='lower right');\n",
    "plt.savefig(conf[\"log_dir\"]+\"/weighted_roc_plot.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the cache\n",
    "!rm -rf ./cache/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset resample to true to make 5050 distribution of samples\n",
    "conf[\"resample\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training, testing and validation dataset from utils/data_prep.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf[\"num_classes\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_resampled = create_dataset(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the mean value is close to 0.5\n",
    "for img, label in ds_resampled[\"train\"].take(3):\n",
    "    print(label.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_model = make_model()\n",
    "resampled_model.load_weights(initial_weights)\n",
    "\n",
    "resampled_history = resampled_model.fit(\n",
    "    ds_resampled[\"train\"],\n",
    "    steps_per_epoch = conf[\"steps\"][\"train\"],\n",
    "    epochs = conf[\"num_epochs\"],\n",
    "    validation_data = ds_resampled[\"test\"],\n",
    "    validation_steps = conf[\"steps\"][\"test\"],\n",
    "    validation_freq = 1,\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(resampled_history)\n",
    "plt.savefig(conf[\"log_dir\"]+\"/resampled_metrics_plot.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_results = resampled_model.evaluate(ds_resampled[\"val\"], verbose=2, steps=conf[\"steps\"][\"val\"])\n",
    "print()\n",
    "\n",
    "f = open(conf[\"log_dir\"]+\"/resampled_val_results.txt\",\"w\")\n",
    "for name, value in zip(resampled_model.metrics_names, resampled_results):\n",
    "    line = \"{} : {}\\n\".format(name, value)\n",
    "    print(line, end='')\n",
    "    f.write(line)\n",
    "f.close()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_resampled, train_predictions_resampled = numpify(ds_resampled[\"train\"], resampled_model, samples=5000)\n",
    "val_labels_resampled, val_predictions_resampled = numpify(ds_resampled[\"val\"], resampled_model, samples=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(train_labels_resampled, train_predictions_resampled)\n",
    "plt.savefig(conf[\"log_dir\"]+\"/resampled_cm_plot.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plot_roc(\"Train Baseline\", train_labels_baseline, train_predictions_baseline, color=colors[0])\n",
    "plot_roc(\"Val Baseline\", val_labels_baseline, val_predictions_baseline, color=colors[0], linestyle='--')\n",
    "\n",
    "plot_roc(\"Train Weighted\", train_labels_weighted, train_predictions_weighted, color=colors[1])\n",
    "plot_roc(\"Val Weighted\", val_labels_weighted, val_predictions_weighted, color=colors[1], linestyle='--')\n",
    "\n",
    "plot_roc(\"Train Resampled\", train_labels_resampled, train_predictions_resampled, color=colors[2])\n",
    "plot_roc(\"Val Resampled\", val_labels_resampled, val_predictions_resampled, color=colors[2], linestyle='--')\n",
    "\n",
    "plt.legend(loc='lower right');\n",
    "plt.savefig(conf[\"log_dir\"]+\"/resampled_roc_plot.pdf\", format=\"pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
